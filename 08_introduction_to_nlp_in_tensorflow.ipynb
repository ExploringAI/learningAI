{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"08_introduction_to_nlp_in_tensorflow.ipynb","provenance":[],"authorship_tag":"ABX9TyO+URKhqJwLTiAnE8c8NHHw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"vtAgo5zYCClj"},"source":["# 08. Natural Language Processing with TensorFlow\n","\n","![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/08-example-nlp-problems.png)\n","*A handful of example natural language processing (NLP) and natural language understanding (NLU) problems. These are also often referred to as sequence problems (going from one sequence to another).*\n","\n","The main goal of [natural language processing (NLP)](https://becominghuman.ai/a-simple-introduction-to-natural-language-processing-ea66a1747b32) is to derive information from natural language.\n","\n","Natural language is a broad term but you can consider it to cover any of the following:\n","* Text (such as that contained in an email, blog post, book, Tweet)\n","* Speech (a conversation you have with a doctor, voice commands you give to a smart speaker)\n","\n","Under the umbrellas of text and speech there are many different things you might want to do.\n","\n","If you're building an email application, you might want to scan incoming emails to see if they're spam or not spam (classification).\n","\n","If you're trying to analyse customer feedback complaints, you might want to discover which section of your business they're for.\n","\n","> üîë **Note:** Both of these types of data are often referred to as *sequences* (a sentence is a sequence of words). So a common term you'll come across in NLP problems is called *seq2seq*, in other words, finding information in one sequence to produce another sequence (e.g. converting a speech command to a sequence of text-based steps).\n","\n","To get hands-on with NLP in TensorFlow, we're going to practice the steps we've used previously but this time with text data:\n","\n","```\n","Text -> turn into numbers -> build a model -> train the model to find patterns -> use patterns (make predictions)\n","```\n","\n","> üìñ **Resource:** For a great overview of NLP and the different problems within it, read the article [*A Simple Introduction to Natural Language Processing*](https://becominghuman.ai/a-simple-introduction-to-natural-language-processing-ea66a1747b32).\n","\n","## What we're going to cover\n","\n","Let's get specific hey?\n","\n","* Downloading a text dataset\n","* Visualizing text data\n","* Converting text into numbers using tokenization\n","* Turning our tokenized text into an embedding\n","* Modelling a text dataset\n","  * Starting with a baseline (TF-IDF)\n","  * Building several deep learning text models\n","    * Dense, LSTM, GRU, Conv1D, Transfer learning\n","* Comparing the performance of each our models\n","* Combining our models into an ensemble\n","* Saving and loading a trained model\n","* Find the most wrong predictions\n","\n","## How you should approach this notebook\n","\n","You can read through the descriptions and the code (it should all run, except for the cells which error on purpose), but there's a better option.\n","\n","Write all of the code yourself.\n","\n","Yes. I'm serious. Create a new notebook, and rewrite each line by yourself. Investigate it, see if you can break it, why does it break?\n","\n","You don't have to write the text descriptions but writing the code yourself is a great way to get hands-on experience.\n","\n","Don't worry if you make mistakes, we all do. The way to get better and make less mistakes is to write more code.\n","\n","> üìñ **Resource:** See the full set of course materials on GitHub: https://github.com/mrdbourke/tensorflow-deep-learning"]},{"cell_type":"markdown","metadata":{"id":"4Zh2N1hZtvpN"},"source":["## Check for GPU\n","\n","In order for our deep learning models to run as fast as possible, we'll need access to a GPU.\n","\n","In Google Colab, you can set this up by going to Runtime -> Change runtime type -> Hardware accelerator -> GPU.\n","\n","After selecting GPU, you may have to restart the runtime."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6cLjrKXxiAhJ","executionInfo":{"status":"ok","timestamp":1641217017434,"user_tz":300,"elapsed":9,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"4c00f50f-5cf4-4d5e-f0c6-ca14c9d7530c"},"outputs":[{"output_type":"stream","name":"stdout","text":["NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n","\n"]}],"source":["# Check for GPU\n","!nvidia-smi -L"]},{"cell_type":"markdown","metadata":{"id":"gS3YnNNI8oFk"},"source":["## Get helper functions\n","\n","In past modules, we've created a bunch of helper functions to do small tasks required for our notebooks.\n","\n","Rather than rewrite all of these, we can import a script and load them in from there.\n","\n","The script containing our helper functions can be [found on GitHub](https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/extras/helper_functions.py)."]},{"cell_type":"code","source":["# Download helper functions script\n","!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nAVaOyZ3ruSU","executionInfo":{"status":"ok","timestamp":1641217017741,"user_tz":300,"elapsed":311,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"cfc3b91a-9f4e-41bd-8ab0-3bbe201cf2c7"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-01-03 13:36:56--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 10246 (10K) [text/plain]\n","Saving to: ‚Äòhelper_functions.py‚Äô\n","\n","helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n","\n","2022-01-03 13:36:56 (33.4 MB/s) - ‚Äòhelper_functions.py‚Äô saved [10246/10246]\n","\n"]}]},{"cell_type":"code","source":["# Import these helper functions for this notebook\n","from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"],"metadata":{"id":"aMXz-skwr6dt","executionInfo":{"status":"ok","timestamp":1641217020785,"user_tz":300,"elapsed":3045,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cCZrclc2COWW"},"source":["## Download a text dataset\n","\n","Let's start by download a text dataset. We'll be using the [Real or Not?](https://www.kaggle.com/c/nlp-getting-started/data) datset from Kaggle which contains text-based Tweets about natural disasters. \n","\n","The Real Tweets are actually about diasters, for example:\n","\n","```\n","Jetstar and Virgin forced to cancel Bali flights again because of ash from Mount Raung volcano\n","```\n","\n","The Not Real Tweets are Tweets not about diasters (they can be on anything), for example:\n","\n","```\n","'Education is the most powerful weapon which you can use to change the world.' Nelson #Mandela #quote\n","```\n","\n","For convenience, the dataset has been [downloaded from Kaggle](https://www.kaggle.com/c/nlp-getting-started/data) (doing this requires a Kaggle account) and uploaded as a downloadable zip file. \n","\n","> üîë **Note:** The original downloaded data has not been altered to how you would download it from Kaggle."]},{"cell_type":"code","source":["# Download data (same as from Kaggle)\n","!wget \"https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\"\n","\n","# Unzip data\n","unzip_data(\"nlp_getting_started.zip\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wScr_-KCsLOZ","executionInfo":{"status":"ok","timestamp":1641217021225,"user_tz":300,"elapsed":444,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"8da1fddd-cd39-44af-c108-1c7586354b8a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-01-03 13:36:59--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n","Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.125.128, 142.250.157.128, 142.251.8.128, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.125.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 607343 (593K) [application/zip]\n","Saving to: ‚Äònlp_getting_started.zip‚Äô\n","\n","\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.01s   \n","\n","2022-01-03 13:36:59 (60.7 MB/s) - ‚Äònlp_getting_started.zip‚Äô saved [607343/607343]\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"wBIR6tTI9QcR"},"source":["Unzipping `nlp_getting_started.zip` gives the following 3 `.csv` files:\n","* `sample_submission.csv` - an example of the file you'd submit to the Kaggle competition of your model's predictions.\n","* `train.csv` - training samples of real and not real diaster Tweets.\n","* `test.csv` - testing samples of real and not real diaster Tweets."]},{"cell_type":"markdown","metadata":{"id":"7HpxZKYdD6V-"},"source":["## Visualizing a text dataset\n","\n","Once you've acquired a new dataset to work with, what should you do first?\n","\n","Explore it? Inspect it? Verify it? Become one with it?\n","\n","All correct.\n","\n","Remember the motto: visualize, visualize, visualize.\n","\n","Right now, our text data samples are in the form of `.csv` files. For an easy way to make them visual, let's turn them into pandas DataFrame's.\n","\n","> üìñ **Reading:** You might come across text datasets in many different formats. Aside from CSV files (what we're working with), you'll probably encounter `.txt` files and `.json` files too. For working with these type of files, I'd recommend reading the two following articles by RealPython:\n","* [How to Read and Write Files in Python](https://realpython.com/read-write-files-python/)\n","* [Working with JSON Data in Python](https://realpython.com/python-json/)"]},{"cell_type":"code","source":["# Turn .csv files into pandas DataFrame's\n","import pandas as pd\n","train_df = pd.read_csv(\"train.csv\")\n","test_df = pd.read_csv(\"test.csv\")\n","train_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":250},"id":"dJDlTWq6sser","executionInfo":{"status":"ok","timestamp":1641217021226,"user_tz":300,"elapsed":22,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"7c636be0-afd4-4dd3-a1ac-56c4c01939a1"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-1e5b8904-10fe-42d9-9465-4c4bc389819d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>keyword</th>\n","      <th>location</th>\n","      <th>text</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Our Deeds are the Reason of this #earthquake M...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Forest fire near La Ronge Sask. Canada</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>All residents asked to 'shelter in place' are ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>6</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>13,000 people receive #wildfires evacuation or...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>7</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e5b8904-10fe-42d9-9465-4c4bc389819d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1e5b8904-10fe-42d9-9465-4c4bc389819d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1e5b8904-10fe-42d9-9465-4c4bc389819d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   id keyword  ...                                               text target\n","0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n","1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n","2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n","3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n","4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n","\n","[5 rows x 5 columns]"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"1xGqlnQaLmaT"},"source":["The training data we downloaded is probably shuffled already. But just to be sure, let's shuffle it again."]},{"cell_type":"code","source":["from pandas.core.common import random_state\n","# Shuffle training dataframe\n","train_df_shuffled = train_df.sample(frac=1, random_state=42) # shuffle with random state = 42 for reproducability\n","train_df_shuffled.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":337},"id":"UCXx9cspxbCX","executionInfo":{"status":"ok","timestamp":1641217021226,"user_tz":300,"elapsed":21,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"3dd9e4f0-06c0-43f1-d9d6-d6e0a9c72563"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-3a53318e-cf56-4205-8083-265bed6253db\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>keyword</th>\n","      <th>location</th>\n","      <th>text</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2644</th>\n","      <td>3796</td>\n","      <td>destruction</td>\n","      <td>NaN</td>\n","      <td>So you have a new weapon that can cause un-ima...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2227</th>\n","      <td>3185</td>\n","      <td>deluge</td>\n","      <td>NaN</td>\n","      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5448</th>\n","      <td>7769</td>\n","      <td>police</td>\n","      <td>UK</td>\n","      <td>DT @georgegalloway: RT @Galloway4Mayor: ¬â√õ√èThe...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>132</th>\n","      <td>191</td>\n","      <td>aftershock</td>\n","      <td>NaN</td>\n","      <td>Aftershock back to school kick off was great. ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6845</th>\n","      <td>9810</td>\n","      <td>trauma</td>\n","      <td>Montgomery County, MD</td>\n","      <td>in response to trauma Children of Addicts deve...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a53318e-cf56-4205-8083-265bed6253db')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3a53318e-cf56-4205-8083-265bed6253db button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3a53318e-cf56-4205-8083-265bed6253db');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["        id  ... target\n","2644  3796  ...      1\n","2227  3185  ...      0\n","5448  7769  ...      1\n","132    191  ...      0\n","6845  9810  ...      0\n","\n","[5 rows x 5 columns]"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"Lw4mKW1yL0kI"},"source":["Notice how the training data has a `\"target\"` column.\n","\n","We're going to be writing code to find patterns (e.g. different combinations of words) in the `\"text\"` column of the training dataset to predict the value of the `\"target\"` column.\n","\n","The test dataset doesn't have a `\"target\"` column.\n","\n","```\n","Inputs (text column) -> Machine Learning Algorithm -> Outputs (target column)\n","```\n","\n","![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/08-text-classification-inputs-and-outputs.png)\n","*Example text classification inputs and outputs for the problem of classifying whether a Tweet is about a diaster or not.*"]},{"cell_type":"code","source":["# The test data doesn't have a target (which is what I want it to predict)\n","test_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"xKezM6BfyMkj","executionInfo":{"status":"ok","timestamp":1641217021227,"user_tz":300,"elapsed":22,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"d440082a-c5d1-47d8-fe44-8bba740d0041"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-ea20b31a-ce49-43f8-a3bf-d6c4319ff369\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>keyword</th>\n","      <th>location</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Just happened a terrible car crash</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Heard about #earthquake is different cities, s...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>there is a forest fire at spot pond, geese are...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Apocalypse lighting. #Spokane #wildfires</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>11</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ea20b31a-ce49-43f8-a3bf-d6c4319ff369')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ea20b31a-ce49-43f8-a3bf-d6c4319ff369 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ea20b31a-ce49-43f8-a3bf-d6c4319ff369');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   id keyword location                                               text\n","0   0     NaN      NaN                 Just happened a terrible car crash\n","1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n","2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n","3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n","4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"O4JhBRn5Mn-V"},"source":["Let's check how many examples of each target we have."]},{"cell_type":"code","source":["# How many examples of each class?\n","train_df.target.value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sJbBrsYTzG4T","executionInfo":{"status":"ok","timestamp":1641217021227,"user_tz":300,"elapsed":21,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"b0ad91c1-283a-44de-ad1c-d4074e689d81"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    4342\n","1    3271\n","Name: target, dtype: int64"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"WjEDQ297Ihy4"},"source":["Since we have two target values, we're dealing with a **binary classification** problem.\n","\n","It's fairly balanced too, about 60% negative class (`target = 0`) and 40% positive class (`target = 1`).\n","\n","Where, \n","\n","* `1` = a real disaster Tweet\n","* `0` = not a real disaster Tweet\n","\n","And what about the total number of samples we have?"]},{"cell_type":"code","source":["# How many samples total?\n","print(f\"Total training samples: {len(train_df)}\")\n","print(f\"Total testing samples: {len(test_df)}\")\n","print(f\"Total samples: {len(train_df) + len(test_df)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QwV8hPEL3Tms","executionInfo":{"status":"ok","timestamp":1641217021227,"user_tz":300,"elapsed":17,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"3bb56dfc-2165-4635-f105-ef06d43bed42"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Total training samples: 7613\n","Total testing samples: 3263\n","Total samples: 10876\n"]}]},{"cell_type":"markdown","metadata":{"id":"Q1upY8-xNPWV"},"source":["Alright, seems like we've got a decent amount of training and test data. If anything, we've got an abundance of testing examples, usually a split of 90/10 (90% training, 10% testing) or 80/20 is suffice.\n","\n","Okay, time to visualize, let's write some code to visualize random text samples.\n","\n","> ü§î **Question:** Why visualize random samples? You could visualize samples in order but this could lead to only seeing a certain subset of data. Better to visualize a substantial quantity (100+) of random samples to get an idea of the different kinds of data you're working with. In machine learning, never underestimate the power of randomness."]},{"cell_type":"code","source":["# Visualize some random training examples\n","import random\n","random_index = random.randint(0, len(train_df)-5) # Create a random index not higher than the total num of samples\n","for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n","  _, text, target = row\n","  print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n","  print(f\"Text:\\n{text}\\n\")\n","  print(\"---\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EH77e2jV35By","executionInfo":{"status":"ok","timestamp":1641217021227,"user_tz":300,"elapsed":14,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"2e5553f1-84c2-41aa-af3f-f469c3c1ca6a"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Target: 0 (not real disaster)\n","Text:\n","@EnvySeven My beautiful Aquarius queenmy Siren of the cliffs and pretenses of overtures.Please sing this phantom songfor you alone shall\n","\n","---\n","\n","Target: 0 (not real disaster)\n","Text:\n","It's not a cute dinner date Til cams nose starts bleeding\n","\n","---\n","\n","Target: 1 (real disaster)\n","Text:\n","Remove the http://t.co/VbqmZ5aPwj and Linkury Browser Hijacker http://t.co/C2EyjNyBfN http://t.co/gt7gf0fSeX\n","\n","---\n","\n","Target: 0 (not real disaster)\n","Text:\n","People really still be having curfew even when they're 18 &amp; graduated high school ??\n","\n","---\n","\n","Target: 0 (not real disaster)\n","Text:\n","Came across this fire video not mine..enjoy..Babes way of saying hi to me while he's in the fire truck??\n","#fireman #¬â√õ_ http://t.co/V5gTUnwohy\n","\n","---\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"1FhRRewGPNS_"},"source":["### Split data into training and validation sets\n","\n","Since the test set has no labels and we need a way to evalaute our trained models, we'll split off some of the training data and create a validation set.\n","\n","When our model trains (tries patterns in the Tweet samples), it'll only see data from the training set and we can see how it performs on unseen data using the validation set.\n","\n","We'll convert our splits from pandas Series datatypes to lists of strings (for the text) and lists of ints (for the labels) for ease of use later.\n","\n","To split our training dataset and create a validation dataset, we'll use Scikit-Learn's [`train_test_split()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) method and dedicate 10% of the training samples to the validation set."]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","# Use train_test_split to split training data into training & validation sets\n","train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n","                                                                            train_df_shuffled[\"target\"].to_numpy(),\n","                                                                            test_size=0.1, # dedicate 10% of samples to validation set\n","                                                                            random_state=42) # random state for reproducibility"],"metadata":{"id":"PA83Lohc5kz0","executionInfo":{"status":"ok","timestamp":1641217021228,"user_tz":300,"elapsed":12,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Check the lengths\n","len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7ZokvI6L-miM","executionInfo":{"status":"ok","timestamp":1641217021631,"user_tz":300,"elapsed":415,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"8cb80d25-5d46-4ff4-f870-85f1acbf81ff"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(6851, 6851, 762, 762)"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["# View the first 10 train sentances & their labels\n","train_sentences[:10], train_labels[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mjFEXpjy-0TQ","executionInfo":{"status":"ok","timestamp":1641217021632,"user_tz":300,"elapsed":8,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"b0c2f2ea-0418-4640-d12b-d6ac7b53a30d"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n","        'Imagine getting flattened by Kurt Zouma',\n","        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n","        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n","        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n","        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n","        'destroy the free fandom honestly',\n","        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n","        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n","        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n","       dtype=object), array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"EN-houoSD-hP"},"source":["## Converting text into numbers\n","\n","Wonderful! We've got a training set and a validation set containing Tweets and labels.\n","\n","Our labels are in numerical form (`0` and `1`) but our Tweets are in string form.\n","\n","> ü§î **Question:** What do you think we have to do before we can use a machine learning algorithm with our text data? \n","\n","If you answered something along the lines of \"turn it into numbers\", you're correct. A machine learning algorithm requires its inputs to be in numerical form.\n","\n","In NLP, there are two main concepts for turning text into numbers:\n","* **Tokenization** - A straight mapping from word or character or sub-word to a numerical value. There are three main levels of tokenization:\n","  1. Using **word-level tokenization** with the sentence \"I love TensorFlow\" might result in \"I\" being `0`, \"love\" being `1` and \"TensorFlow\" being `2`. In this case, every word in a sequence considered a single **token**.\n","  2. **Character-level tokenization**, such as converting the letters A-Z to values `1-26`. In this case, every character in a sequence considered a single **token**.\n","  3. **Sub-word tokenization** is in between word-level and character-level tokenization. It involves breaking invidual words into smaller parts and then converting those smaller parts into numbers. For example, \"my favourite food is pineapple pizza\" might become \"my, fav, avour, rite, fo, oo, od, is, pin, ine, app, le, piz, za\". After doing this, these sub-words would then be mapped to a numerical value. In this case, every word could be considered multiple **tokens**.\n","* **Embeddings** - An embedding is a representation of natural language which can be learned. Representation comes in the form of a **feature vector**. For example, the word \"dance\" could be represented by the 5-dimensional vector `[-0.8547, 0.4559, -0.3332, 0.9877, 0.1112]`. It's important to note here, the size of the feature vector is tuneable. There are two ways to use embeddings: \n","  1. **Create your own embedding** - Once your text has been turned into numbers (required for an embedding), you can put them through an embedding layer (such as [`tf.keras.layers.Embedding`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding)) and an embedding representation will be learned during model training.\n","  2. **Reuse a pre-learned embedding** - Many pre-trained embeddings exist online. These pre-trained embeddings have often been learned on large corpuses of text (such as all of Wikipedia) and thus have a good underlying representation of natural language. You can use a pre-trained embedding to initialize your model and fine-tune it to your own specific task.\n","\n","![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/08-tokenization-vs-embedding.png)\n","*Example of **tokenization** (straight mapping from word to number) and **embedding** (richer representation of relationships between tokens).*\n","\n","> ü§î **Question:** What level of tokenzation should I use? What embedding should should I choose?\n","\n","It depends on your problem. You could try character-level tokenization/embeddings and word-level tokenization/embeddings and see which perform best. You might even want to try stacking them (e.g. combining the outputs of your embedding layers using [`tf.keras.layers.concatenate`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/concatenate)). \n","\n","If you're looking for pre-trained word embeddings, [Word2vec embeddings](http://jalammar.github.io/illustrated-word2vec/), [GloVe embeddings](https://nlp.stanford.edu/projects/glove/) and many of the options available on [TensorFlow Hub](https://tfhub.dev/s?module-type=text-embedding) are great places to start.\n","\n","> üîë **Note:** Much like searching for a pre-trained computer vision model, you can search for pre-trained word embeddings to use for your problem. Try searching for something like \"use pre-trained word embeddings in TensorFlow\"."]},{"cell_type":"markdown","metadata":{"id":"8UnRcM1PELHn"},"source":["### Text vectorization (tokenization)\n","\n","Enough talking about tokenization and embeddings, let's create some.\n","\n","We'll practice tokenzation (mapping our words to numbers) first.\n","\n","To tokenize our words, we'll use the helpful preprocessing layer [`tf.keras.layers.experimental.preprocessing.TextVectorization`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/TextVectorization).\n","\n","The `TextVectorization` layer takes the following parameters:\n","* `max_tokens` - The maximum number of words in your vocabulary (e.g. 20000 or the number of unique words in your text), includes a value for OOV (out of vocabulary) tokens. \n","* `standardize` - Method for standardizing text. Default is `\"lower_and_strip_punctuation\"` which lowers text and removes all punctuation marks.\n","* `split` - How to split text, default is `\"whitespace\"` which splits on spaces.\n","* `ngrams` - How many words to contain per token split, for example, `ngrams=2` splits tokens into continuous sequences of 2.\n","* `output_mode` -  How to output tokens, can be `\"int\"` (integer mapping), `\"binary\"` (one-hot encoding), `\"count\"` or `\"tf-idf\"`. See documentation for more.\n","* `output_sequence_length` - Length of tokenized sequence to output. For example, if `output_sequence_length=150`, all tokenized sequences will be 150 tokens long.\n","* `pad_to_max_tokens` - Defaults to `False`, if `True`, the output feature axis will be padded to `max_tokens` even if the number of unique tokens in the vocabulary is less than `max_tokens`. Only valid in certain modes, see docs for more.\n","\n","Let's see it in action."]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n","# Note: in TensorFlow 2.6+, \"layers.experimental.preprocessing\" is no longer needed\n","# Instead use: \"tf.keras.layers.TextVectorization\"\n","\n","# Use the default TextVectorization variables\n","text_vectorizor = TextVectorization(max_tokens=None, # how many words in vocab (num of different words in text)\n","                                    standardize=\"lower_and_strip_punctuation\", # how to process text\n","                                    split=\"whitespace\", # how to split tokens\n","                                    ngrams=None, # Create groups of n-words?\n","                                    output_mode=\"int\", # How to map tokens to nums\n","                                    output_sequence_length=None) #how long should the output sequence of tokens be?\n","                                    # pad_to_max_tokens=True) # Invalid if using max_tokens=None"],"metadata":{"id":"LGJtSaom_IHq","executionInfo":{"status":"ok","timestamp":1641217021632,"user_tz":300,"elapsed":6,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u0Ej5mzKGkK8"},"source":["We've initialized a `TextVectorization` object with the default settings but let's customize it a little bit for our own use case.\n","\n","In particular, let's set values for `max_tokens` and `output_sequence_length`.\n","\n","For `max_tokens` (the number of words in the vocabulary), multiples of 10,000 (`10,000`, `20,000`, `30,000`) or the exact number of unique words in your text (e.g. `32,179`) are common values.\n","\n","For our use case, we'll use `10,000`.\n","\n","And for the `output_sequence_length` we'll use the average number of tokens per Tweet in the training set. But first, we'll need to find it."]},{"cell_type":"code","source":["# Find average number of tokens (words) in training Tweets\n","round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IrkA9lSVDEDa","executionInfo":{"status":"ok","timestamp":1641217021632,"user_tz":300,"elapsed":6,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"6fd734a5-55f7-4808-c4e4-e72e6fafb92e"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["15"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"AFGTRcw8Hv7R"},"source":["Now let's create another `TextVectorization` object using our custom parameters."]},{"cell_type":"code","source":["# Setup text vectorization with custom variables\n","max_vocab_length = 10000 # max number of words to have in my vocabulary\n","max_length = 15 # max length of a sequence (e.g. how many words of the tweet does the model see?)\n","\n","text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n","                                    output_mode=\"int\",\n","                                    output_sequence_length=max_length)"],"metadata":{"id":"Maauf2LRE63X","executionInfo":{"status":"ok","timestamp":1641217021632,"user_tz":300,"elapsed":5,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BSWycfB3H3wV"},"source":["Beautiful!\n","\n","To map our `TextVectorization` instance `text_vectorizer` to our data, we can call the `adapt()` method on it whilst passing it our training text."]},{"cell_type":"code","source":["# Fit the text vectorizer to the training text\n","text_vectorizer.adapt(train_sentences)"],"metadata":{"id":"QXO0yW-yFuwH","executionInfo":{"status":"ok","timestamp":1641217022588,"user_tz":300,"elapsed":961,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Syh0VB9wIHUq"},"source":["Training data mapped! Let's try our `text_vectorizer` on a custom sentence (one similar to what you might see in the training data)."]},{"cell_type":"code","source":["# Create sample sentence & tokenize it\n","sample_sentence = \"I for one, welcome our new robot overlords!\"\n","text_vectorizer([sample_sentence])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bn8MRacyG36u","executionInfo":{"status":"ok","timestamp":1641217022955,"user_tz":300,"elapsed":10,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"33ad520a-eb62-400a-b437-b969865962b8"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n","array([[   8,   10,   61, 1569,  103,   50, 9028,    1,    0,    0,    0,\n","           0,    0,    0,    0]])>"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"M0RmAeplIW57"},"source":["Wonderful, it seems we've got a way to turn our text into numbers (in this case, word-level tokenization). Notice the 0's at the end of the returned tensor, this is because we set `output_sequence_length=15`, meaning no matter the size of the sequence we pass to `text_vectorizer`, it always returns a sequence with a length of 15.\n","\n","How about we try our `text_vectorizer` on a few random sentences?"]},{"cell_type":"code","source":["# Choose a random sentence from the training dataset & tokenize it\n","random_sentence = random.choice(train_sentences)\n","print(f\"Original text:\\n{random_sentence}\\\n","      \\n\\nVectorized version:\")\n","text_vectorizer([random_sentence])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AK2_otsWHJ_x","executionInfo":{"status":"ok","timestamp":1641217022955,"user_tz":300,"elapsed":7,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"16bef8ba-cb7d-4ebc-a8ed-1be9823f3e9b"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Original text:\n","Mom is hijacking my account to earn MCR STATUS!!!  Get your own account snort!  \n","http://t.co/jST5hAUK35 #FlavorChargedTea      \n","\n","Vectorized version:\n"]},{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n","array([[ 881,    9,  510,   13, 1156,    5,    1,    1, 2282,   52,   33,\n","         730, 1156, 8344,    1]])>"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"PErGKRbPJF89"},"source":["Looking good!\n","\n","Finally, we can check the unique tokens in our vocabulary using the `get_vocabulary()` method."]},{"cell_type":"code","source":["# Get the unique words in the vocabulary\n","words_in_vocab = text_vectorizer.get_vocabulary()\n","top_5_words = words_in_vocab[:5] # most common tokens (notice the [UNK] token for \"unknown\" words)\n","bottom_5_words = words_in_vocab[-5:] # least common tokens (like nfdasofakafi)\n","print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n","print(f\"Top 5 most common words: {top_5_words}\")\n","print(f\"Bottom 5 leas common words: {bottom_5_words}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0evYoV97Inef","executionInfo":{"status":"ok","timestamp":1641217022956,"user_tz":300,"elapsed":6,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"2bdb1b03-d343-406c-9219-6ccb24027c0c"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of words in vocab: 10000\n","Top 5 most common words: ['', '[UNK]', 'the', 'a', 'in']\n","Bottom 5 leas common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"]}]},{"cell_type":"markdown","metadata":{"id":"AHyCdO0uEOkH"},"source":["### Creating an Embedding using an Embedding Layer\n","\n","We've got a way to map our text to numbers. How about we go a step further and turn those numbers into an embedding?\n","\n","The powerful thing about an embedding is it can be learned during training. This means rather than just being static (e.g. `1` = I, `2` = love, `3` = TensorFlow), a word's numeric representation can be improved as a model goes through data samples.\n","\n","We can see what an embedding of a word looks like by using the [`tf.keras.layers.Embedding`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding) layer. \n","\n","The main parameters we're concerned about here are:\n","* `input_dim` - The size of the vocabulary (e.g. `len(text_vectorizer.get_vocabulary()`).\n","* `output_dim` - The size of the output embedding vector, for example, a value of `100` outputs a  feature vector of size 100 for each word.\n","* `embeddings_initializer` - How to initialize the embeddings matrix, default is `\"uniform\"` which randomly initalizes embedding matrix with uniform distribution. This can be changed for using pre-learned embeddings.\n","* `input_length` - Length of sequences being passed to embedding layer.\n","\n","Knowing these, let's make an embedding layer."]},{"cell_type":"code","source":["tf.random.set_seed(42)\n","from tensorflow.keras import layers\n","\n","embedding = layers.Embedding(input_dim=max_vocab_length, # set input shape\n","                             output_dim=128, # set size of embedding vector \n","                             embeddings_initializer=\"uniform\", # default, initialize randomly\n","                             input_length=max_length, # how long is each input\n","                             name=\"embedding_1\")\n","\n","embedding"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wYCBmflpL1q4","executionInfo":{"status":"ok","timestamp":1641217023287,"user_tz":300,"elapsed":337,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"720e8cd0-1b61-47b6-fb55-f22a3bf6b729"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<keras.layers.embeddings.Embedding at 0x7f7f7da63890>"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"bfML_IzlSUho"},"source":["Excellent, notice how `embedding` is a TensoFlow layer? This is important because we can use it as part of a model, meaning its parameters (word representations) can be updated and improved as the model learns.\n","\n","How about we try it out on a sample sentence?"]},{"cell_type":"code","source":["# Get a random sentence from training set\n","random_sentence = random.choice(train_sentences)\n","print(f\"Original text:\\n{random_sentence}\\\n","      \\n\\nEmbedded version:\")\n","\n","# Embed the random sentence (turn it into numberical representation)\n","sample_embed = embedding(text_vectorizer([random_sentence])) \n","sample_embed "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B3MrytR2M9jS","executionInfo":{"status":"ok","timestamp":1641217023287,"user_tz":300,"elapsed":4,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"7d63bdbf-ec64-4853-9681-319fb6742ddc"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Original text:\n","Study: Wider Variety of Therapies Could Help Vets Troops With PTSD | http://t.co/g0q0bzBjli http://t.co/ExYr6c5QPu via @Militarydotcom      \n","\n","Embedded version:\n"]},{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n","array([[[ 0.00251568,  0.0410994 , -0.03502933, ..., -0.0494392 ,\n","          0.02543285, -0.00709542],\n","        [ 0.0413156 , -0.00101626, -0.01129375, ..., -0.01703794,\n","          0.0362303 , -0.04230295],\n","        [-0.03130306, -0.02456138, -0.02510688, ...,  0.01766601,\n","         -0.01109115, -0.04077469],\n","        ...,\n","        [ 0.03977952, -0.03782602, -0.03646283, ...,  0.00236253,\n","          0.03332629,  0.02803668],\n","        [-0.00234969, -0.03639654,  0.04625012, ...,  0.03042295,\n","          0.04206065, -0.00413541],\n","        [ 0.03977952, -0.03782602, -0.03646283, ...,  0.00236253,\n","          0.03332629,  0.02803668]]], dtype=float32)>"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"e4Sn8o9pTBE5"},"source":["Each token in the sentence gets turned into a length 128 feature vector."]},{"cell_type":"code","source":["# Check out a single token's embedding\n","sample_embed[0][0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-NdOckhJNjfy","executionInfo":{"status":"ok","timestamp":1641217023287,"user_tz":300,"elapsed":3,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"7ff4ab2f-959a-47e9-91a9-4233da11cfe3"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(128,), dtype=float32, numpy=\n","array([ 0.00251568,  0.0410994 , -0.03502933, -0.03746984, -0.03694709,\n","       -0.02135676, -0.00029679,  0.02923261,  0.00090107,  0.03777936,\n","       -0.02669307,  0.01482792,  0.01761786,  0.04228606,  0.04227184,\n","        0.04909452,  0.00098366,  0.00202692, -0.02455658,  0.00637667,\n","       -0.04993118,  0.00777268, -0.02915295,  0.03342659,  0.03730409,\n","       -0.01334142, -0.03220356, -0.02390089, -0.04012462, -0.02036563,\n","       -0.01465135,  0.01426473, -0.02358804,  0.02966883, -0.03670261,\n","       -0.00644165, -0.04250861, -0.04449922,  0.03367097, -0.04037292,\n","       -0.04579439, -0.03109083,  0.03873557, -0.04146742, -0.04147754,\n","       -0.04063972, -0.0195949 , -0.015127  , -0.00496349,  0.01719334,\n","        0.04381701, -0.0139233 , -0.00084601, -0.0330856 , -0.02258177,\n","       -0.04476675, -0.03196393,  0.00297247, -0.02436231,  0.04384098,\n","        0.02880572, -0.04239023, -0.01246227,  0.02258885,  0.03919392,\n","        0.00878453,  0.02360393,  0.01202244,  0.01166525,  0.00916995,\n","        0.01342324, -0.03901462, -0.00770741,  0.02506844,  0.02860541,\n","        0.02563336,  0.03141072, -0.0354524 ,  0.02545248,  0.03979031,\n","       -0.00638331,  0.01670588, -0.03030107, -0.0089635 , -0.03059189,\n","        0.00206434, -0.00557809, -0.03668486, -0.04509106, -0.00310941,\n","       -0.01535519,  0.04806954, -0.00677849, -0.01229459, -0.02191801,\n","        0.00361749, -0.0097929 ,  0.00705808,  0.00856239,  0.02909261,\n","        0.03012128, -0.03299168,  0.04873183,  0.00724014,  0.02835881,\n","        0.02981234, -0.01530832,  0.02136744,  0.00248694, -0.02930348,\n","        0.03463313, -0.02245514,  0.03285172, -0.0464429 , -0.02776855,\n","        0.03609714,  0.03592863, -0.04955422, -0.02693837, -0.01909826,\n","       -0.03850633,  0.03249416,  0.03942834,  0.03101995,  0.00060358,\n","       -0.0494392 ,  0.02543285, -0.00709542], dtype=float32)>"]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"Z0NTsDklR0xw"},"source":["These values might not mean much to us but they're what our computer sees each word as. When our model looks for patterns in different samples, these values will be updated as necessary.\n","\n","> üîë **Note:** The previous two concepts (tokenization and embeddings) are the foundation for many NLP tasks. So if you're not sure about anything, be sure to research and conduct your own experiments to further help your understanding."]},{"cell_type":"markdown","metadata":{"id":"ZJENUdF3F7Rn"},"source":["## Modelling a text dataset\n","\n","![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/08-inputs-and-outputs-with-shapes-and-models-were-going-to-build.png)\n","*Once you've got your inputs and outputs prepared, it's a matter of figuring out which machine learning model to build in between them to bridge the gap.*\n","\n","Now that we've got a way to turn our text data into numbers, we can start to build machine learning models to model it.\n","\n","To get plenty of practice, we're going to build a series of different models, each as its own experiment. We'll then compare the results of each model and see which one performed best.\n","\n","More specifically, we'll be building the following:\n","* **Model 0**: Naive Bayes (baseline)\n","* **Model 1**: Feed-forward neural network (dense model)\n","* **Model 2**: LSTM model\n","* **Model 3**: GRU model\n","* **Model 4**: Bidirectional-LSTM model\n","* **Model 5**: 1D Convolutional Neural Network\n","* **Model 6**: TensorFlow Hub Pretrained Feature Extractor\n","* **Model 7**: Same as model 6 with 10% of training data\n","\n","Model 0 is the simplest to acquire a baseline which we'll expect each other of the other deeper models to beat.\n","\n","Each experiment will go through the following steps:\n","* Construct the model\n","* Train the model\n","* Make predictions with the model\n","* Track prediction evaluation metrics for later comparison\n","\n","Let's get started."]},{"cell_type":"markdown","metadata":{"id":"q4i5BiQfF--y"},"source":["### Model 0: Getting a baseline\n","\n","As with all machine learning modelling experiments, it's important to create a baseline model so you've got a benchmark for future experiments to build upon.\n","\n","To create our baseline, we'll create a Scikit-Learn Pipeline using the TF-IDF (term frequency-inverse document frequency) formula to convert our words to numbers and then model them with the [Multinomial Naive Bayes algorithm](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB). This was chosen via referring to the [Scikit-Learn machine learning map](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html).\n","\n","> üìñ **Reading:** The ins and outs of TF-IDF algorithm is beyond the scope of this notebook, however, the curious reader is encouraged to check out the [Scikit-Learn documentation for more](https://scikit-learn.org/stable/modules/feature_extraction.html#tfidf-term-weighting)."]},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.pipeline import Pipeline\n","\n","# Create tokenization &  modeling pipeline\n","model_0 = Pipeline([\n","                    (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n","                    (\"clf\", MultinomialNB()) # model the text\n","])\n","\n","# Fit the pipeline to the training data\n","model_0.fit(train_sentences, train_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CzAGqDoEO6Sb","executionInfo":{"status":"ok","timestamp":1641217023785,"user_tz":300,"elapsed":500,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"8f4e51c3-17eb-4ffc-db2d-27b7f20c79fa"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"ybOvOuVJbNjg"},"source":["The benefit of using a shallow model like Multinomial Naive Bayes is that training is very fast.\n","\n","Let's evaluate our model and find our baseline metric."]},{"cell_type":"code","source":["baseline_score = model_0.score(val_sentences, val_labels)\n","print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Zgi1FdoRnjF","executionInfo":{"status":"ok","timestamp":1641217023786,"user_tz":300,"elapsed":5,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"86e5afdc-b359-4574-9d4c-f015e72a69db"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Our baseline model achieves an accuracy of: 79.27%\n"]}]},{"cell_type":"markdown","metadata":{"id":"hUv5dyuibf3M"},"source":["How about we make some predictions with our baseline model?"]},{"cell_type":"code","source":["# Make predictions\n","baseline_preds = model_0.predict(val_sentences)\n","baseline_preds[:20]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hj5CV94vSd4N","executionInfo":{"status":"ok","timestamp":1641217023786,"user_tz":300,"elapsed":4,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"892ac7fe-0dc0-4c8c-bae2-b09a411bd7e0"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"]},"metadata":{},"execution_count":26}]},{"cell_type":"markdown","metadata":{"id":"K354svk_bmdf"},"source":["### Creating an evaluation function for our model experiments\n","\n","We could evaluate these as they are but since we're going to be evaluating several models in the same way going forward, let's create a helper function which takes an array of predictions and ground truth labels and computes the following:\n","* Accuracy\n","* Precision\n","* Recall\n","* F1-score\n","\n","> üîë **Note:** Since we're dealing with a classification problem, the above metrics are the most appropriate. If we were working with a regression problem, other metrics such as MAE (mean absolute error) would be a better choice."]},{"cell_type":"code","source":["# Function to evaluate: accuracy, precision, recall, f1-score\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","\n","def calculate_results(y_true, y_pred):\n","  \"\"\"\n","  Calculates model accuracy, precision, recall, & f1 score of a binary classification model.\n","\n","  Args: \n","  -------\n","  y_true = true labels in the form of a 1D array\n","  y_pred = predicted labels in the form of a 1D array\n","\n","  Returns a dictionary of accuracy, precision, recall, f1-score.\n","  \"\"\"\n","  # Calculate model accuracy\n","  model_accuracy = accuracy_score(y_true, y_pred) * 100\n","  # Calculate model precision, recall & f1 score using \"weighted\" average\n","  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n","  model_results = {\"accuracy\": model_accuracy,\n","                   \"precision\": model_precision,\n","                   \"recall\": model_recall,\n","                   \"f1\": model_f1}\n","  return model_results"],"metadata":{"id":"mjs78AF8TE52","executionInfo":{"status":"ok","timestamp":1641217024108,"user_tz":300,"elapsed":326,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["# Get baseline results\n","baseline_results = calculate_results(y_true=val_labels,\n","                                     y_pred=baseline_preds)\n","baseline_results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i0hGhTiJYSPD","executionInfo":{"status":"ok","timestamp":1641217024108,"user_tz":300,"elapsed":5,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"56174d0d-cfa1-4ad3-82c0-054a848c2e19"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'accuracy': 79.26509186351706,\n"," 'f1': 0.7862189758049549,\n"," 'precision': 0.8111390004213173,\n"," 'recall': 0.7926509186351706}"]},"metadata":{},"execution_count":28}]},{"cell_type":"markdown","metadata":{"id":"noRJNm7dGNyh"},"source":["### Model 1: A simple dense model\n","\n","The first \"deep\" model we're going to build is a single layer dense model. In fact, it's barely going to have a single layer. \n","\n","It'll take our text and labels as input, tokenize the text, create an embedding, find the average of the embedding (using Global Average Pooling) and then pass the average through a fully connected layer with one output unit and a sigmoid activation function.\n","\n","If the previous sentence sounds like a mouthful, it'll make sense when we code it out (remember, if in doubt, code it out).\n","\n","And since we're going to be building a number of TensorFlow deep learning models, we'll import our `create_tensorboard_callback()` function from `helper_functions.py` to keep track of the results of each. "]},{"cell_type":"code","source":["# Create tensorboard callback (need to create a new one for each model)\n","from helper_functions import create_tensorboard_callback\n","\n","# Create directory to dave TensorBoard logs\n","SAVE_DIR = \"model_logs\""],"metadata":{"id":"NWPWFi85Yltw","executionInfo":{"status":"ok","timestamp":1641217024108,"user_tz":300,"elapsed":4,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":29,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Pib8hHtu7vt1"},"source":["Now we've got a TensorBoard callback function ready to go, let's build our first deep model."]},{"cell_type":"code","source":["# Build model with the Functional API\n","from tensorflow.keras import layers\n","inputs = layers.Input(shape=(1,), dtype=\"string\") # inputs are 1-dimensional strings\n","x = text_vectorizer(inputs) # turn the input text into numbers\n","x = embedding(x) # create an embedding of the numerized numbers\n","x = layers.GlobalAveragePooling1D()(x) # lower the dimensionality of the embedding (What happens if I run the model withought this layer? A: it dosen't fit because the different input shapes)\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x) # create the output layer, want binary outputs so use sigmoid activation\n","model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\") # construct the model"],"metadata":{"id":"akJD-eyZZUmZ","executionInfo":{"status":"ok","timestamp":1641217024109,"user_tz":300,"elapsed":4,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":30,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JYzsu36Y8JUe"},"source":["Looking good. Our model takes a 1-dimensional string as input (in our case, a Tweet), it then tokenizes the string using `text_vectorizer` and creates an embedding using `embedding`.\n","\n","We then (optionally) pool the outputs of the embedding layer to reduce the dimensionality of the tensor we pass to the output layer.\n","\n","> üõ† **Exercise:** Try building `model_1` with and without a `GlobalAveragePooling1D()` layer after the `embedding` layer. What happens? Why do you think this is?\n","\n","Finally, we pass the output of the pooling layer to a dense layer with sigmoid activation (we use sigmoid since our problem is binary classification).\n","\n","Before we can fit our model to the data, we've got to compile it. Since we're working with binary classification, we'll use `\"binary_crossentropy\"` as our loss function and the Adam optimizer."]},{"cell_type":"code","source":["# Compile model\n","model_1.compile(loss=\"binary_crossentropy\",\n","                optimizer=tf.keras.optimizers.Adam(),\n","                metrics=[\"accuracy\"])"],"metadata":{"id":"qAEis08Xarjh","executionInfo":{"status":"ok","timestamp":1641217024109,"user_tz":300,"elapsed":4,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":31,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"crgltz1O9uku"},"source":["Model compiled. Let's get a summary."]},{"cell_type":"code","source":["# Get a summary of the model\n","model_1.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8dlqQiG3bKHq","executionInfo":{"status":"ok","timestamp":1641217024109,"user_tz":300,"elapsed":4,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"2b68da8f-638b-43d8-9213-0517c0520c7e"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_1_dense\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 1)]               0         \n","                                                                 \n"," text_vectorization_1 (TextV  (None, 15)               0         \n"," ectorization)                                                   \n","                                                                 \n"," embedding_1 (Embedding)     (None, 15, 128)           1280000   \n","                                                                 \n"," global_average_pooling1d (G  (None, 128)              0         \n"," lobalAveragePooling1D)                                          \n","                                                                 \n"," dense (Dense)               (None, 1)                 129       \n","                                                                 \n","=================================================================\n","Total params: 1,280,129\n","Trainable params: 1,280,129\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"bH0JLyR09yYt"},"source":["Most of the trainable parameters are contained within the embedding layer. Recall we created an embedding of size 128 (`output_dim=128`) for a vocabulary of size 10,000 (`input_dim=10000`), hence the 1,280,000 trainable parameters.\n","\n","Alright, our model is compiled, let's fit it to our training data for 5 epochs. We'll also pass our TensorBoard callback function to make sure our model's training metrics are logged."]},{"cell_type":"code","source":["# Fit the model\n","model_1_history = model_1.fit(train_sentences, # input sentences can be list of strings due to built-in text preprocessing model\n","                              train_labels,\n","                              epochs=5,\n","                              validation_data=(val_sentences, val_labels),\n","                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n","                                                                     experiment_name=\"simple_dense_model\")])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qa71CEZ_bQBv","executionInfo":{"status":"ok","timestamp":1641217066602,"user_tz":300,"elapsed":42496,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"dafd5982-0aad-436b-e793-99ee15d65e75"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving TensorBoard log files to: model_logs/simple_dense_model/20220103-133702\n","Epoch 1/5\n","215/215 [==============================] - 8s 29ms/step - loss: 0.6094 - accuracy: 0.6916 - val_loss: 0.5357 - val_accuracy: 0.7572\n","Epoch 2/5\n","215/215 [==============================] - 6s 26ms/step - loss: 0.4410 - accuracy: 0.8189 - val_loss: 0.4691 - val_accuracy: 0.7848\n","Epoch 3/5\n","215/215 [==============================] - 5s 26ms/step - loss: 0.3463 - accuracy: 0.8605 - val_loss: 0.4590 - val_accuracy: 0.7900\n","Epoch 4/5\n","215/215 [==============================] - 6s 26ms/step - loss: 0.2848 - accuracy: 0.8923 - val_loss: 0.4641 - val_accuracy: 0.7927\n","Epoch 5/5\n","215/215 [==============================] - 6s 26ms/step - loss: 0.2380 - accuracy: 0.9118 - val_loss: 0.4767 - val_accuracy: 0.7874\n"]}]},{"cell_type":"markdown","metadata":{"id":"kZR5_j9C_LW-"},"source":["Nice! Since we're using such a simple model, each epoch processes very quickly.\n","\n","Let's check our model's performance on the validation set."]},{"cell_type":"code","source":["# Check the results\n","model_1.evaluate(val_sentences, val_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pzGtTXRNcRwu","executionInfo":{"status":"ok","timestamp":1641217066602,"user_tz":300,"elapsed":15,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"b9ed39db-62b5-4da7-fa9f-97455c99848d"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 0s 3ms/step - loss: 0.4767 - accuracy: 0.7874\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.4766846001148224, 0.787401556968689]"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["embedding.weights"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"haDYyzWMcfB3","executionInfo":{"status":"ok","timestamp":1641217066603,"user_tz":300,"elapsed":11,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"6eedc11d-df1f-4cb8-acee-1453d6419727"},"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<tf.Variable 'embedding_1/embeddings:0' shape=(10000, 128) dtype=float32, numpy=\n"," array([[ 0.00073164,  0.01504797, -0.03425453, ..., -0.04403542,\n","         -0.01042278,  0.01876436],\n","        [ 0.04135864, -0.03945082, -0.03811938, ...,  0.00464735,\n","          0.03163553,  0.02928304],\n","        [ 0.00684034,  0.05363134, -0.00241555, ..., -0.07082174,\n","         -0.04750701,  0.01448254],\n","        ...,\n","        [-0.03301444, -0.0052493 , -0.04209725, ...,  0.02028764,\n","          0.00308807,  0.02215792],\n","        [ 0.00692342,  0.05942352, -0.01975194, ..., -0.06199061,\n","         -0.01018394,  0.03510419],\n","        [-0.03723461,  0.06267188, -0.07451147, ..., -0.02367217,\n","         -0.08643329,  0.01742156]], dtype=float32)>]"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["embed_weights = model_1.get_layer(\"embedding_1\").get_weights()[0]\n","print(embed_weights.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MKVxSHksciok","executionInfo":{"status":"ok","timestamp":1641217066977,"user_tz":300,"elapsed":8,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"28c588d1-734a-4d90-8247-12afc785679f"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["(10000, 128)\n"]}]},{"cell_type":"markdown","metadata":{"id":"I9dg2aba_VxK"},"source":["And since we tracked our model's training logs with TensorBoard, how about we visualize them?\n","\n","We can do so by uploading our TensorBoard log files (contained in the `model_logs` directory) to [TensorBoard.dev](https://tensorboard.dev/).\n","\n","> üîë **Note:** Remember, whatever you upload to TensorBoard.dev becomes public. If there are training logs you don't want to share, don't upload them."]},{"cell_type":"code","source":["# View tensorboard logs to transfer learning modelling experiments (should be 4 models)\n","# Upload TensorBoard dev records\n","#!tensorboard dev upload --logdir ./model_logs \\\n","#    --name \"First deep model on text data\" \\\n","#    --description \"Trying a dense model with an embedding layer\" \\\n","#    --one_shot # exits the uploader when upload has finished"],"metadata":{"id":"ye-CYSfAc1p7","executionInfo":{"status":"ok","timestamp":1641217066978,"user_tz":300,"elapsed":6,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["# If you need to remove previous experiments, you can do so using the following command\n","# !tensorboard dev delete --experiment_id EXPERIMENT_ID_TO_DELETE"],"metadata":{"id":"KAlrf1Bwdtkp","executionInfo":{"status":"ok","timestamp":1641217066978,"user_tz":300,"elapsed":5,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":38,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PkinGcjQ_yI9"},"source":["The TensorBoard.dev experiment for our first deep model can be viewed here: https://tensorboard.dev/experiment/5d1Xm10aT6m6MgyW3HAGfw/\n","\n","![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/08-tensorboard-dense-model-training-curves.png)\n","\n","*What the training curves of our model look like on TensorBoard. From looking at the curves can you tell if the model is overfitting or underfitting?*\n","\n","Beautiful! Those are some colorful training curves. Would you say the model is overfitting or underfitting?\n","\n","We've built and trained our first deep model, the next step is to make some predictions with it."]},{"cell_type":"code","source":["# Make predictions (these come back in the form of probabilities)\n","model_1_pred_probs = model_1.predict(val_sentences)\n","model_1_pred_probs[:10] # only print out the first 10 prediction probabilities"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W6FpXXGceTFp","executionInfo":{"status":"ok","timestamp":1641217067310,"user_tz":300,"elapsed":337,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"6935bb34-da7e-40d5-8e44-039147c2de63"},"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.40488204],\n","       [0.7443311 ],\n","       [0.997895  ],\n","       [0.10889998],\n","       [0.11143529],\n","       [0.93556094],\n","       [0.9134594 ],\n","       [0.99253446],\n","       [0.9715681 ],\n","       [0.26570344]], dtype=float32)"]},"metadata":{},"execution_count":39}]},{"cell_type":"markdown","metadata":{"id":"YWU5e1NLAKJ9"},"source":["Since our final layer uses a sigmoid activation function, we get our predictions back in the form of probabilities.\n","\n","To convert them to prediction classes, we'll use `tf.round()`, meaning prediction probabilities below 0.5 will be rounded to 0 and those above 0.5 will be rounded to 1.\n","\n","> üîë **Note:** In practice, the output threshold of a sigmoid prediction probability doesn't necessarily have to 0.5. For example, through testing, you may find that a cut off of 0.25 is better for your chosen evaluation metrics. A common example of this threshold cutoff is the [precision-recall tradeoff](https://www.machinelearningaptitude.com/topics/machine-learning/what-is-precision-recall-tradeoff/#:~:text=precision%2Drecall%20tradeoff%20occur%20due,the%20threshold%20of%20the%20classifier.&text=When%20threshold%20is%20decreased%20to,but%20precision%20decreases%20to%200.4.)."]},{"cell_type":"code","source":["# Turn prediction probabilities into single-dimension tensor of floats\n","model_1_preds = tf.squeeze(tf.round(model_1_pred_probs)) # squeeze removes single dimensions\n","model_1_preds[:20]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dFxT3vP-fJ4e","executionInfo":{"status":"ok","timestamp":1641217067311,"user_tz":300,"elapsed":5,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"90d41428-8c1b-42d2-eb0e-68d41e7bc0bf"},"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(20,), dtype=float32, numpy=\n","array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n","       0., 0., 1.], dtype=float32)>"]},"metadata":{},"execution_count":40}]},{"cell_type":"markdown","metadata":{"id":"Zc3ryY0yCHcI"},"source":["Now we've got our model's predictions in the form of classes, we can use our `calculate_results()` function to compare them to the ground truth validation labels."]},{"cell_type":"code","source":["# Calculate model_1 metrics\n","model_1_results = calculate_results(y_true=val_labels,\n","                                    y_pred=model_1_preds)\n","model_1_results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"94pzzt-Ff-JJ","executionInfo":{"status":"ok","timestamp":1641217067311,"user_tz":300,"elapsed":4,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"b09c688c-18c2-4a3f-a950-797f921a0ebf"},"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'accuracy': 78.74015748031496,\n"," 'f1': 0.7846966492209201,\n"," 'precision': 0.7914920592553047,\n"," 'recall': 0.7874015748031497}"]},"metadata":{},"execution_count":41}]},{"cell_type":"markdown","metadata":{"id":"gnkK6Uc7CYlX"},"source":["How about we compare our first deep model to our baseline model?"]},{"cell_type":"code","source":["# Is the simple Keras model better than the baseline?\n","import numpy as np\n","np.array(list(model_1_results.values())) > np.array(list(baseline_results.values()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7jv8RCH6j_Vc","executionInfo":{"status":"ok","timestamp":1641217067311,"user_tz":300,"elapsed":4,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"76ff9b86-ca9c-4694-e379-c59d705f557c"},"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([False, False, False, False])"]},"metadata":{},"execution_count":42}]},{"cell_type":"markdown","metadata":{"id":"lUINrCdRCpFf"},"source":["Since we'll be doing this kind of comparison (baseline compared to new model) quite a few times, let's create a function to help us out. "]},{"cell_type":"code","source":["# Create a helper function to compare my baseline results to the results of the new model\n","def compare_baseline_to_new_results(baseline_results, new_model_results):\n","  for key, value in baseline_results.items():\n","    print(f\"Baseline {key}: {value:.2f}, New {key}: {new_model_results[key]:.2f}, Difference: {new_model_results[key]-value:.2f}\")\n","\n","compare_baseline_to_new_results(baseline_results=baseline_results,\n","                                new_model_results=model_1_results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OyWGxWELkjIX","executionInfo":{"status":"ok","timestamp":1641217067311,"user_tz":300,"elapsed":3,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"01a51612-6624-45f6-8529-01857fdadcf4"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["Baseline accuracy: 79.27, New accuracy: 78.74, Difference: -0.52\n","Baseline precision: 0.81, New precision: 0.79, Difference: -0.02\n","Baseline recall: 0.79, New recall: 0.79, Difference: -0.01\n","Baseline f1: 0.79, New f1: 0.78, Difference: -0.00\n"]}]},{"cell_type":"markdown","metadata":{"id":"6e-1LuioSLAM"},"source":["## Visualizing learned embeddings\n","\n","Our first model (`model_1`) contained an embedding layer (`embedding`) which learned a way of representing words as feature vectors by passing over the training data.\n","\n","Hearing this for the first few times may sound confusing.\n","\n","So to further help understand what a text embedding is, let's visualize the embedding our model learned.\n","\n","To do so, let's remind ourselves of the words in our vocabulary.\n"]},{"cell_type":"code","source":["# Get the vocabulary from the text vectorization layer\n","words_in_vocab = text_vectorizer.get_vocabulary()\n","len(words_in_vocab), words_in_vocab[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7lyhXX4ml1Yg","executionInfo":{"status":"ok","timestamp":1641217067721,"user_tz":300,"elapsed":413,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"0df1c726-431f-496c-b839-ce3492b224d4"},"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"]},"metadata":{},"execution_count":44}]},{"cell_type":"markdown","metadata":{"id":"KzmAPJXQEx6r"},"source":["And now let's get our embedding layer's weights (these are the numerical representations of each word)."]},{"cell_type":"code","source":["model_1.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZubrWJE3mRkP","executionInfo":{"status":"ok","timestamp":1641217067722,"user_tz":300,"elapsed":4,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"7bd727bd-b4af-42d0-d198-f1cb3c32b2c0"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_1_dense\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 1)]               0         \n","                                                                 \n"," text_vectorization_1 (TextV  (None, 15)               0         \n"," ectorization)                                                   \n","                                                                 \n"," embedding_1 (Embedding)     (None, 15, 128)           1280000   \n","                                                                 \n"," global_average_pooling1d (G  (None, 128)              0         \n"," lobalAveragePooling1D)                                          \n","                                                                 \n"," dense (Dense)               (None, 1)                 129       \n","                                                                 \n","=================================================================\n","Total params: 1,280,129\n","Trainable params: 1,280,129\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# Get the weight matrix of embedding layer\n","# (these are the numerical patterns between the text in the training dataset the model has learned)\n","embed_weights = model_1.get_layer(\"embedding_1\").get_weights()[0]\n","print(embed_weights.shape) # same size as vocab size & embedding_dim (each word is a embedding_dim size vector)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4pBWBK-nmWbw","executionInfo":{"status":"ok","timestamp":1641217067722,"user_tz":300,"elapsed":3,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"4986ec2d-3587-4b60-b5ae-7bd0dbb0f330"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["(10000, 128)\n"]}]},{"cell_type":"markdown","metadata":{"id":"jzOJhJHPW1ju"},"source":["Now we've got these two objects, we can use the [Embedding Projector tool](http://projector.tensorflow.org/_) to visualize our embedding. \n","\n","To use the Embedding Projector tool, we need two files:\n","* The embedding vectors (same as embedding weights).\n","* The meta data of the embedding vectors (the words they represent - our vocabulary).\n","\n","Right now, we've got of these files as Python objects. To download them to file, we're going to [use the code example available on the TensorFlow word embeddings tutorial page](https://www.tensorflow.org/tutorials/text/word_embeddings#retrieve_the_trained_word_embeddings_and_save_them_to_disk).\n"]},{"cell_type":"code","source":["# Code below is adapted from: https://www.tensorflow.org/tutorials/text/word_embeddings#retrieve_the_trained_word_embeddings_and_save_them_to_disk\n","import io\n","\n","# create output writers\n","out_v = io.open(\"embedding_vectors.tsv\", \"w\", encoding=\"utf-8\")\n","out_m = io.open(\"embedding_metadata.tsv\", \"w\", encoding=\"utf-8\")\n","\n","# Write embedding vectors & words to a file\n","for num, word in enumerate(words_in_vocab):\n","  if num == 0:\n","    continue # skip padding token\n","  vec = embed_weights[num]\n","  out_m.write(word + \"\\n\") # write words to file\n","  out_v.write(\"\\t\".join([str(x) for x in vec]) + \"\\n\") # write corresponding word vector to file\n","out_v.close()\n","out_m.close()\n","\n","# Download files locally to upload to Embedding Projector\n","try:\n","  from google.colab import files\n","except ImportError:\n","  pass\n","else:\n","  files.download(\"embedding_vectors.tsv\")\n","  files.download(\"embedding_metadata.tsv\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"QPMtsIXJm-4G","executionInfo":{"status":"ok","timestamp":1641217069836,"user_tz":300,"elapsed":2117,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"fe0d9e04-2b12-479a-9940-5901740310a9"},"execution_count":47,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_2b182ccb-ce11-4d24-a1d0-d622ad0afdc4\", \"embedding_vectors.tsv\", 15391233)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_fc61524f-8849-4ec7-a221-55ea69a2bd04\", \"embedding_metadata.tsv\", 80388)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"BVM7ifzpZaxJ"},"source":["Once you've downloaded the embedding vectors and metadata, you can visualize them using Embedding Vector tool:\n","1. Go to  http://projector.tensorflow.org/\n","2. Click on \"Load data\"\n","3. Upload the two files you downloaded (`embedding_vectors.tsv` and `embedding_metadata.tsv`)\n","4. Explore\n","5. Optional: You can share the data you've created by clicking \"Publish\"\n","\n","What do you find?\n","\n","Are words with similar meanings close together?\n","\n","Remember, they might not be. The embeddings we downloaded are how our model interprets words, not necessarily how we interpret them. \n","\n","Also, since the embedding has been learned purely from Tweets, it may contain some strange values as Tweets are a very unique style of natural language.\n","\n","> ü§î **Question:** Do you have to visualize embeddings every time?\n","\n","No. Although helpful for gaining an intuition of what natural language embeddings are, it's not completely necessary. Especially as the dimensions of your vocabulary and embeddings grow, trying to comprehend them would become an increasingly difficult task."]},{"cell_type":"markdown","metadata":{"id":"AcRdDiEtGQj4"},"source":["## Recurrent Neural Networks (RNN's)\n","\n","For our next series of modelling experiments we're going to be using a special kind of neural network called a **Recurrent Neural Network (RNN)**.\n","\n","The premise of an RNN is simple: use information from the past to help you with the future (this is where the term recurrent comes from). In other words, take an input (`X`) and compute an output (`y`) based on all previous inputs.\n","\n","This concept is especially helpful when dealing with sequences such as passages of natural language text (such as our Tweets).\n","\n","For example, when you read this sentence, you take into context the previous words when deciphering the meaning of the current word dog. \n","\n","See what happened there? \n","\n","I put the word \"dog\" at the end which is a valid word but it doesn't make sense in the context of the rest of the sentence.\n","\n","When an RNN looks at a sequence of text (already in numerical form), the patterns it learns are continually updated based on the order of the sequence. \n","\n","For a simple example, take two sentences:\n","1. Massive earthquake last week, no?\n","2. No massive earthquake last week.\n","\n","Both contain exactly the same words but have different meaning. The order of the words determines the meaning (one could argue punctuation marks also dictate the meaning but for simplicity sake, let's stay focused on the words).\n","\n","Recurrent neural networks can be used for a number of sequence-based problems:\n","* **One to one:** one input, one output, such as image classification.\n","* **One to many:** one input, many outputs, such as image captioning (image input, a sequence of text as caption output).\n","* **Many to one:** many inputs, one outputs, such as text classification (classifying a Tweet as real diaster or not real diaster).\n","* **Many to many:** many inputs, many outputs, such as machine translation (translating English to Spanish) or speech to text (audio wave as input, text as output).\n","\n","When you come across RNN's in the wild, you'll most likely come across variants of the following:\n","* Long short-term memory cells (LSTMs).\n","* Gated recurrent units (GRUs).\n","* Bidirectional RNN's (passes forward and backward along a sequence, left to right and right to left).\n","\n","Going into the details of each these is beyond the scope of this notebook (we're going to focus on using them instead), the main thing you should know for now is that they've proven very effective at modelling sequences.\n","\n","For a deeper understanding of what's happening behind the scenes of the code we're about to write, I'd recommend the following resources:\n","\n","> üìñ **Resources:**\n","> * [MIT Deep Learning Lecture on Recurrent Neural Networks](https://youtu.be/SEnXr6v2ifU) - explains the background of recurrent neural networks and introduces LSTMs.\n","> * [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) by Andrej Karpathy - demonstrates the power of RNN's with examples generating various sequences.\n","> * [Understanding LSTMs](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) by Chris Olah - an in-depth (and technical) look at the mechanics of the LSTM cell, possibly the most popular RNN building block.\n"]},{"cell_type":"markdown","metadata":{"id":"tDERKwP_XWro"},"source":["### Model 2: LSTM\n","\n","With all this talk of what RNN's are and what they're good for, I'm sure you're eager to build one.\n","\n","We're going to start with an LSTM-powered RNN.\n","\n","To harness the power of the LSTM cell (LSTM cell and LSTM layer are often used interchangably) in TensorFlow, we'll use [`tensorflow.keras.layers.LSTM()`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM).\n","\n","![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/08-RNN-architecture-coloured-block-edition.png)\n","*Coloured block example of the structure of an recurrent neural network.*\n","\n","Our model is going to take on a very similar structure to `model_1`:\n","\n","```\n","Input (text) -> Tokenize -> Embedding -> Layers -> Output (label probability)\n","```\n","\n","The main difference will be that we're going to add an LSTM layer between our embedding and output.\n","\n","And to make sure we're not getting reusing trained embeddings (this would involve data leakage between models, leading to an uneven comparison later on), we'll create another embedding layer (`model_2_embedding`) for our model. The `text_vectorizer` layer can be reused since it doesn't get updated during training.\n","\n","> üîë **Note:** The reason we use a new embedding layer for each model is since the embedding layer is a *learned* representation of words (as numbers), if we were to use the same embedding layer (`embedding_1`) for each model, we'd be mixing what one model learned with the next. And because we want to compare our models later on, starting them with their own embedding layer each time is a better idea."]},{"cell_type":"code","source":["# Set random seed for reproducability & create new embedding layer\n","tf.random.set_seed(42)\n","from tensorflow.keras import layers\n","model_2_embedding = layers.Embedding(input_dim=max_vocab_length,\n","                                     output_dim=128,\n","                                     embeddings_initializer=\"uniform\",\n","                                     input_length=max_length,\n","                                     name=\"embedding_2\")\n","\n","# Create LSTM model\n","inputs = layers.Input(shape=(1,), dtype=\"string\")\n","x = text_vectorizer(inputs)\n","x = model_2_embedding(x)\n","print(x.shape)\n","# x = layersLSTM(64, return_sequence=True)(x) # return vector for each word in the Tweet (RNN cells can be stacked as long as return_sequence=True)\n","x = layers.LSTM(64)(x) # Return vector for whole sequence\n","print(x.shape)\n","# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer on top of output of LSTM cell\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A2amK1qqnSP_","executionInfo":{"status":"ok","timestamp":1641217070543,"user_tz":300,"elapsed":711,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"9a6f2be7-9162-4002-efc3-af6f420fc15c"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["(None, 15, 128)\n","(None, 64)\n"]}]},{"cell_type":"markdown","metadata":{"id":"e1wfTARuwWDg"},"source":["> üîë **Note:** Reading the documentation for the [TensorFlow LSTM layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM), you'll find a plethora of parameters. Many of these have been tuned to make sure they compute as fast as possible. The main ones you'll be looking to adjust are `units` (number of hidden units) and `return_sequences` (set this to `True` when stacking LSTM or other recurrent layers).\n","\n","Now we've got our LSTM model built, let's compile it using `\"binary_crossentropy\"` loss and the Adam optimizer."]},{"cell_type":"code","source":["# Compile model\n","model_2.compile(loss=\"binary_crossentropy\",\n","                optimizer=tf.keras.optimizers.Adam(),\n","                metrics=[\"accuracy\"])"],"metadata":{"id":"xzsfXZH_3Y0R","executionInfo":{"status":"ok","timestamp":1641217070543,"user_tz":300,"elapsed":8,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":49,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I2e_t8RFxgXG"},"source":["And before we fit our model to the data, let's get a summary."]},{"cell_type":"code","source":["model_2.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kSCmTf_737La","executionInfo":{"status":"ok","timestamp":1641217070543,"user_tz":300,"elapsed":8,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"08cf0fa5-cbd3-4c4e-f5c0-9bb68642d886"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_2_LSTM\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 1)]               0         \n","                                                                 \n"," text_vectorization_1 (TextV  (None, 15)               0         \n"," ectorization)                                                   \n","                                                                 \n"," embedding_2 (Embedding)     (None, 15, 128)           1280000   \n","                                                                 \n"," lstm (LSTM)                 (None, 64)                49408     \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 1,329,473\n","Trainable params: 1,329,473\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"S5NLw3wD0aMz"},"source":["Looking good! You'll notice a fair few more trainable parameters within our LSTM layer than `model_1`. \n","\n","If you'd like to know where this number comes from, I recommend going through the above resources as well the following on calculating the number of parameters in an LSTM cell:\n","* [Stack Overflow answer to calculate the number of parameters in an LSTM cell](https://stackoverflow.com/questions/38080035/how-to-calculate-the-number-of-parameters-of-an-lstm-network) by Marcin Mo≈ºejko\n","* [Calculating number of parameters in a LSTM unit and layer](https://medium.com/@priyadarshi.cse/calculating-number-of-parameters-in-a-lstm-unit-layer-7e491978e1e4) by Shridhar Priyadarshi\n","\n","Now our first RNN model's compiled let's fit it to our training data, validating it on the validation data and tracking its training parameters using our TensorBoard callback."]},{"cell_type":"code","source":["# Fit model\n","model_2_history = model_2.fit(train_sentences,\n","                              train_labels,\n","                              epochs=5,\n","                              validation_data=(val_sentences, val_labels),\n","                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n","                                                                     \"LSTM\")])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7uf9LCl73_jH","executionInfo":{"status":"ok","timestamp":1641217107546,"user_tz":300,"elapsed":37010,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"a5a1bf22-1cbe-43a1-e3f3-ee67be3a6bc3"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving TensorBoard log files to: model_logs/LSTM/20220103-133749\n","Epoch 1/5\n","215/215 [==============================] - 9s 30ms/step - loss: 0.5100 - accuracy: 0.7416 - val_loss: 0.4566 - val_accuracy: 0.7822\n","Epoch 2/5\n","215/215 [==============================] - 6s 27ms/step - loss: 0.3176 - accuracy: 0.8717 - val_loss: 0.5138 - val_accuracy: 0.7756\n","Epoch 3/5\n","215/215 [==============================] - 6s 30ms/step - loss: 0.2201 - accuracy: 0.9152 - val_loss: 0.5858 - val_accuracy: 0.7677\n","Epoch 4/5\n","215/215 [==============================] - 6s 28ms/step - loss: 0.1556 - accuracy: 0.9428 - val_loss: 0.6041 - val_accuracy: 0.7743\n","Epoch 5/5\n","215/215 [==============================] - 10s 46ms/step - loss: 0.1076 - accuracy: 0.9594 - val_loss: 0.8746 - val_accuracy: 0.7507\n"]}]},{"cell_type":"markdown","metadata":{"id":"1gikGe_Z16PP"},"source":["Nice! We've got our first trained RNN model using LSTM cells. Let's make some predictions with it.\n","\n","The same thing will happen as before, due to the sigmoid activiation function in the final layer, when we call the `predict()` method on our model, it'll return prediction probabilities rather than classes."]},{"cell_type":"code","source":["# Make predictions on the validation dataset\n","model_2_pred_probs = model_2.predict(val_sentences)\n","model_2_pred_probs.shape, model_2_pred_probs[:10] # see the first 10"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TulwChI34nG4","executionInfo":{"status":"ok","timestamp":1641217108382,"user_tz":300,"elapsed":839,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"aafd5c6f-d384-4fe8-d14c-9d833f9b66d9"},"execution_count":52,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((762, 1), array([[0.00712615],\n","        [0.7873689 ],\n","        [0.9996376 ],\n","        [0.05679163],\n","        [0.00258216],\n","        [0.99962384],\n","        [0.9217019 ],\n","        [0.9997994 ],\n","        [0.99949545],\n","        [0.66457486]], dtype=float32))"]},"metadata":{},"execution_count":52}]},{"cell_type":"markdown","metadata":{"id":"fQ6ope-ddpOo"},"source":["We can turn these prediction probabilities into prediction classes by rounding to the nearest integer (by default, prediction probabilities under 0.5 will go to 0 and those over 0.5 will go to 1)."]},{"cell_type":"code","source":["# Round out predictions & reduce to 1-dim array\n","model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n","model_2_preds[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oXWaqLFj5Ja_","executionInfo":{"status":"ok","timestamp":1641217108855,"user_tz":300,"elapsed":475,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"3678f92e-8640-4eeb-8099-47c563e52945"},"execution_count":53,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"]},"metadata":{},"execution_count":53}]},{"cell_type":"markdown","metadata":{"id":"zTBy4poXd_7p"},"source":["Beautiful, now let's use our `caculate_results()` function to evaluate our LSTM model and our `compare_baseline_to_new_results()` function to compare it to our baseline model."]},{"cell_type":"code","source":["# Calculate LSTM model results\n","model_2_results = calculate_results(y_true=val_labels,\n","                                    y_pred=model_2_preds)\n","model_2_results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z_zfgV8y5kii","executionInfo":{"status":"ok","timestamp":1641217108855,"user_tz":300,"elapsed":3,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"5dbeb847-b56b-4bb7-8be5-f4c6b1c0541a"},"execution_count":54,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'accuracy': 75.06561679790026,\n"," 'f1': 0.7489268622514025,\n"," 'precision': 0.7510077975908164,\n"," 'recall': 0.7506561679790026}"]},"metadata":{},"execution_count":54}]},{"cell_type":"code","source":["# Compare model 2 to my baseline\n","compare_baseline_to_new_results(baseline_results, model_2_results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ufa60yDF5-q4","executionInfo":{"status":"ok","timestamp":1641217108855,"user_tz":300,"elapsed":2,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"f3b31473-8494-4855-a6b4-c329a5bc1bd3"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["Baseline accuracy: 79.27, New accuracy: 75.07, Difference: -4.20\n","Baseline precision: 0.81, New precision: 0.75, Difference: -0.06\n","Baseline recall: 0.79, New recall: 0.75, Difference: -0.04\n","Baseline f1: 0.79, New f1: 0.75, Difference: -0.04\n"]}]},{"cell_type":"markdown","metadata":{"id":"Q0pAtADt8ju7"},"source":["### Model 3: GRU\n","\n","Another popular and effective RNN component is the GRU or gated recurrent unit.\n","\n","The GRU cell has similar features to an LSTM cell but has less parameters.\n","\n","> üìñ **Resource:** A full explanation of the GRU cell is beyond the scope of this noteook but I'd suggest the following resources to learn more:\n","* [Gated Recurrent Unit](https://en.wikipedia.org/wiki/Gated_recurrent_unit) Wikipedia page\n","* [Understanding GRU networks](https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be) by Simeon Kostadinov\n","\n","To use the GRU cell in TensorFlow, we can call the [`tensorflow.keras.layers.GRU()`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU) class.\n","\n","The architecture of the GRU-powered model will follow the same structure we've been using:\n","\n","```\n","Input (text) -> Tokenize -> Embedding -> Layers -> Output (label probability)\n","```\n","\n","Again, the only difference will be the layer(s) we use between the embedding and the output."]},{"cell_type":"code","source":["# Set random seed to 42 for repeatability & create new embedding layer\n","tf.random.set_seed(42)\n","from tensorflow.keras import layers\n","model_3_embedding = layers.Embedding(input_dim=max_vocab_length,\n","                                     output_dim=128,\n","                                     embeddings_initializer=\"uniform\",\n","                                     input_length=max_length,\n","                                     name=\"embedding_3\")\n","\n","# Build an RNN using the GRU cell\n","inputs = layers.Input(shape=(1,), dtype=\"string\")\n","x = text_vectorizer(inputs)\n","x = model_3_embedding(x)\n","# x = layers.GRU(64, return_sequences=True) # stacking recurrent cells  requires return_sequences=True\n","x = layers.GRU(64)(x)\n","# x = layers.Dense(64, activation=\"relu\")(x) # optional recurrent layer after GRU cell\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"],"metadata":{"id":"Q8nZwfVv6Oyp","executionInfo":{"status":"ok","timestamp":1641217109228,"user_tz":300,"elapsed":375,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":56,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JLT5maFWhKH1"},"source":["TensorFlow makes it easy to use powerful components such as the GRU cell in our models. And now our third model is built, let's compile it, just as before."]},{"cell_type":"code","source":["# Compile GRU model\n","model_3.compile(loss=\"binary_crossentropy\",\n","                optimizer=tf.keras.optimizers.Adam(),\n","                metrics=[\"accuracy\"])"],"metadata":{"id":"gfYvUnlc-7jE","executionInfo":{"status":"ok","timestamp":1641217109229,"user_tz":300,"elapsed":10,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":57,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yvnksvkmha2A"},"source":["What does a summary of our model look like?"]},{"cell_type":"code","source":["# Get the summary of the GRU model\n","model_3.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OHLwt3Le_S6N","executionInfo":{"status":"ok","timestamp":1641217109229,"user_tz":300,"elapsed":10,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"92b04e6a-1bfe-4f07-fc68-b52f3f301fbe"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_3_GRU\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_3 (InputLayer)        [(None, 1)]               0         \n","                                                                 \n"," text_vectorization_1 (TextV  (None, 15)               0         \n"," ectorization)                                                   \n","                                                                 \n"," embedding_3 (Embedding)     (None, 15, 128)           1280000   \n","                                                                 \n"," gru (GRU)                   (None, 64)                37248     \n","                                                                 \n"," dense_2 (Dense)             (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 1,317,313\n","Trainable params: 1,317,313\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"KcXzKqgXhdez"},"source":["Notice the difference in number of trainable parameters between `model_2` (LSTM) and `model_3` (GRU). The difference comes from the LSTM cell having more trainable parameters than the GRU cell.\n","\n","We'll fit our model just as we've been doing previously. We'll also track our models results using our `create_tensorboard_callback()` function."]},{"cell_type":"code","source":["# Fit the model\n","model_3_history = model_3.fit(train_sentences,\n","                              train_labels,\n","                              epochs=5,\n","                              validation_data=(val_sentences, val_labels),\n","                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"GRU\")])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fj06EDZx_akf","executionInfo":{"status":"ok","timestamp":1641217147096,"user_tz":300,"elapsed":37872,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"b7c97e2b-e317-495e-fd60-2ee65f3ec497"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving TensorBoard log files to: model_logs/GRU/20220103-133828\n","Epoch 1/5\n","215/215 [==============================] - 14s 46ms/step - loss: 0.5242 - accuracy: 0.7314 - val_loss: 0.4553 - val_accuracy: 0.7769\n","Epoch 2/5\n","215/215 [==============================] - 6s 26ms/step - loss: 0.3195 - accuracy: 0.8694 - val_loss: 0.4937 - val_accuracy: 0.7808\n","Epoch 3/5\n","215/215 [==============================] - 6s 27ms/step - loss: 0.2197 - accuracy: 0.9181 - val_loss: 0.5607 - val_accuracy: 0.7743\n","Epoch 4/5\n","215/215 [==============================] - 6s 28ms/step - loss: 0.1599 - accuracy: 0.9441 - val_loss: 0.6220 - val_accuracy: 0.7782\n","Epoch 5/5\n","215/215 [==============================] - 6s 27ms/step - loss: 0.1221 - accuracy: 0.9584 - val_loss: 0.6205 - val_accuracy: 0.7677\n"]}]},{"cell_type":"markdown","metadata":{"id":"hM4mQj1Sh7Gn"},"source":["Due to the optimized default settings of the GRU cell in TensorFlow, training doesn't take long at all. \n","\n","Time to make some predictions on the validation samples."]},{"cell_type":"code","source":["# Make predictions on the validation data\n","model_3_pred_probs = model_3.predict(val_sentences)\n","model_3_pred_probs.shape, model_3_pred_probs[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S45d7xD4AI54","executionInfo":{"status":"ok","timestamp":1641217147728,"user_tz":300,"elapsed":643,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"da3a84e3-6307-4fe8-c39f-2430aa1f4a42"},"execution_count":60,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((762, 1), array([[0.333252  ],\n","        [0.877412  ],\n","        [0.9980252 ],\n","        [0.11561716],\n","        [0.01235956],\n","        [0.9925637 ],\n","        [0.6214276 ],\n","        [0.9981333 ],\n","        [0.9982377 ],\n","        [0.50181204]], dtype=float32))"]},"metadata":{},"execution_count":60}]},{"cell_type":"markdown","metadata":{"id":"hasS7dzRiYQh"},"source":["Again we get an array of prediction probabilities back which we can convert to prediction classes by rounding them."]},{"cell_type":"code","source":["# Convert prediction probs into prediction classes\n","model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n","model_3_preds[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ORznO-YtB6Zx","executionInfo":{"status":"ok","timestamp":1641217147729,"user_tz":300,"elapsed":8,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"969eb66e-81d7-44b9-b6cd-aa3879665f2f"},"execution_count":61,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"]},"metadata":{},"execution_count":61}]},{"cell_type":"markdown","metadata":{"id":"_7yAgh-viglB"},"source":["Now we've got predicted classes, let's evaluate them against the ground truth labels."]},{"cell_type":"code","source":["# Calculate model_3 results\n","model_3_results = calculate_results(y_true=val_labels,\n","                                    y_pred=model_3_preds)\n","model_3_results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tVj5N_3-CSQF","executionInfo":{"status":"ok","timestamp":1641217147729,"user_tz":300,"elapsed":5,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"54496d8a-23ef-4858-fa44-89c9f1c88527"},"execution_count":62,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'accuracy': 76.77165354330708,\n"," 'f1': 0.7667932666650168,\n"," 'precision': 0.7675450859410361,\n"," 'recall': 0.7677165354330708}"]},"metadata":{},"execution_count":62}]},{"cell_type":"markdown","metadata":{"id":"o9t7wcALiuRk"},"source":["Finally we can compare our GRU model's results to our baseline."]},{"cell_type":"code","source":["# Compare GRU to baseline\n","compare_baseline_to_new_results(baseline_results, model_3_results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S-55UOBWCluf","executionInfo":{"status":"ok","timestamp":1641217147729,"user_tz":300,"elapsed":4,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"06aecc0b-a1e5-411b-a842-fed5aa073d61"},"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["Baseline accuracy: 79.27, New accuracy: 76.77, Difference: -2.49\n","Baseline precision: 0.81, New precision: 0.77, Difference: -0.04\n","Baseline recall: 0.79, New recall: 0.77, Difference: -0.02\n","Baseline f1: 0.79, New f1: 0.77, Difference: -0.02\n"]}]},{"cell_type":"markdown","metadata":{"id":"oLm6r4nQ-Wdr"},"source":["### Model 4: Bidirectonal RNN model \n","\n","Look at us go! We've already built two RNN's with GRU and LSTM cells. Now we're going to look into another kind of RNN, the bidirectional RNN.\n","\n","A standard RNN will process a sequence from left to right, where as a bidirectional RNN will process the sequence from left to right and then again from right to left.\n","\n","Intuitively, this can be thought of as if you were reading a sentence for the first time in the normal fashion (left to right) but for some reason it didn't make sense so you traverse back through the words and go back over them again (right to left).\n","\n","In practice, many sequence models often see and improvement in performance when using bidirectional RNN's.\n","\n","However, this improvement in performance often comes at the cost of longer training times and increased model parameters (since the model goes left to right and right to left, the number of trainable parameters doubles).\n","\n","Okay enough talk, let's build a bidirectional RNN.\n","\n","Once again, TensorFlow helps us out by providing the [`tensorflow.keras.layers.Bidirectional`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Bidirectional) class. We can use the `Bidirectional` class to wrap our existing RNNs, instantly making them bidirectional."]},{"cell_type":"code","source":["# Set random seed & create new embedding layer\n","tf.random.set_seed(42)\n","from tensorflow.keras import layers\n","model_4_embedding = layers.Embedding(input_dim=max_vocab_length,\n","                                     output_dim=128,\n","                                     embeddings_initializer=\"uniform\",\n","                                     input_length=max_length,\n","                                     name=\"embedding_4\")\n","\n","# Build a Bidirectional RNN in TensorFlow\n","inputs = layers.Input(shape=(1,), dtype=\"string\")\n","x = text_vectorizer(inputs)\n","x = model_4_embedding(x)\n","# x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x) return_sequence=True to stack RNN layers\n","x = layers.Bidirectional(layers.LSTM(64))(x) # has double the parameters of a normal LSTM layer\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_Bidirectional\")\n"],"metadata":{"id":"TkwGR3pjCw9x","executionInfo":{"status":"ok","timestamp":1641217148469,"user_tz":300,"elapsed":742,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":64,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9Hm5cwmNm-g4"},"source":["> üîë **Note:** You can use the `Bidirectional` wrapper on any RNN cell in TensorFlow. For example, `layers.Bidirectional(layers.GRU(64))` creates a bidirectional GRU cell.\n","\n","Our bidirectional model is built, let's compile it."]},{"cell_type":"code","source":["# Compile the model\n","model_4.compile(loss=\"binary_crossentropy\",\n","                optimizer=tf.keras.optimizers.Adam(),\n","                metrics=[\"accuracy\"])"],"metadata":{"id":"YXzDkSolaVqJ","executionInfo":{"status":"ok","timestamp":1641217148470,"user_tz":300,"elapsed":6,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":65,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NtpYyjsbnEwN"},"source":["And of course, we'll check out a summary."]},{"cell_type":"code","source":["# Get a summary of my bidirectional model\n","model_4.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L3Jn_HNpa0vI","executionInfo":{"status":"ok","timestamp":1641217148470,"user_tz":300,"elapsed":5,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"e893fd85-ee38-436c-9bf0-a3a771407916"},"execution_count":66,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_4_Bidirectional\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_4 (InputLayer)        [(None, 1)]               0         \n","                                                                 \n"," text_vectorization_1 (TextV  (None, 15)               0         \n"," ectorization)                                                   \n","                                                                 \n"," embedding_4 (Embedding)     (None, 15, 128)           1280000   \n","                                                                 \n"," bidirectional (Bidirectiona  (None, 128)              98816     \n"," l)                                                              \n","                                                                 \n"," dense_3 (Dense)             (None, 1)                 129       \n","                                                                 \n","=================================================================\n","Total params: 1,378,945\n","Trainable params: 1,378,945\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"TvItfzeZnIE-"},"source":["Notice the increased number of trainable parameters in `model_4` (bidirectional LSTM) compared to `model_2` (regular LSTM). This is due to the bidirectionality we added to our RNN.\n","\n","Time to fit our bidirectional model and track its performance."]},{"cell_type":"code","source":["# Fit the model (takes longer due to bidirectional layers)\n","model_4_history = model_4.fit(train_sentences,\n","                              train_labels,\n","                              epochs=5,\n","                              validation_data=(val_sentences, val_labels),\n","                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"bidirectional_RNN\")])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CAyEh24ta9nb","executionInfo":{"status":"ok","timestamp":1641217233760,"user_tz":300,"elapsed":85293,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"d9794217-b2c7-40cc-f6e2-87d2eb90b48c"},"execution_count":67,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving TensorBoard log files to: model_logs/bidirectional_RNN/20220103-133907\n","Epoch 1/5\n","215/215 [==============================] - 12s 40ms/step - loss: 0.5093 - accuracy: 0.7481 - val_loss: 0.4606 - val_accuracy: 0.7795\n","Epoch 2/5\n","215/215 [==============================] - 9s 42ms/step - loss: 0.3135 - accuracy: 0.8708 - val_loss: 0.5144 - val_accuracy: 0.7690\n","Epoch 3/5\n","215/215 [==============================] - 8s 37ms/step - loss: 0.2150 - accuracy: 0.9178 - val_loss: 0.5626 - val_accuracy: 0.7677\n","Epoch 4/5\n","215/215 [==============================] - 12s 54ms/step - loss: 0.1523 - accuracy: 0.9469 - val_loss: 0.6365 - val_accuracy: 0.7769\n","Epoch 5/5\n","215/215 [==============================] - 14s 63ms/step - loss: 0.1083 - accuracy: 0.9639 - val_loss: 0.6509 - val_accuracy: 0.7664\n"]}]},{"cell_type":"markdown","metadata":{"id":"zkt8GVRHoJz6"},"source":["Due to the bidirectionality of our model we see a slight increase in training time.\n","\n","Not to worry, it's not too dramatic of an increase.\n","\n","Let's make some predictions with it."]},{"cell_type":"code","source":["# Make predictions with bidirectional RNN on the validation data\n","model_4_pred_probs = model_4.predict(val_sentences)\n","model_4_pred_probs[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tRTD5kbdbpCO","executionInfo":{"status":"ok","timestamp":1641217234690,"user_tz":300,"elapsed":939,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"a3bf131a-c105-4ec1-e2d3-f46337c65a0f"},"execution_count":68,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.04000095],\n","       [0.82792675],\n","       [0.99842227],\n","       [0.13531172],\n","       [0.00311336],\n","       [0.9922074 ],\n","       [0.9552848 ],\n","       [0.9994564 ],\n","       [0.99898285],\n","       [0.28141806]], dtype=float32)"]},"metadata":{},"execution_count":68}]},{"cell_type":"markdown","metadata":{"id":"L_9HmNIYobDB"},"source":["And we'll convert them to prediction classes and evaluate them against the ground truth labels and baseline model."]},{"cell_type":"code","source":["# Convert prediction probabilities into labels\n","model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n","model_4_preds[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MKIddgEtcx5B","executionInfo":{"status":"ok","timestamp":1641217234691,"user_tz":300,"elapsed":10,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"15b7211c-47e6-41f0-efd1-219266f783ff"},"execution_count":69,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"]},"metadata":{},"execution_count":69}]},{"cell_type":"code","source":["# Calculate bidirectional RNN model results\n","model_4_results = calculate_results(val_labels, model_4_preds)\n","model_4_results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"83-yPrpmdS2N","executionInfo":{"status":"ok","timestamp":1641217234691,"user_tz":300,"elapsed":7,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"159118df-dd12-40e3-fa5f-57cfa0ef4dff"},"execution_count":70,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'accuracy': 76.64041994750657,\n"," 'f1': 0.7651213533864446,\n"," 'precision': 0.7665895370389821,\n"," 'recall': 0.7664041994750657}"]},"metadata":{},"execution_count":70}]},{"cell_type":"code","source":["# Check to see how the bidirectional model preforms against the baseline\n","compare_baseline_to_new_results(baseline_results, model_4_results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HAdA4mbudlLv","executionInfo":{"status":"ok","timestamp":1641217234691,"user_tz":300,"elapsed":6,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"26e11271-1d7b-4fcf-baf3-09a0bdb99e95"},"execution_count":71,"outputs":[{"output_type":"stream","name":"stdout","text":["Baseline accuracy: 79.27, New accuracy: 76.64, Difference: -2.62\n","Baseline precision: 0.81, New precision: 0.77, Difference: -0.04\n","Baseline recall: 0.79, New recall: 0.77, Difference: -0.03\n","Baseline f1: 0.79, New f1: 0.77, Difference: -0.02\n"]}]},{"cell_type":"markdown","metadata":{"id":"wcvt_7emuKlR"},"source":["## Convolutional Neural Networks for Text\n","\n","You might've used convolutional neural networks (CNNs) for images before but they can also be used for sequences.\n","\n","The main difference between using CNNs for images and sequences is the shape of the data. Images come in 2-dimensions (height x width) where as sequences are often 1-dimensional (a string of text).\n","\n","So to use CNNs with sequences, we use a 1-dimensional convolution instead of a 2-dimensional convolution.\n","\n","A typical CNN architecture for sequences will look like the following: \n","\n","```\n","Inputs (text) -> Tokenization -> Embedding -> Layers -> Outputs (class probabilities)\n","```\n","\n","You might be thinking \"that just looks like the architecture layout we've been using for the other models...\"\n","\n","And you'd be right.\n","\n","The difference again is in the layers component. Instead of using an LSTM or GRU cell, we're going to use a [`tensorflow.keras.layers.Conv1D()`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv1D) layer followed by a [`tensorflow.keras.layers.GlobablMaxPool1D()`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalMaxPool1D) layer.\n","\n","> üìñ **Resource:** The intuition here is explained succinctly in the paper [*Understanding Convolutional Neural Networks for Text Classification*](https://www.aclweb.org/anthology/W18-5408.pdf), where they state that CNNs classify text through the following steps:\n","1. 1-dimensional convolving filters are used as ngram detectors, each filter specializing in a closely-related family of ngrams (an ngram is a collection of n-words, for example, an ngram of 5 might result in \"hello, my name is Daniel\").\n","2. Max-pooling over time extracts the relevant ngrams for making a decision.\n","3. The rest of the network classifies the text based on this information.\n","\n","> \n"]},{"cell_type":"markdown","metadata":{"id":"lgXEorf9GWY1"},"source":["### Model 5: Conv1D\n","\n","Before we build a full 1-dimensional CNN model, let's see a 1-dimensional convolutional layer (also called a **temporal convolution**) in action.\n","\n","We'll first create an embedding of a sample of text and experiment passing it through a `Conv1D()` layer and `GlobalMaxPool1D()` layer."]},{"cell_type":"code","source":["# Test out the embedding, 1D convolutional & max pooling\n","embedding_test = embedding(text_vectorizer([\"this is a test sentence\"])) # Turn this sentence into embedding\n","conv_1d = layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\") # convolve over test sequence 5 words at a time\n","conv_1d_output = conv_1d(embedding_test) # pass embedding through iD convolutional layer\n","max_pool = layers.GlobalMaxPool1D()\n","max_pool_output = max_pool(conv_1d_output) # get the most important features\n","embedding_test.shape, conv_1d_output.shape, max_pool_output.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GvR1rv0Cd7A2","executionInfo":{"status":"ok","timestamp":1641217234692,"user_tz":300,"elapsed":7,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"c44499d2-6d43-4a67-ab65-ad8e81f93311"},"execution_count":72,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(TensorShape([1, 15, 128]), TensorShape([1, 11, 32]), TensorShape([1, 32]))"]},"metadata":{},"execution_count":72}]},{"cell_type":"markdown","metadata":{"id":"-WzTeShEemJ2"},"source":["Notice the output shapes of each layer.\n","\n","The embedding has an output shape dimension of the parameters we set it to (`input_length=15` and `output_dim=128`).\n","\n","The 1-dimensional convolutional layer has an output which has been compressed inline with its parameters. And the same goes for the max pooling layer output.\n","\n","Our text starts out as a string but gets converted to a feature vector of length 64 through various transformation steps (from tokenization to embedding to 1-dimensional convolution to max pool).\n","\n","Let's take a peak at what each of these transformations looks like."]},{"cell_type":"code","source":["# See the outputs of each layer\n","embedding_test[:1], conv_1d_output[:1], max_pool_output[:1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AUXeX_Nkgs8s","executionInfo":{"status":"ok","timestamp":1641217234692,"user_tz":300,"elapsed":6,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"6ef202c0-a84c-456e-f1e4-f5f63496744b"},"execution_count":73,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n"," array([[[ 0.02534916, -0.03109057,  0.00285617, ..., -0.00783162,\n","          -0.02685577, -0.04434136],\n","         [-0.0658626 ,  0.09451495, -0.01477603, ..., -0.00657782,\n","          -0.0423879 ,  0.07777893],\n","         [-0.04803651, -0.00709754, -0.02330894, ..., -0.01807334,\n","           0.02351035,  0.02676385],\n","         ...,\n","         [ 0.00073164,  0.01504797, -0.03425453, ..., -0.04403542,\n","          -0.01042278,  0.01876436],\n","         [ 0.00073164,  0.01504797, -0.03425453, ..., -0.04403542,\n","          -0.01042278,  0.01876436],\n","         [ 0.00073164,  0.01504797, -0.03425453, ..., -0.04403542,\n","          -0.01042278,  0.01876436]]], dtype=float32)>,\n"," <tf.Tensor: shape=(1, 11, 32), dtype=float32, numpy=\n"," array([[[0.08324988, 0.00648715, 0.        , 0.03983571, 0.        ,\n","          0.01144423, 0.00416252, 0.02288385, 0.        , 0.00900975,\n","          0.        , 0.        , 0.03401771, 0.06408267, 0.08103719,\n","          0.00409016, 0.01579616, 0.        , 0.07930174, 0.        ,\n","          0.        , 0.        , 0.14525089, 0.        , 0.        ,\n","          0.        , 0.03682069, 0.06534278, 0.        , 0.        ,\n","          0.05094636, 0.        ],\n","         [0.        , 0.05387188, 0.        , 0.11491337, 0.        ,\n","          0.        , 0.162371  , 0.        , 0.        , 0.00171238,\n","          0.14336716, 0.        , 0.        , 0.        , 0.        ,\n","          0.01197944, 0.        , 0.        , 0.13551354, 0.00401044,\n","          0.1030985 , 0.09445545, 0.08390276, 0.        , 0.04213047,\n","          0.04487596, 0.06560449, 0.        , 0.0227268 , 0.        ,\n","          0.        , 0.        ],\n","         [0.03683233, 0.04895752, 0.        , 0.15324758, 0.        ,\n","          0.        , 0.        , 0.        , 0.        , 0.        ,\n","          0.        , 0.0465033 , 0.00496452, 0.07349393, 0.01608639,\n","          0.        , 0.02779119, 0.        , 0.08080545, 0.01403154,\n","          0.        , 0.03768804, 0.10382751, 0.        , 0.03361667,\n","          0.        , 0.02577581, 0.0014034 , 0.        , 0.        ,\n","          0.03211504, 0.        ],\n","         [0.00887842, 0.10450961, 0.        , 0.06974545, 0.02328697,\n","          0.        , 0.04052219, 0.        , 0.        , 0.02733745,\n","          0.08674347, 0.        , 0.        , 0.06129848, 0.02007272,\n","          0.        , 0.        , 0.        , 0.03364249, 0.        ,\n","          0.04525369, 0.05219691, 0.06375685, 0.        , 0.        ,\n","          0.00774411, 0.00273442, 0.        , 0.        , 0.00499653,\n","          0.        , 0.        ],\n","         [0.        , 0.02369048, 0.        , 0.0582763 , 0.05297656,\n","          0.        , 0.        , 0.        , 0.        , 0.        ,\n","          0.01719728, 0.02936819, 0.00466114, 0.06879897, 0.01944812,\n","          0.01585551, 0.01294555, 0.        , 0.06866515, 0.        ,\n","          0.00623799, 0.03514046, 0.02407502, 0.        , 0.05979812,\n","          0.        , 0.01170122, 0.        , 0.        , 0.        ,\n","          0.04444926, 0.        ],\n","         [0.03544889, 0.        , 0.        , 0.05054991, 0.06105448,\n","          0.        , 0.00997431, 0.01403009, 0.        , 0.01680709,\n","          0.0314852 , 0.0388938 , 0.        , 0.07710699, 0.00590967,\n","          0.        , 0.00263043, 0.        , 0.08935817, 0.        ,\n","          0.        , 0.05331144, 0.05227914, 0.        , 0.06658379,\n","          0.01881718, 0.02448674, 0.        , 0.        , 0.        ,\n","          0.02008448, 0.        ],\n","         [0.03544889, 0.        , 0.        , 0.05054991, 0.06105448,\n","          0.        , 0.00997431, 0.01403009, 0.        , 0.01680709,\n","          0.0314852 , 0.0388938 , 0.        , 0.07710699, 0.00590967,\n","          0.        , 0.00263043, 0.        , 0.08935817, 0.        ,\n","          0.        , 0.05331144, 0.05227914, 0.        , 0.06658379,\n","          0.01881718, 0.02448674, 0.        , 0.        , 0.        ,\n","          0.02008448, 0.        ],\n","         [0.03544889, 0.        , 0.        , 0.05054991, 0.06105448,\n","          0.        , 0.00997431, 0.01403009, 0.        , 0.01680709,\n","          0.0314852 , 0.0388938 , 0.        , 0.07710699, 0.00590967,\n","          0.        , 0.00263043, 0.        , 0.08935817, 0.        ,\n","          0.        , 0.05331144, 0.05227914, 0.        , 0.06658379,\n","          0.01881718, 0.02448674, 0.        , 0.        , 0.        ,\n","          0.02008448, 0.        ],\n","         [0.03544889, 0.        , 0.        , 0.05054991, 0.06105448,\n","          0.        , 0.00997431, 0.01403009, 0.        , 0.01680709,\n","          0.0314852 , 0.0388938 , 0.        , 0.07710699, 0.00590967,\n","          0.        , 0.00263043, 0.        , 0.08935817, 0.        ,\n","          0.        , 0.05331144, 0.05227914, 0.        , 0.06658379,\n","          0.01881718, 0.02448674, 0.        , 0.        , 0.        ,\n","          0.02008448, 0.        ],\n","         [0.03544889, 0.        , 0.        , 0.05054991, 0.06105448,\n","          0.        , 0.00997431, 0.01403009, 0.        , 0.01680709,\n","          0.0314852 , 0.0388938 , 0.        , 0.07710699, 0.00590967,\n","          0.        , 0.00263043, 0.        , 0.08935817, 0.        ,\n","          0.        , 0.05331144, 0.05227914, 0.        , 0.06658379,\n","          0.01881718, 0.02448674, 0.        , 0.        , 0.        ,\n","          0.02008448, 0.        ],\n","         [0.03544889, 0.        , 0.        , 0.05054991, 0.06105448,\n","          0.        , 0.00997431, 0.01403009, 0.        , 0.01680709,\n","          0.0314852 , 0.0388938 , 0.        , 0.07710699, 0.00590967,\n","          0.        , 0.00263043, 0.        , 0.08935817, 0.        ,\n","          0.        , 0.05331144, 0.05227914, 0.        , 0.06658379,\n","          0.01881718, 0.02448674, 0.        , 0.        , 0.        ,\n","          0.02008448, 0.        ]]], dtype=float32)>,\n"," <tf.Tensor: shape=(1, 32), dtype=float32, numpy=\n"," array([[0.08324988, 0.10450961, 0.        , 0.15324758, 0.06105448,\n","         0.01144423, 0.162371  , 0.02288385, 0.        , 0.02733745,\n","         0.14336716, 0.0465033 , 0.03401771, 0.07710699, 0.08103719,\n","         0.01585551, 0.02779119, 0.        , 0.13551354, 0.01403154,\n","         0.1030985 , 0.09445545, 0.14525089, 0.        , 0.06658379,\n","         0.04487596, 0.06560449, 0.06534278, 0.0227268 , 0.00499653,\n","         0.05094636, 0.        ]], dtype=float32)>)"]},"metadata":{},"execution_count":73}]},{"cell_type":"markdown","metadata":{"id":"kMcrthJwg3B2"},"source":["Alright, we've seen the outputs of several components of a CNN for sequences, let's put them together and construct a full model, compile it (just as we've done with our other models) and get a summary. "]},{"cell_type":"code","source":["# Set random seed & create new embedding layer\n","tf.random.set_seed(42)\n","from tensorflow.keras import layers\n","model_5_embedding = layers.Embedding(input_dim=max_vocab_length,\n","                                     output_dim=128,\n","                                     embeddings_initializer=\"uniform\",\n","                                     input_length=max_length,\n","                                     name=\"embedding_5\")\n","\n","# Create 1-dimensional convolutional layer to model sequences\n","from tensorflow.keras import layers\n","inputs = layers.Input(shape=(1,), dtype=\"string\")\n","x = text_vectorizer(inputs)\n","x = model_5_embedding(x)\n","x = layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\")(x)\n","x = layers.GlobalMaxPool1D()(x)\n","x = layers.Dense(64, activation=\"relu\")(x) # optional Dense layer\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","model_5 = tf.keras.Model(inputs, outputs, name=\"model_5_Conv1D\")\n","\n","# Compile Conv1D model\n","model_5.compile(loss=\"binary_crossentropy\",\n","                optimizer=tf.keras.optimizers.Adam(),\n","                metrics=[\"accuracy\"])\n","\n","# Get the model's summary\n","model_5.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YYFWfI1whW3S","executionInfo":{"status":"ok","timestamp":1641217234987,"user_tz":300,"elapsed":301,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"96b7cca3-9969-40bf-8481-66c23fd40500"},"execution_count":74,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_5_Conv1D\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_5 (InputLayer)        [(None, 1)]               0         \n","                                                                 \n"," text_vectorization_1 (TextV  (None, 15)               0         \n"," ectorization)                                                   \n","                                                                 \n"," embedding_5 (Embedding)     (None, 15, 128)           1280000   \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 11, 32)            20512     \n","                                                                 \n"," global_max_pooling1d_1 (Glo  (None, 32)               0         \n"," balMaxPooling1D)                                                \n","                                                                 \n"," dense_4 (Dense)             (None, 64)                2112      \n","                                                                 \n"," dense_5 (Dense)             (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 1,302,689\n","Trainable params: 1,302,689\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"o1Y4BpMGh0jG"},"source":["Woohoo! Looking great! Notice how the number of trainable parameters for the 1-dimensional convolutional layer is similar to that of the LSTM layer in `model_2`.\n","\n","Let's fit our 1D CNN model to our text data. In line with previous experiments, we'll save its results using our `create_tensorboard_callback()` function."]},{"cell_type":"code","source":["# Fit the model\n","model_5_history = model_5.fit(train_sentences,\n","                              train_labels,\n","                              epochs=5,\n","                              validation_data=(val_sentences, val_labels),\n","                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n","                                                                     \"Conv1D\")])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wOwSq6hk03cA","executionInfo":{"status":"ok","timestamp":1641217254757,"user_tz":300,"elapsed":19773,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"09ee8b43-c1e3-4ba1-d0cc-e92b16797c59"},"execution_count":75,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving TensorBoard log files to: model_logs/Conv1D/20220103-134033\n","Epoch 1/5\n","215/215 [==============================] - 5s 19ms/step - loss: 0.5559 - accuracy: 0.7116 - val_loss: 0.4681 - val_accuracy: 0.7769\n","Epoch 2/5\n","215/215 [==============================] - 4s 18ms/step - loss: 0.3114 - accuracy: 0.8781 - val_loss: 0.5056 - val_accuracy: 0.7822\n","Epoch 3/5\n","215/215 [==============================] - 4s 18ms/step - loss: 0.1641 - accuracy: 0.9447 - val_loss: 0.5470 - val_accuracy: 0.7743\n","Epoch 4/5\n","215/215 [==============================] - 4s 17ms/step - loss: 0.1025 - accuracy: 0.9680 - val_loss: 0.6080 - val_accuracy: 0.7690\n","Epoch 5/5\n","215/215 [==============================] - 4s 17ms/step - loss: 0.0768 - accuracy: 0.9762 - val_loss: 0.6315 - val_accuracy: 0.7835\n"]}]},{"cell_type":"markdown","metadata":{"id":"d2up-1tLiXKD"},"source":["Nice! Thanks to GPU acceleration, our 1D convolutional model trains nice and fast. Let's make some predictions with it and evaluate them just as before."]},{"cell_type":"code","source":["# Make predictions with model_5\n","model_5_pred_probs = model_5.predict(val_sentences)\n","model_5_pred_probs[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lgM969-W1gwU","executionInfo":{"status":"ok","timestamp":1641217255114,"user_tz":300,"elapsed":359,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"d3d073d9-2655-4fa6-b16b-6d285570e04a"},"execution_count":76,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.26122957],\n","       [0.7062168 ],\n","       [0.9994906 ],\n","       [0.05618027],\n","       [0.00768995],\n","       [0.9955522 ],\n","       [0.89105517],\n","       [0.9951191 ],\n","       [0.99836326],\n","       [0.15751001]], dtype=float32)"]},"metadata":{},"execution_count":76}]},{"cell_type":"code","source":["# Conver model_5 prediction probabilites to labels\n","model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n","model_5_preds[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zj45zcyp10-W","executionInfo":{"status":"ok","timestamp":1641217255114,"user_tz":300,"elapsed":4,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"bfb7c358-1fa0-417c-d19f-eb576d9e019f"},"execution_count":77,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"]},"metadata":{},"execution_count":77}]},{"cell_type":"code","source":["# Calculate model_5 evaluation metrics\n","model_5_results = calculate_results(y_true=val_labels,\n","                                    y_pred=model_5_preds)\n","model_5_results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9FiuUoCx2IFY","executionInfo":{"status":"ok","timestamp":1641217255115,"user_tz":300,"elapsed":4,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"a5a31393-14b2-4029-e289-955ba5dc7107"},"execution_count":78,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'accuracy': 78.34645669291339,\n"," 'f1': 0.7807800582578167,\n"," 'precision': 0.7872123378365872,\n"," 'recall': 0.7834645669291339}"]},"metadata":{},"execution_count":78}]},{"cell_type":"code","source":["# Compare model_5 results to baseline\n","compare_baseline_to_new_results(baseline_results, model_5_results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LVkHqprT2jr_","executionInfo":{"status":"ok","timestamp":1641217255115,"user_tz":300,"elapsed":4,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"609480cf-654c-4471-ac5d-15aa8ebd17a4"},"execution_count":79,"outputs":[{"output_type":"stream","name":"stdout","text":["Baseline accuracy: 79.27, New accuracy: 78.35, Difference: -0.92\n","Baseline precision: 0.81, New precision: 0.79, Difference: -0.02\n","Baseline recall: 0.79, New recall: 0.78, Difference: -0.01\n","Baseline f1: 0.79, New f1: 0.78, Difference: -0.01\n"]}]},{"cell_type":"markdown","metadata":{"id":"g_roVSSRt-7h"},"source":["## Using Pretrained Embeddings (transfer learning for NLP)\n","\n","For all of the previous deep learning models we've built and trained, we've created and used our own embeddings from scratch each time.\n","\n","However, a common practice is to leverage pretrained embeddings through **transfer learning**. This is one of the main benefits of using deep models: being able to take what one (often larger) model has learned (often on a large amount of data) and adjust it for our own use case.\n","\n","For our next model, instead of using our own embedding layer, we're going to replace it with a pretrained embedding layer.\n","\n","More specifically, we're going to be using the [Universal Sentence Encoder](https://www.aclweb.org/anthology/D18-2029.pdf) from [TensorFlow Hub](https://tfhub.dev/google/universal-sentence-encoder/4) (a great resource containing a plethora of pretrained model resources for a variety of tasks).\n","\n","> üîë **Note:** There are many different pretrained text embedding options on TensorFlow Hub, however, some require different levels of text preprocessing than others. Best to experiment with a few and see which best suits your use case.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"R-NQ2MA5GZBo"},"source":["### Model 6: TensorFlow Hub Pretrained Sentence Encoder\n","\n","The main difference between the embedding layer we created and the Universal Sentence Encoder is that rather than create a word-level embedding, the Universal Sentence Encoder, as you might've guessed, creates a whole sentence-level embedding.\n","\n","Our embedding layer also outputs an a 128 dimensional vector for each word, where as, the Universal Sentence Encoder outputs a 512 dimensional vector for each sentence.\n","\n","![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/08-USE-tensorflow-hub-encoder-decoder-model.png)\n","*The feature extractor model we're building through the eyes of an **encoder/decoder** model.*\n","\n","> üîë **Note:** An **encoder** is the name for a model which converts raw data such as text into a numerical representation (feature vector), a **decoder** converts the numerical representation to a desired output.\n","\n","As usual, this is best demonstrated with an example.\n","\n","We can load in a TensorFlow Hub module using the [`hub.load()`](https://www.tensorflow.org/hub/api_docs/python/hub/load) method and passing it the target URL of the module we'd like to use, in our case, it's \"https://tfhub.dev/google/universal-sentence-encoder/4\".\n","\n","Let's load the Universal Sentence Encoder model and test it on a couple of sentences."]},{"cell_type":"code","source":["# Example of pretrained embedding with universal sentence encoder - https://tfhub.dev/google/universal-sentence-encoder/4\n","import tensorflow_hub as hub\n","embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\") # load Universal Sentance Encoder\n","embed_samples = embed([sample_sentence,\n","                       \"when you call the universal sentence encoder on a sentence, it converts it into 512 numbers.\"])\n","\n","print(embed_samples[0][:50])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b6ZQi0Aa201n","executionInfo":{"status":"ok","timestamp":1641217272343,"user_tz":300,"elapsed":17231,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"135a98ec-4821-4bae-994b-2604a13230d5"},"execution_count":80,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[ 0.00631518 -0.07459866 -0.06445549 -0.01485588 -0.06489823 -0.06002204\n"," -0.03152726 -0.05252237 -0.04773648  0.00989666  0.04352921  0.03561042\n","  0.04075905  0.08286662 -0.00972523 -0.05947517  0.00245964 -0.08763208\n","  0.02874581 -0.03670164 -0.03577576  0.01614941 -0.05441156  0.09408329\n","  0.02269614  0.03617552 -0.08607402  0.07365561  0.03822912  0.04681071\n","  0.02991436  0.01468298  0.00519688  0.02605805  0.00108473  0.00627405\n","  0.0376049   0.0175275   0.03458991  0.05407251  0.08296665 -0.0439896\n"," -0.00876843 -0.00102584 -0.06568834  0.0380155  -0.03399475 -0.0811411\n","  0.03733486  0.01152785], shape=(50,), dtype=float32)\n"]}]},{"cell_type":"code","source":["# Each sentence has been encoded into a 512 dim vector\n","embed_samples[0].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cQ-3H0Ev5h9h","executionInfo":{"status":"ok","timestamp":1641217272343,"user_tz":300,"elapsed":12,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"71873cd5-d96a-4d53-9cc2-8dfe9fcb515f"},"execution_count":81,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([512])"]},"metadata":{},"execution_count":81}]},{"cell_type":"markdown","metadata":{"id":"ZxYFDkGD-XjF"},"source":["Passing our sentences to the Universal Sentence Encoder (USE) encodes them from strings to 512 dimensional vectors, which make no sense to us but hopefully make sense to our machine learning models.\n","\n","Speaking of models, let's build one with the USE as our embedding layer.\n","\n","We can convert the TensorFlow Hub USE module into a Keras layer using the [`hub.KerasLayer`](https://www.tensorflow.org/hub/api_docs/python/hub/KerasLayer) class.\n","\n","> üîë **Note:** Due to the size of the USE TensorFlow Hub module, it may take a little while to download. Once it's downloaded though, it'll be cached and ready to use. And as with many TensorFlow Hub modules, there is a [\"lite\" version of the USE](https://tfhub.dev/google/universal-sentence-encoder-lite/2) which takes up less space but sacrifices some performance and requires more preprocessing steps. However, depending on your available compute power, the lite version may be better for your application use case."]},{"cell_type":"code","source":["# I can use this encoding layer in place of my text_vectorizer & embedding layer\n","sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n","                                        input_shape=[], # shape of inputs entering my model\n","                                        dtype=tf.string, # data type of inputs entering the USE layer\n","                                        trainable=False, # keep the pretrained weights (will create a feature extractor)\n","                                        name=\"USE\")"],"metadata":{"id":"AzJICogU5w9m","executionInfo":{"status":"ok","timestamp":1641217276406,"user_tz":300,"elapsed":4071,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":82,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WvjQl4p7BO_A"},"source":["Beautiful! Now we've got the USE as a Keras layer, we can use it in a Keras Sequential model."]},{"cell_type":"code","source":["# Create a model using the Sequential API\n","model_6 = tf.keras.Sequential([\n","                               sentence_encoder_layer, # Take sentences & encode them into an embedding\n","                               layers.Dense(64, activation=\"relu\"),\n","                               layers.Dense(1, activation=\"sigmoid\")\n","], name=\"model_6_USE\")\n","\n","# Compile model\n","model_6.compile(loss=\"binary_crossentropy\",\n","                optimizer=tf.keras.optimizers.Adam(),\n","                metrics=[\"accuracy\"])\n","\n","model_6.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xkd9mgCHDo8L","executionInfo":{"status":"ok","timestamp":1641217277024,"user_tz":300,"elapsed":627,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"9c7a87c9-071d-4c16-e892-8a9c3fa36b62"},"execution_count":83,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_6_USE\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," USE (KerasLayer)            (None, 512)               256797824 \n","                                                                 \n"," dense_6 (Dense)             (None, 64)                32832     \n","                                                                 \n"," dense_7 (Dense)             (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 256,830,721\n","Trainable params: 32,897\n","Non-trainable params: 256,797,824\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"yukgxOgCCR2Z"},"source":["Notice the number of paramters in the USE layer, these are the pretrained weights its learned on various text sources (Wikipedia, web news, web question-answer forums, etc, see the [Universal Sentence Encoder paper](https://www.aclweb.org/anthology/D18-2029.pdf) for more).\n","\n","The trainable parameters are only in our output layers, in other words, we're keeping the USE weights frozen and using it as a feature-extractor. We could fine-tune these weights by setting `trainable=True` when creating the `hub.KerasLayer` instance.\n","\n","Now we've got a feature extractor model ready, let's train it and track its results to TensorBoard using our `create_tensorboard_callback()` function."]},{"cell_type":"code","source":["# Train a classifier on top of pretrained embeddings\n","model_6_history = model_6.fit(train_sentences,\n","                              train_labels,\n","                              epochs=5,\n","                              validation_data=(val_sentences, val_labels),\n","                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n","                                                                     \"tf_hub_sentence_encoder\")])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HNKGSg6zEojT","executionInfo":{"status":"ok","timestamp":1641217292186,"user_tz":300,"elapsed":15163,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"81cf356a-83ee-47c1-bbb6-fb25d24f8ce6"},"execution_count":84,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder/20220103-134115\n","Epoch 1/5\n","215/215 [==============================] - 5s 14ms/step - loss: 0.5100 - accuracy: 0.7824 - val_loss: 0.4448 - val_accuracy: 0.7992\n","Epoch 2/5\n","215/215 [==============================] - 2s 12ms/step - loss: 0.4149 - accuracy: 0.8142 - val_loss: 0.4345 - val_accuracy: 0.8110\n","Epoch 3/5\n","215/215 [==============================] - 3s 12ms/step - loss: 0.4000 - accuracy: 0.8218 - val_loss: 0.4305 - val_accuracy: 0.8163\n","Epoch 4/5\n","215/215 [==============================] - 2s 11ms/step - loss: 0.3926 - accuracy: 0.8259 - val_loss: 0.4269 - val_accuracy: 0.8176\n","Epoch 5/5\n","215/215 [==============================] - 2s 11ms/step - loss: 0.3863 - accuracy: 0.8304 - val_loss: 0.4288 - val_accuracy: 0.8110\n"]}]},{"cell_type":"markdown","metadata":{"id":"KeI0kvVVDmbl"},"source":["USE model trained! Let's make some predictions with it an evaluate them as we've done with our other models."]},{"cell_type":"code","source":["# Make predictions with USE TF Hub model\n","model_6_pred_probs = model_6.predict(val_sentences)\n","model_6_pred_probs[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LY_IfKbFFeo2","executionInfo":{"status":"ok","timestamp":1641217292941,"user_tz":300,"elapsed":764,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"2ce91de5-d72b-48f2-ec59-7d4b8c8559cd"},"execution_count":85,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.1530006 ],\n","       [0.736035  ],\n","       [0.9886079 ],\n","       [0.19721147],\n","       [0.72985935],\n","       [0.6702606 ],\n","       [0.98279464],\n","       [0.9803151 ],\n","       [0.9246544 ],\n","       [0.09441808]], dtype=float32)"]},"metadata":{},"execution_count":85}]},{"cell_type":"code","source":["# Convert prediction probabilities to labels\n","model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n","model_6_preds[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_1abV_p0Fxjg","executionInfo":{"status":"ok","timestamp":1641217292941,"user_tz":300,"elapsed":7,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"2daba453-b690-4d68-bba3-b5119a9e5390"},"execution_count":86,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"]},"metadata":{},"execution_count":86}]},{"cell_type":"code","source":["# Calculate model 6 preformance metrics\n","model_6_results = calculate_results(val_labels, model_6_preds)\n","model_6_results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sz5ZFGvqGD_Y","executionInfo":{"status":"ok","timestamp":1641217292942,"user_tz":300,"elapsed":5,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"e87a05c7-6a41-4e24-cd1d-abf30ca0dd76"},"execution_count":87,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'accuracy': 81.10236220472441,\n"," 'f1': 0.809201931950287,\n"," 'precision': 0.8140341548215564,\n"," 'recall': 0.8110236220472441}"]},"metadata":{},"execution_count":87}]},{"cell_type":"code","source":["# Compare TF Hub model to baseline\n","compare_baseline_to_new_results(baseline_results, model_6_results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zyU7Bn4eGtnl","executionInfo":{"status":"ok","timestamp":1641217292942,"user_tz":300,"elapsed":4,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"dd7ee537-f065-4bff-e47a-181a385f126d"},"execution_count":88,"outputs":[{"output_type":"stream","name":"stdout","text":["Baseline accuracy: 79.27, New accuracy: 81.10, Difference: 1.84\n","Baseline precision: 0.81, New precision: 0.81, Difference: 0.00\n","Baseline recall: 0.79, New recall: 0.81, Difference: 0.02\n","Baseline f1: 0.79, New f1: 0.81, Difference: 0.02\n"]}]},{"cell_type":"markdown","metadata":{"id":"LHwu4QjijYWG"},"source":["### Model 7: TensorFlow Hub Pretrained Sentence Encoder 10% of the training data\n","\n","One of the benefits of using transfer learning methods, such as, the pretrained embeddings within the USE is the ability to get great results on a small amount of data (the USE paper even mentions this in the abstract).\n","\n","To put this to the test, we're going to make a small subset of the training data (10%), train a model and evaluate it."]},{"cell_type":"code","source":["# One kind of correct way (there are many others) to make data subset\n","# (split the already split train_sentences/train_labels)\n","train_sentences_90_precent, train_sentences_10_precent, train_labels_90_precent, train_labels_10_precent = train_test_split(np.array(train_sentences),\n","                                                                                                                            train_labels,\n","                                                                                                                            test_size=0.1,\n","                                                                                                                            random_state=42)"],"metadata":{"id":"nS7P6YaWG5FO","executionInfo":{"status":"ok","timestamp":1641217292942,"user_tz":300,"elapsed":4,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":89,"outputs":[]},{"cell_type":"code","source":["# Check length of 10 precent datasets\n","print(f\"Total training examples: {len(train_sentences)}\")\n","print(f\"Lenght of 10% of training examples: {len(train_sentences_10_precent)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DX7vVqeaIGm0","executionInfo":{"status":"ok","timestamp":1641217292942,"user_tz":300,"elapsed":4,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"f1823ab9-f96a-49f7-9e08-7931abf213eb"},"execution_count":90,"outputs":[{"output_type":"stream","name":"stdout","text":["Total training examples: 6851\n","Lenght of 10% of training examples: 686\n"]}]},{"cell_type":"markdown","metadata":{"id":"7E2jr7rSEYT8"},"source":["Because we've selected a random subset of the training samples, the classes should be roughly balanced (as they are in the full training dataset)."]},{"cell_type":"code","source":["# Check the number of targets in my subset data\n","# (this should be close to the distrobution of labels in the original train_labels)\n","pd.Series(train_labels_10_precent).value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VPdk0qSBIhyv","executionInfo":{"status":"ok","timestamp":1641217292943,"user_tz":300,"elapsed":4,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"e93388ef-e43f-4143-a414-dedbd8b88ea6"},"execution_count":91,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    415\n","1    271\n","dtype: int64"]},"metadata":{},"execution_count":91}]},{"cell_type":"markdown","metadata":{"id":"ghl1qeGOEnXG"},"source":["To make sure we're making an appropriate comparison between our model's ability to learn from the full training set and 10% subset, we'll clone our USE model (`model_6`) using the [`tf.keras.models.clone_model()`](https://www.tensorflow.org/api_docs/python/tf/keras/models/clone_model) method.\n","\n","Doing this will create the same architecture but reset the learned weights of the clone target (pretrained weights from the USE will remain but all others will be reset)."]},{"cell_type":"code","source":["# Clone model_6 but reset weights\n","model_7 = tf.keras.models.clone_model(model_6)\n","\n","# Compile model\n","model_7.compile(loss=\"binary_crossentropy\",\n","                optimizer=tf.keras.optimizers.Adam(),\n","                metrics=[\"accuracy\"])\n","\n","# Get a summary (will be same as model_6)\n","model_7.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T6QfDTtWQpjr","executionInfo":{"status":"ok","timestamp":1641217297453,"user_tz":300,"elapsed":4514,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"4ad6a799-c062-41fa-9080-76ddd23a1774"},"execution_count":92,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_6_USE\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," USE (KerasLayer)            (None, 512)               256797824 \n","                                                                 \n"," dense_6 (Dense)             (None, 64)                32832     \n","                                                                 \n"," dense_7 (Dense)             (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 256,830,721\n","Trainable params: 32,897\n","Non-trainable params: 256,797,824\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"LxFkEM_aFoLK"},"source":["Notice the layout of `model_7` is the same as `model_6`. Now let's train the newly created model on our 10% training data subset."]},{"cell_type":"code","source":["# Fit the model to 10% of the training data\n","model_7_history = model_7.fit(x=train_sentences_10_precent,\n","                              y=train_labels_10_precent,\n","                              epochs=5,\n","                              validation_data=(val_sentences, val_labels),\n","                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"10_percent_tf_hub_sentence_encoder\")])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dHjJgKcHRSBu","executionInfo":{"status":"ok","timestamp":1641217305161,"user_tz":300,"elapsed":7729,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"06767d7a-1002-410b-d25d-fecb0182d346"},"execution_count":93,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving TensorBoard log files to: model_logs/10_percent_tf_hub_sentence_encoder/20220103-134136\n","Epoch 1/5\n","22/22 [==============================] - 4s 47ms/step - loss: 0.6691 - accuracy: 0.6691 - val_loss: 0.6485 - val_accuracy: 0.7244\n","Epoch 2/5\n","22/22 [==============================] - 0s 21ms/step - loss: 0.5942 - accuracy: 0.8251 - val_loss: 0.5879 - val_accuracy: 0.7493\n","Epoch 3/5\n","22/22 [==============================] - 0s 21ms/step - loss: 0.5158 - accuracy: 0.8222 - val_loss: 0.5355 - val_accuracy: 0.7625\n","Epoch 4/5\n","22/22 [==============================] - 1s 26ms/step - loss: 0.4524 - accuracy: 0.8411 - val_loss: 0.5050 - val_accuracy: 0.7664\n","Epoch 5/5\n","22/22 [==============================] - 0s 20ms/step - loss: 0.4096 - accuracy: 0.8426 - val_loss: 0.4883 - val_accuracy: 0.7703\n"]}]},{"cell_type":"markdown","metadata":{"id":"9Qpyqdh-F6Eh"},"source":["Due to the smaller amount of training data, training happens even quicker than before.\n","\n","Let's evaluate our model's performance after learning on 10% of the training data."]},{"cell_type":"code","source":["# Make predictions with the model trained on 10% of the data\n","model_7_pred_probs = model_7.predict(val_sentences)\n","model_7_pred_probs[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Qk3qeUgR6fK","executionInfo":{"status":"ok","timestamp":1641217305751,"user_tz":300,"elapsed":599,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"246e9b41-583f-4336-947f-590d20a79d73"},"execution_count":94,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.23453256],\n","       [0.80757797],\n","       [0.91575396],\n","       [0.3039955 ],\n","       [0.55507994],\n","       [0.83616275],\n","       [0.82034326],\n","       [0.8569303 ],\n","       [0.84923124],\n","       [0.12980619]], dtype=float32)"]},"metadata":{},"execution_count":94}]},{"cell_type":"code","source":["# convert predicion probabilities to labels\n","model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n","model_7_preds[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rxi9QhmjSQEI","executionInfo":{"status":"ok","timestamp":1641217305752,"user_tz":300,"elapsed":10,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"8998940b-a831-41bd-b9b6-bafc616ebef4"},"execution_count":95,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"]},"metadata":{},"execution_count":95}]},{"cell_type":"code","source":["# Calculate model results\n","model_7_results = calculate_results(val_labels, model_7_preds)\n","model_7_results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JP6oC8NkSeCZ","executionInfo":{"status":"ok","timestamp":1641217305752,"user_tz":300,"elapsed":6,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"89a548aa-b48a-4310-d8a5-74cbd7f815bb"},"execution_count":96,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'accuracy': 77.03412073490814,\n"," 'f1': 0.7668707484010339,\n"," 'precision': 0.7751330918759862,\n"," 'recall': 0.7703412073490814}"]},"metadata":{},"execution_count":96}]},{"cell_type":"code","source":["# Compare to baseline\n","compare_baseline_to_new_results(baseline_results, model_7_results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gpzq9-hQStrz","executionInfo":{"status":"ok","timestamp":1641217305753,"user_tz":300,"elapsed":7,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"db713756-41db-42e0-d832-33f33ce5388b"},"execution_count":97,"outputs":[{"output_type":"stream","name":"stdout","text":["Baseline accuracy: 79.27, New accuracy: 77.03, Difference: -2.23\n","Baseline precision: 0.81, New precision: 0.78, Difference: -0.04\n","Baseline recall: 0.79, New recall: 0.77, Difference: -0.02\n","Baseline f1: 0.79, New f1: 0.77, Difference: -0.02\n"]}]},{"cell_type":"markdown","metadata":{"id":"iBs9V61EGh0J"},"source":["## Comparing the performance of each of our models\n","\n","Woah. We've come a long way! From training a baseline to several deep models.\n","\n","Now it's time to compare our model's results.\n","\n","But just before we do, it's worthwhile mentioning, this type of practice is a standard deep learning workflow. Training various different models, then comparing them to see which one performed best and continuing to train it if necessary.\n","\n","The important thing to note is that for all of our modelling experiments we used the same training data (except for `model_7` where we used 10% of the training data).\n","\n","To visualize our model's performances, let's create a pandas DataFrame for our results dictionaries and then plot it."]},{"cell_type":"code","source":["# Combine model results into a DataFrame\n","all_model_results = pd.DataFrame({\"baseline\": baseline_results,\n","                                  \"simple_dense\": model_1_results,\n","                                  \"lstm\": model_2_results,\n","                                  \"gru\": model_3_results,\n","                                  \"bidirectional\": model_4_results,\n","                                  \"conv1d\": model_5_results,\n","                                  \"tf_hub_sentence_encoder\": model_6_results,\n","                                  \"tf_hub_10_precent_data\": model_7_results})\n","all_model_results = all_model_results.transpose()\n","all_model_results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"qlFl8YmRS2DN","executionInfo":{"status":"ok","timestamp":1641217305753,"user_tz":300,"elapsed":6,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"12aac64c-aaed-4c35-d5a6-785a7450368b"},"execution_count":98,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-f87a7255-8c2e-4d0e-8de4-6deb0257b754\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>accuracy</th>\n","      <th>precision</th>\n","      <th>recall</th>\n","      <th>f1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>baseline</th>\n","      <td>79.265092</td>\n","      <td>0.811139</td>\n","      <td>0.792651</td>\n","      <td>0.786219</td>\n","    </tr>\n","    <tr>\n","      <th>simple_dense</th>\n","      <td>78.740157</td>\n","      <td>0.791492</td>\n","      <td>0.787402</td>\n","      <td>0.784697</td>\n","    </tr>\n","    <tr>\n","      <th>lstm</th>\n","      <td>75.065617</td>\n","      <td>0.751008</td>\n","      <td>0.750656</td>\n","      <td>0.748927</td>\n","    </tr>\n","    <tr>\n","      <th>gru</th>\n","      <td>76.771654</td>\n","      <td>0.767545</td>\n","      <td>0.767717</td>\n","      <td>0.766793</td>\n","    </tr>\n","    <tr>\n","      <th>bidirectional</th>\n","      <td>76.640420</td>\n","      <td>0.766590</td>\n","      <td>0.766404</td>\n","      <td>0.765121</td>\n","    </tr>\n","    <tr>\n","      <th>conv1d</th>\n","      <td>78.346457</td>\n","      <td>0.787212</td>\n","      <td>0.783465</td>\n","      <td>0.780780</td>\n","    </tr>\n","    <tr>\n","      <th>tf_hub_sentence_encoder</th>\n","      <td>81.102362</td>\n","      <td>0.814034</td>\n","      <td>0.811024</td>\n","      <td>0.809202</td>\n","    </tr>\n","    <tr>\n","      <th>tf_hub_10_precent_data</th>\n","      <td>77.034121</td>\n","      <td>0.775133</td>\n","      <td>0.770341</td>\n","      <td>0.766871</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f87a7255-8c2e-4d0e-8de4-6deb0257b754')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f87a7255-8c2e-4d0e-8de4-6deb0257b754 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f87a7255-8c2e-4d0e-8de4-6deb0257b754');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                          accuracy  precision    recall        f1\n","baseline                 79.265092   0.811139  0.792651  0.786219\n","simple_dense             78.740157   0.791492  0.787402  0.784697\n","lstm                     75.065617   0.751008  0.750656  0.748927\n","gru                      76.771654   0.767545  0.767717  0.766793\n","bidirectional            76.640420   0.766590  0.766404  0.765121\n","conv1d                   78.346457   0.787212  0.783465  0.780780\n","tf_hub_sentence_encoder  81.102362   0.814034  0.811024  0.809202\n","tf_hub_10_precent_data   77.034121   0.775133  0.770341  0.766871"]},"metadata":{},"execution_count":98}]},{"cell_type":"code","source":["# Reduce the accuracy to same scale as the other metrics\n","all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100"],"metadata":{"id":"Itwv3R5oUFcD","executionInfo":{"status":"ok","timestamp":1641217305754,"user_tz":300,"elapsed":6,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":99,"outputs":[]},{"cell_type":"code","source":["# Plot & compare all of the model results\n","all_model_results.plot(kind=\"bar\", figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 1.0));"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"fpDrlZpXUY9F","executionInfo":{"status":"ok","timestamp":1641217306073,"user_tz":300,"elapsed":325,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"669f5314-f7f9-4e0a-b790-48dddea231f6"},"execution_count":100,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 720x504 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"avbdkiIuKNNr"},"source":["Looks like our pretrained USE TensorFlow Hub models have the best performance, even the one with only 10% of the training data seems to outperform the other models. This goes to show the power of transfer learning.\n","\n","How about we drill down and get the F1-score's of each model?"]},{"cell_type":"code","source":["# Sort model results by f1-score\n","all_model_results.sort_values(\"f1\", ascending=False)[\"f1\"].plot(kind=\"bar\", figsize=(10, 7));"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"j2Gz4aHwUsXb","executionInfo":{"status":"ok","timestamp":1641217306426,"user_tz":300,"elapsed":356,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"d07eb59b-eac5-49c3-fd7b-64a9644ea10b"},"execution_count":101,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAlMAAAIRCAYAAABu0TiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5hlZX3m/e/NSUU5GVoTAQGZFl+iKKYFFCcecSAZIRIP4BiPkdERD9GYwGiQYCZGjDoZw0RRgycQwUlMqygSz/FIgwgCEjt4AMzERg0Qndigv/ePvQo2RTVV9FNVa1Wv7+e69kWttVd33W6rd917rWc9T6oKSZIkbZ6t+g4gSZK0klmmJEmSGlimJEmSGlimJEmSGlimJEmSGmzT1zfedddda6+99urr20uSJC3YhRdeeF1VrZrrud7K1F577cW6dev6+vaSJEkLluS7m3rOy3ySJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNtlnIQUkOA/4C2Bp4R1X92azn7wu8G9i5O+b4qjp3kbPOaa/jP7oc32Ze3/mz3+w7giRJ6sG8Z6aSbA2cChwO7Acck2S/WYe9Gji7qg4Ajgb+92IHlSRJGqKFXOY7EFhfVVdV1UbgLODIWccUsGP39U7A9xcvoiRJ0nAt5DLfbsDVU9vXAAfNOuYk4BNJXgzcHXj8oqSTJEkauMUagH4M8K6q2h34DeC9SW73dyc5Nsm6JOs2bNiwSN9akiSpPwspU9cCe0xt797tm/Y84GyAqvoScFdg19l/UVWdVlVrqmrNqlWrNi+xJEnSgCykTF0ArE6yd5LtmAwwXzvrmO8BjwNI8v8xKVOeepIkSVu8ectUVd0MHAecB1zB5K69y5KcnOSI7rBXAM9P8nXg/cCzq6qWKrQkSdJQLGieqW7OqHNn7Ttx6uvLgUMWN5okSdLwOQO6JElSgwWdmdLKMpRZ4WFYM8P7ukiSloJnpiRJkhp4ZkoaOc/YSVIbz0xJkiQ1sExJkiQ1sExJkiQ1sExJkiQ1sExJkiQ18G4+SZrDUO5y9A5HafgsU5KkBRlKwYRhlUxfF3mZT5IkqYFlSpIkqYFlSpIkqYFlSpIkqYFlSpIkqYFlSpIkqYFlSpIkqYHzTEmSpEU3pvm3PDMlSZLUwDIlSZLUwDIlSZLUwDIlSZLUwDIlSZLUwDIlSZLUwDIlSZLUwDIlSZLUwDIlSZLUwDIlSZLUwDIlSZLUwDIlSZLUwDIlSZLUwDIlSZLUwDIlSZLUwDIlSZLUwDIlSZLUYEFlKslhSa5Msj7J8XM8/+YkF3ePf0zyr4sfVZIkaXi2me+AJFsDpwKHAtcAFyRZW1WXzxxTVb83dfyLgQOWIKskSdLgLOTM1IHA+qq6qqo2AmcBR97B8ccA71+McJIkSUO3kDK1G3D11PY13b7bSbInsDfwqU08f2ySdUnWbdiw4c5mlSRJGpzFHoB+NPDBqvr5XE9W1WlVtaaq1qxatWqRv7UkSdLyW0iZuhbYY2p7927fXI7GS3ySJGlEFlKmLgBWJ9k7yXZMCtPa2QcleQCwC/ClxY0oSZI0XPOWqaq6GTgOOA+4Aji7qi5LcnKSI6YOPRo4q6pqaaJKkiQNz7xTIwBU1bnAubP2nThr+6TFiyVJkrQyOAO6JElSA8uUJElSA8uUJElSA8uUJElSA8uUJElSA8uUJElSA8uUJElSA8uUJElSA8uUJElSA8uUJElSA8uUJElSA8uUJElSA8uUJElSA8uUJElSA8uUJElSA8uUJElSA8uUJElSA8uUJElSA8uUJElSA8uUJElSA8uUJElSA8uUJElSA8uUJElSA8uUJElSA8uUJElSA8uUJElSA8uUJElSA8uUJElSA8uUJElSA8uUJElSA8uUJElSA8uUJElSA8uUJElSA8uUJElSA8uUJElSA8uUJElSgwWVqSSHJbkyyfokx2/imKcmuTzJZUnOXNyYkiRJw7TNfAck2Ro4FTgUuAa4IMnaqrp86pjVwAnAIVX14yT3WqrAkiRJQ7KQM1MHAuur6qqq2gicBRw565jnA6dW1Y8BquoHixtTkiRpmBZSpnYDrp7avqbbN+3+wP2TfCHJl5McNtdflOTYJOuSrNuwYcPmJZYkSRqQxRqAvg2wGng0cAzw9iQ7zz6oqk6rqjVVtWbVqlWL9K0lSZL6s5AydS2wx9T27t2+adcAa6vqpqr6NvCPTMqVJEnSFm0hZeoCYHWSvZNsBxwNrJ11zIeYnJUiya5MLvtdtYg5JUmSBmneMlVVNwPHAecBVwBnV9VlSU5OckR32HnAD5NcDnwaeGVV/XCpQkuSJA3FvFMjAFTVucC5s/adOPV1AS/vHpIkSaPhDOiSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNFlSmkhyW5Mok65McP8fzz06yIcnF3eN3Fz+qJEnS8Gwz3wFJtgZOBQ4FrgEuSLK2qi6fdegHquq4JcgoSZI0WAs5M3UgsL6qrqqqjcBZwJFLG0uSJGllWEiZ2g24emr7mm7fbL+d5JIkH0yyx1x/UZJjk6xLsm7Dhg2bEVeSJGlYFmsA+oeBvapqf+B84N1zHVRVp1XVmqpas2rVqkX61pIkSf1ZSJm6Fpg+07R7t+8WVfXDqvpZt/kO4NcWJ54kSdKwLaRMXQCsTrJ3ku2Ao4G10wck+ZWpzSOAKxYvoiRJ0nDNezdfVd2c5DjgPGBr4K+r6rIkJwPrqmot8JIkRwA3Az8Cnr2EmSVJkgZj3jIFUFXnAufO2nfi1NcnACcsbjRJkqThcwZ0SZKkBpYpSZKkBpYpSZKkBpYpSZKkBpYpSZKkBpYpSZKkBpYpSZKkBpYpSZKkBpYpSZKkBpYpSZKkBpYpSZKkBpYpSZKkBpYpSZKkBpYpSZKkBpYpSZKkBpYpSZKkBpYpSZKkBpYpSZKkBpYpSZKkBpYpSZKkBpYpSZKkBpYpSZKkBpYpSZKkBpYpSZKkBpYpSZKkBpYpSZKkBpYpSZKkBpYpSZKkBpYpSZKkBpYpSZKkBpYpSZKkBpYpSZKkBpYpSZKkBpYpSZKkBpYpSZKkBpYpSZKkBgsqU0kOS3JlkvVJjr+D4347SSVZs3gRJUmShmveMpVka+BU4HBgP+CYJPvNcdwOwEuBryx2SEmSpKFayJmpA4H1VXVVVW0EzgKOnOO41wKvB/59EfNJkiQN2kLK1G7A1VPb13T7bpHkocAeVfXRO/qLkhybZF2SdRs2bLjTYSVJkoameQB6kq2ANwGvmO/YqjqtqtZU1ZpVq1a1fmtJkqTeLaRMXQvsMbW9e7dvxg7AA4HPJPkOcDCw1kHokiRpDBZSpi4AVifZO8l2wNHA2pknq+r6qtq1qvaqqr2ALwNHVNW6JUksSZI0IPOWqaq6GTgOOA+4Aji7qi5LcnKSI5Y6oCRJ0pBts5CDqupc4NxZ+07cxLGPbo8lSZK0MjgDuiRJUgPLlCRJUgPLlCRJUgPLlCRJUgPLlCRJUgPLlCRJUgPLlCRJUgPLlCRJUgPLlCRJUgPLlCRJUgPLlCRJUgPLlCRJUgPLlCRJUgPLlCRJUgPLlCRJUgPLlCRJUgPLlCRJUgPLlCRJUgPLlCRJUgPLlCRJUgPLlCRJUgPLlCRJUgPLlCRJUgPLlCRJUgPLlCRJUgPLlCRJUgPLlCRJUgPLlCRJUgPLlCRJUgPLlCRJUgPLlCRJUgPLlCRJUgPLlCRJUgPLlCRJUgPLlCRJUoMFlakkhyW5Msn6JMfP8fwLklya5OIk/5Bkv8WPKkmSNDzzlqkkWwOnAocD+wHHzFGWzqyqB1XVQ4BTgDctelJJkqQBWsiZqQOB9VV1VVVtBM4Cjpw+oKpumNq8O1CLF1GSJGm4tlnAMbsBV09tXwMcNPugJC8CXg5sBzx2UdJJkiQN3KINQK+qU6tqH+APgVfPdUySY5OsS7Juw4YNi/WtJUmSerOQMnUtsMfU9u7dvk05C/ituZ6oqtOqak1VrVm1atXCU0qSJA3UQsrUBcDqJHsn2Q44Glg7fUCS1VObvwl8a/EiSpIkDde8Y6aq6uYkxwHnAVsDf11VlyU5GVhXVWuB45I8HrgJ+DHwrKUMLUmSNBQLGYBOVZ0LnDtr34lTX790kXNJkiStCM6ALkmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1MAyJUmS1GBBZSrJYUmuTLI+yfFzPP/yJJcnuSTJJ5PsufhRJUmShmfeMpVka+BU4HBgP+CYJPvNOuxrwJqq2h/4IHDKYgeVJEkaooWcmToQWF9VV1XVRuAs4MjpA6rq01X1027zy8DuixtTkiRpmBZSpnYDrp7avqbbtynPAz421xNJjk2yLsm6DRs2LDylJEnSQC3qAPQkzwDWAG+Y6/mqOq2q1lTVmlWrVi3mt5YkSerFNgs45lpgj6nt3bt9t5Hk8cCrgEdV1c8WJ54kSdKwLeTM1AXA6iR7J9kOOBpYO31AkgOAtwFHVNUPFj+mJEnSMM1bpqrqZuA44DzgCuDsqrosyclJjugOewNwD+CcJBcnWbuJv06SJGmLspDLfFTVucC5s/adOPX14xc5lyRJ0orgDOiSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNLFOSJEkNFlSmkhyW5Mok65McP8fzv57koiQ3J3ny4seUJEkapnnLVJKtgVOBw4H9gGOS7DfrsO8BzwbOXOyAkiRJQ7bNAo45EFhfVVcBJDkLOBK4fOaAqvpO99wvliCjJEnSYC3kMt9uwNVT29d0++60JMcmWZdk3YYNGzbnr5AkSRqUZR2AXlWnVdWaqlqzatWq5fzWkiRJS2IhZepaYI+p7d27fZIkSaO3kDJ1AbA6yd5JtgOOBtYubSxJkqSVYd4yVVU3A8cB5wFXAGdX1WVJTk5yBECShyW5BngK8LYkly1laEmSpKFYyN18VNW5wLmz9p049fUFTC7/SZIkjYozoEuSJDWwTEmSJDWwTEmSJDWwTEmSJDWwTEmSJDWwTEmSJDWwTEmSJDWwTEmSJDWwTEmSJDWwTEmSJDWwTEmSJDWwTEmSJDWwTEmSJDWwTEmSJDWwTEmSJDWwTEmSJDWwTEmSJDWwTEmSJDWwTEmSJDWwTEmSJDWwTEmSJDWwTEmSJDWwTEmSJDWwTEmSJDWwTEmSJDWwTEmSJDWwTEmSJDWwTEmSJDWwTEmSJDWwTEmSJDWwTEmSJDWwTEmSJDWwTEmSJDWwTEmSJDWwTEmSJDWwTEmSJDVYUJlKcliSK5OsT3L8HM/fJckHuue/kmSvxQ4qSZI0RPOWqSRbA6cChwP7Acck2W/WYc8DflxV/wF4M/D6xQ4qSZI0RAs5M3UgsL6qrqqqjcBZwJGzjjkSeHf39QeBxyXJ4sWUJEkaplTVHR+QPBk4rKp+t9v+HeCgqjpu6phvdMdc023/U3fMdbP+rmOBY7vNfYErF+t/SKNdgevmPWp8fF1uz9dkbr4uc/N1mZuvy+35msxtSK/LnlW1aq4ntlnOFFV1GnDacn7PhUiyrqrW9J1jaHxdbs/XZG6+LnPzdZmbr8vt+ZrMbaW8Lgu5zHctsMfU9u7dvjmPSbINsBPww8UIKEmSNGQLKVMXAKuT7J1kO+BoYO2sY9YCz+q+fjLwqZrv+qEkSdIWYN7LfFV1c5LjgPOArYG/rqrLkpwMrKuqtcA7gfcmWQ/8iEnhWkkGd+lxIHxdbs/XZG6+LnPzdZmbr8vt+ZrMbUW8LvMOQJckSdKmOQO6JElSA8uUJElSA8uUJElSA8uUJElSg2WdtHMouvUG/76qHtN3liFK8khgdVWdnmQVcI+q+nbfufqSZHvgFcB9q+r5SVYD+1bVR3qO1oskbwE2eedKVb1kGeMMTvfz8Toma5nedWZ/Vd2vt1AalCT3vKPnq+pHy5VliJKsAV4F7MmkpwSoqtq/12B3YJRlqqp+nuQXSXaqquv7zjMkSV4DrGGy3M/pwLbA+4BD+szVs9OBC4GHd9vXAucAoyxTwLruv4cwKQwf6LafAlzeS6JhOR14DZNF3x8DPIeRXwVIciO3FvDtmLyv/KSqduwvVa8uZPJ6zLWGbQFjL95nAK8ELgV+0XOWBRllmer8G3BpkvOBn8zsHPunauBJwAHARQBV9f0kO/QbqXf7VNXTkhwDUFU/HfNC3lX1boAkLwQeWVU3d9tvBT7fZ7aBuFtVfTJJquq7wElJLgRO7DtYX6rqlveQ7t/OkcDB/SXqV1Xt3XeGgdvQzWG5Yoy5TP1N99BtbayqSlIASe7ed6AB2JjkbnSfrJPsA/ys30iDsAuwI5OJegHu0e0bu58l2Qr4Vjfh8bVMXhsxuVYDfKg7C35833n6lmQXYDW3vST8uf4SDcJrkrwD+CRT77VVNdjf2aMtU1X17u4X5H2r6sq+8wzI2UneBuyc5PnAc4G395ypb68BPg7skeQMJpe3nt1romH4M+BrST7N5HLFrwMn9ZpoGF4KbA+8BHgtk0t9z+w1Uc+SHDW1uRWToQT/3lOcwUjyu0x+XnYHLmZytu5LwGP7zDUAzwEewORy8MxlvmLAJ0BGOwN6kicCfw5sV1V7J3kIcHJVHdFztN4lORR4ApNfkOdV1fk9R+pdkl9i8kYX4MtVdV3PkQYhyS8DB3WbX6mq/9tnniFI8pSqOme+fWOS5PSpzZuB7wBvr6of9JNoGJJcCjyMyXvKQ5I8APjTqjpqnj+6RUtyZVXt23eOO2PMZepCJu3/M1V1QLfvG1X1wH6TaWiSHAJcXFU/SfIM4KHAX3TjYTQlyQOq6pt95+hTkouq6qHz7RuL7u7pl1TVm/vOMjRJLqiqhyW5GDioqn6W5LKq+tW+s/WpK99vqKoVc0PLaC/zATdV1fWzxhGviLsGllJ3Ov71wL2YnIWZuSV1rHfdAPwV8OAkDwZezmRh7/cAj+o11TB9Arhv3yH6kORw4DeA3ZL8r6mndmRyNmaUurunj2Fyd6Nu65okOwMfAs5P8mPAD2mTqwAXJ/k2kzFTTo0wYJcleTqwdTcvzEuAL/acaQhOAZ5YVVf0HWRAbu4G5R8JnFpV70zyvL5D9WVWUbjNU8DOy5llYL7PZNqII5jc+j7jRuD3ekk0HF9I8pdMptGYvnv6ov4i9a+qntR9eVI39nAnJuMzx+6wvgPcWWO+zLc9k0nBbhkbBLy2qkY9KDLJF6pqzHNK3U6SzzJ5g3sOk0HWPwC+XlUP6jVYT7o5g17B3Hc0vrGqdl3mSIOSZNuquqnvHEPSFQW4da6pmTMNYx9oPXMZ9N5Mndyoqu/1l6h/Sd5bVb8z374hGW2Z0tyS/AXwy0xOO6+IW1KXWjfI+unABVX1+ST3BR5dVe/pOVovknwKeHVV3e5MbpJvj30OHWdAv70kr+C2k1QWcAOwrqou7i1Yz5K8mMndwv/C1F1rQ76ctRxmjzHsCuelVbVfj7Hu0OjKVJIPc8dLYYz6br5Zd93MqKp67rKH0SB1S2H8e1X9tO8sQ5TkH7h1BvQn0s2AXlWjnbQzyZlMpkNYy6RQ/WfgEmAv4JyqOqW/dP1Jsp7JwPMf9p1lCJKcAPx34G7AzPtLgI3AaVV1Ql/Z5jPGMjUzaPgoJmdg3tdtHwP8S1WNfWyDZnFQ/ty61+WjVeUEplOSXFhVv5bk0plLwTP7+s7WlySfA36jqv6t274H8FEmY2MuHPIZh6XUXf48dGYVAU0ked2Qi9NcRjcAvao+C5DkjVW1ZuqpDydZt4k/tsVL8gdVdcqmFrEd+TI7Dsqf2xOBN3e/KD8AfNxfCoAzoM/lXtx2jN1NwL2r6v8lGXMZvwr4TJKPctthFW/qL9IgfCTJ3VfSdDSjK1NT7p7kflV1FUCSvYExL50yUxRGWyjvwL9YpG6vqp6TZFvgcCZndk9Ncn5V/W7P0fo2ewb0xwLP6jVR/84AvpLk77rtJwJndstVrZi5hJbA97rHdt1DE9PT0bwCeAcDn45mdJf5ZiQ5DDiNySeDAHsCx1bVJ3oNpsFxUP4d6wrVYXR3O479bj7NLckaJksxAXyhqvzg1ukuezJzGXTsZgagJzkRuLabjmbQE9+OtkwBJLkLk/V/AL455rEfDszfNAflz62bpPJpwKOBzwBnA58Y66U+/w3pzkryQOC9wD27XdcBz6yqy/pL1b+VOB3NaMtU92n6hUz+j4LJL4O3jXV+mKmB+XOaGWsmzUjyfiZjpT425g8iM7y5RXdWki8Cr6qqT3fbj2ayNt8jeg3Ws5U4Hc2Yy9Q7mKxI/e5u1+8AP3e8ByS5G3Dfqrqy7yxDkOT+TK7h37uqHphkf+CIqvqTnqNpgJKsm3Vzy5z7pCRfr6oHz7dPw7dV3wF69LCqelZVfap7PIfJ6t2jluSJwMV0SxokeUiStf2m6t3bgROY3IFEVV0CHN1rogFIclSSbyW5PskNSW5MckPfuQbg7klumaDTm1t0B65K8kdJ9uoer2YyjneUZt5D5ngM/r1lzHfz/TzJPlX1TwDdm9/Pe840BCcBBzK57ElVXdz9Mhiz7avqq7MWxR7luKBZnDJibr/H5Hb329zc0m8kDdRzgT8GZm5m+Xy3b5Sqaoe+M2yuMZepVwKfnvWG95x+Iw3CTVV1/aziMM5rwbe6Lsk+dK9DkicD/9xvpEFwyog5VNXHuyVl5ry5JcmhVXV+P+k0JFX1YyZTaGiFG+2YKbjlbr59u80rHUQLSd4JfBI4HvhtJv/Qt62qF/QarEfdWcvTgEcAPwa+DTyjqr7TZ66+OWXE5hn6Ld5aekn+Z1W9bFN3gHrn58oz2jKV5EXAGVX1r932LsAxVfW/+03WryTbA68CnsDkjN15wGur6t97DTYA3QSDW1XVjX1nGQKnjNg8Sb5WVQf0nUP9SfJrVXXhpu6i9u7plWfMZeriqnrIrH2+yU3pVuq+e1UNeuDfUkny8jt63iUftDk8M6UZSV5aVX8x3z4N35jv5ts6UwODuuIw+un8k5yZZMfuLMylwOVJXtl3rp7s0D3WMJmTbLfu8QIma0WNWpLdk/xtkh90j/+TZPe+c0kryFzLDD17uUOo3ZgHoH8c+ECSt3Xb/7XbN3b7VdUNSf4L8DEmY6cuBN7Qb6zlV1V/DLeseP/Qmct7SU5isuL92J0OnAk8pdt+Rrfv0N4SDUCSu8wefzlr33eWP5WGJMkxTCal3HvW1DM7AD/qJ5VajLlM/SGTAvXCbvt8Jospjt223ezwvwX8ZVXdlGSc14JvdW9g49T2xm7f2K2qqulxU+9K8rLe0gzHl7j9mctb9lXVUcueSEPzRSZ3BO8KvHFq/43AJb0kUpPRlqmq+gWTWa3/qu8sA/M2Jp+cvw58LsmewCjHTE15D/DVJH/bbf8W8K7+4gzGD5M8A3h/t30M8MMe8/SqWwJjN+BuSQ5gcgMHwI7A9r0F0+BU1XeB73ZXAL4/c4NPt/rE7nj2csUZ8wD0Q5hMULknk1IZJnci3e+O/twYJdlmrIvXzkjyUOA/dpufq6qvTT23SzdfzKh0RfstwMOZ3N79ReDFVXV1r8F6kuRZTMa7rAHWTT11I/Aup4zQbEnWAY+oqo3d9nbAF6pq9KtxrDRjLlPfZDJT8YVMzXxeVaP9ZD0jyW8CvwrcdWZfVZ3cX6JhG+vdWUneDbxspkgmuSfw52OfGiHJb1fV/+k7h4ZvE3eVuzbfCjTay3zA9VX1sb5DDE2StzK5JPEYJmPIngx8tddQw5f5D9ki7T99Rq6qftRd3hq7jyR5OrAXU++xfiDRHDYkOaKq1gIkORK4rudM2gxjLlOfTvIGJmsiTc/efFF/kQbhEVW1f5JLquqPk7yRyV192rRxnt6FraYvcXZnpsb8njLj74DrmZz1Hv2qCrpDLwDOSHIqk/eRa4Bn9htJm2PMb3wHdf9dM7WvgMf2kGVI/l/3358muQ+TAcW/0mMeDdcbgS8lOafbfgrwP3rMMxS7V9VhfYfQ8FXVPwEHJ7lHt/1vPUfSZhptmaqqx/SdYaA+kmRn4BQmn6zBKSPmM8rLfFX1nm4A7cwHkKOq6vI+Mw3EF5M8qKou7TuIhi3JvYE/Be5TVYcn2Q94eFW9s+doupPGPADdH+I5dLfmvpDJnWsFfB74q7GvzZfkkcDqqjo9ySrgHlX17e65e1aVE+0JgCSXA/+ByYLYP+PWO4X37zWYBifJx5hMdPuqqnpwkm2Ar1XVg3qOpjtpzGXKH+I5JDmbya3c7+t2PR3Yqaqe2l+qfiV5DZPLwUSbE/0AAA05SURBVPtW1f27y5/nVNUhPUfTAHVTRtxON7eQdIskF1TVw6bXhZ3rDj8N35jX5tu1qs4GfgHQzaP08zv+I6PwwKp6XlV9uns8H3hg36F69iTgCOAnAFX1fSbLPki305WmPYDHdl//lHG/12rTfpLkl+huYklyMJObF7TCjHbMFP4Qb8pFSQ6uqi8DJDmI205AOEYbq6pmltXpFoGW5jR9JpPJ2e9tmZzp9UymZns5sBbYJ8kXgFVMpqPRCjPmMuUP8ZQklzIpltsyGUD7vW57T+CbfWYbgLO7BbF3TvJ84LnA23vOpOF6EnAAcBFMzmQm8UymbiPJ1sCjuse+TMbWXVlVN/UaTJtltGOmYLJMCpv4IU5yaFWd31u4ZbapcR4zxj7eI8mhwBOY/KycN6afDd05Sb5aVQfOzIzfncn8kgPQNdvMz0rfOdRu1GXqjox1iRBJbZL8PrAaOBR4HZMzmWdW1Vt6DabBSfJmJlcDPkA3JhOcPHolskxtwvTdFRqnJDcy9+zmM7e677jMkbRCeCZTC5Hk03Psrqoa++TRK45lahM8MyVpcyTZG/jnmbnZurnb7l1V3+k1mKQlM+YB6NKCJXko8EgmZ6r+oaq+1nMkDdc5wCOmtn/e7XtYP3E0NEmeUVXvS/LyuZ6vqjctdya1ce6TTftO3wE0DElOBN4N/BKwK/CuJK/uN5UGbJuq2jiz0X29XY95NDwz06vssImHVpjRXuZLsj3wCuC+VfX8JKuZzHD9kZ6jaWCSXAk8eNZlm4urat9+k2mIkpwPvKWq1nbbRwIvqarH9ZtM0lIZ82W+05ks5PvwbvtaJqfiLVOa7fvAXYGZ9QnvwuTnRZrLC4AzkpzK5LLwNcAz+42kIUnyv+7o+ap6yXJl0eIYc5nap6qeluQYgKr6aZL0HUqDdD1wWXfGoZjc8v7VmTdE3/g0rar+CTg4yT267X/rOZKG58Luv4cA+zGZGgHgKcDlvSRSkzGXqY3d5ZqZJUL2YbLCuzTb33aPGZ/pKYdWgCT3Bv4UuE9VHZ5kP+DhVfXOnqNpIKrq3QBJXgg8slsbliRvBT7fZzZtnjGXqdcAHwf2SHIGk08Iz+41kQZp5o1PWqB3MRlG8Kpu+x+ZnHmwTGm2XYAdgR912/fo9mmFGW2Zqqrzk1wEHMxkYr2XVtV1PcfSACX5z8BrmaxTuA1O2qk7tmtVnZ3kBICqujnJz/sOpUH6M+Br3eSdAX4dOKnXRNosoy1TSZ4EfKqqPtpt75zkt6rqQz1H0/D8T+Ao4NIa6+2vujN+kuSXuHUIwcFMxt1Jt1FVpyf5GHBQt+sPq+r/9plJm2fMUyNcXFUPmbXPJWR0O92nxsdV1S/6zqLh6yZ4fQvwQOAbwCrgyVV1Sa/BNBhJHlBV3+x+Vm7HtflWntGemWLuCUvH/Hpo0/4AODfJZ5m6ScFZijVbkq2BR3WPfZlcurmyqm7qNZiG5uXAscAbue36n+m2XZtvhRnzmam/Bv4VOLXb9SLgnlX17N5CaZCSfAL4N+BS4JazU1X1x72F0mAl+WpVHdh3Dg1fd0f5f+PWpao+D/zVzATBWjnGXKbuDvwR8Phu1/nAn1TVT/pLpSFK8o2qemDfObQyJHkzsC2TO/hueT/x0o1mS3I2cANwRrfr6cBOVfXU/lJpc4y2TEkLleQU4O+r6hN9Z9HwdWPsZquq8tKNbiPJ5VW133z7NHyjLVNJ7g/8PrAXU2OlfMPTbEluZLIw6c+Am3BqBEmLIMn7gL+sqi932wcBL6oqlx9aYcZcpr4OvJXJtP63zAFTVRdu8g9J0jy6aRFew63jYP4BOLmqfthrMA1GkkuZ/Gxsy+RGhe9123sC3/TM1Moz5jJ1YVX9Wt85NFzevqzN0a3h+Dngfd2u/wI8uqoev+k/pTFJsucdPV9V312uLFocYy5TJwE/YLLm2vTt7j/a1J/RuCQ5raqOnTUG5pZ/MF4S1lzmumEhyaVV9aC+MklaWmMuU9+eY3dV1f2WPYwGLclTgY9X1Q1J/gh4KPBaz0xpLkneBHwVOLvb9WTgwKr6/f5SSVpKoy1T0kIluaSq9k/ySCZr9P05cGJVHTTPH9UITd2wMDMWc2tunSLBGxekLdBcs4CPQpLtk7w6yWnd9upuQVtptplfir8JvL1bz3G7HvNowKpqh6raqqq27R5bdft2qKodk/xq3xklLa7RlingdGAj8Ihu+1rgT/qLowG7NsnbgKcxWVbmLoz7347avLfvAJIW15h/IexTVacwmTeIqvopk/mDpNmeCpwH/Keq+lfgnsAr+42kFcz3GWkLM+aFfTd26yIVQJJ9mLqrT5rRFe2/mdr+Z+Cf+0ukFc6BqtIWZsxl6iTg48AeSc4ADgGe02siSZK04oz6br5upuKDmZx2/3JVXddzJElbuCRfrqqD+84hafGMtkwl+WRVPW6+fZK0UEl2Ag4Ddut2XQuc1421k7SFGt0A9CR3TXJPYNckuyS5Z/fYi1vfACXpTknyTOAi4NHA9t3jMcCF3XOStlCjOzOV5KXAy4D7MPnUOHNnzQ1M5hD6y76ySVq5klwJHDT7LFSSXYCvVNX9+0kmaamNrkzNSPLiqnpL3zkkbRmS/CPwsKq6ftb+nYB1VbW6n2SSltpo7+arqrckeQSwF1OvQ1W9p7dQklay/wFclOQTwNXdvvsChzJZhkjSFmrMZ6beC+wDXMyty4VUVb2kv1SSVrLukt5/4vYD0H/cXypJS23MZeoKYL8a6wsgSZIWxeju5pvyDeCX+w4hacuX5NK+M0haOqMdMwXsClye5KtMLSNTVUf0F0nSSpXkqE09hR/cpC3amMvUSX0HkLRF+QBwBnOvvXfXZc4iaRmNdswUQJI9gdVV9fdJtge2rqob+84laeVJciHwrKr6xhzPXV1Ve/QQS9IyGO2YqSTPBz4IvK3btRvwof4SSVrhXsZk8t+5PGk5g0haXqMtU8CLgEPo3vyq6lvAvXpNJGnFqqrPV9X3NvHcupmvk5ywfKkkLYcxl6mfVdXGmY0k2zD3WAdJWkxP6TuApMU15jL12ST/HbhbkkOBc4AP95xJ0pYv8x8iaSUZ7QD0JFsBzwOewOTN7TzgHU7iKWkpJbmoqh7adw5Ji2e0ZWpaknsCu1fVJX1nkbRlS/K1qjqg7xySFs9oL/Ml+UySHbsidSHw9iRv7juXpC3eOX0HkLS4RlumgJ2q6gbgKOA9VXUQ8LieM0la4ZLcL8mHk1yX5AdJ/i7J/Waer6o/7TOfpMU35jK1TZJfAZ4KfKTvMJK2GGcCZzNZQuY+TM5Evb/XRJKW1JjL1MlMBp2vr6oLuk+O3+o5k6SVb/uqem9V3dw93ofLyUhbNAegb0KSE6rqdX3nkLQydOMvAf4Q+DFwFpO5654G7FJVTtYpbaEsU5vg7cuS7owk32ZSnuaaR6qq6n5z7Je0Bdim7wAD5sR6khasqvbuO4OkflimNs1TdpLutCTPnGt/Vb1nubNIWh6WqU3zzJSkzfGwqa/vymTKlYsAy5S0hbJMbZoT60m606rqxdPbSXZmMhhd0hZqtFMjOLGepGXyE8DxVNIWbMxnps4ETgWe1G0fzWRivYN6SyRpxUvyYW4dc7kVsB+TSTwlbaFGOzVCkkuqav9Z+75eVQ/uK5OklS/Jo6Y2bwa+W1XX9JVH0tIbXZlyYj1JkrSYxlimnFhP0pJJchTweuBeTN5nwuS9Zcdeg0laMqMrU5K0lJKsB55YVVf0nUXS8hjtAHQn1pO0RP7FIiWNy2jPTCV5y9TmLRPrVdWTe4okaQXrLu8BPAr4ZeBDwM9mnq+qv+kjl6SlN9oyNdvMxHpVdVjfWSStPElOv4Onq6qeu2xhJC0ry1QnybbAN6pq376zSNpyJTmhql7Xdw5Ji2fMY6acWE9SH54CWKakLchoyxTw51NfO7GepOXiIurSFma0ZaqqPtt3Bkmj5NgKaQsz5oWOj0ryrSTXJ7khyY1Jbug7l6QtnmempC3MaMsUcApwRFXtVFU7VtUOzlAsaXMleX3336fMc+g5yxBH0jIa7d18Sb5QVYf0nUPSliHJpcD+wIVV9dC+80haPqMbMzU1sd66JB/AifUkLY6PM1k8/R6zhgy4Np+0hRvdmSkn1pO0lJJ8oqqeMGvfKVX1B31lkrS0RlemFsqJ9SRtjiQXzb7Ml+SSqtq/r0ySltaYB6DPZ75BpJJ0iyQv7MZN7ZvkkqnHt4FL+84nael4ZmoTknytqg7oO4eklSHJTsAuTGY3P37qqRur6kf9pJK0HCxTmzDXqXpJkqTZvMy3aU6sJ0mS5jW6MuXEepIkaTGN7jKfE+tJkqTFNLpJO3FiPUmStIhGd5mvql5ZVTsDn+rW5Jt57AC8te98kiRpZRldmZqy6xz7Dlv2FJIkaUUb3WW+JC8E/htwvySXTD21A/DFflJJkqSVaowD0J1YT5IkLZrRlSlJkqTFNOYxU5IkSc0sU5IkSQ0sU5IkSQ0sU5IkSQ3+fzuyvU7z7mzzAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 720x504 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"pv2iE0TPGdNy"},"source":["Drilling down into a single metric we see our USE TensorFlow Hub models performing  better than all of the other models. Interestingly, the baseline's F1-score isn't too far off the rest of the deeper models.\n","\n","We can also visualize all of our model's training logs using TensorBoard.dev."]},{"cell_type":"code","source":["# View tensorboard logs of transfer learning modelling experiments (should be 4 models)\n","# Upload TensorBoard dev records\n","#!tensorboard dev upload --logdir ./model_logs \\\n","#    --name \"NLP modelling experiments\" \\\n","#    --description \"a series of different NLP modelling experiments with various models\" \\\n","#    --one_shot # exits the uploader when upload is finished"],"metadata":{"id":"4S6p2IGuVPWd","executionInfo":{"status":"ok","timestamp":1641217306426,"user_tz":300,"elapsed":9,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":102,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uIYVXCUJ3FBn"},"source":["The TensorBoard logs of the different modelling experiments we ran can be viewed here: https://tensorboard.dev/experiment/LkoAakb7QIKBZ0RL97cXbw/"]},{"cell_type":"markdown","metadata":{"id":"GGVZhTTiGdd5"},"source":["## Combining our models (model ensembling/stacking)\n","\n","Many production systems use an **ensemble** (multiple different models combined) of models to make a prediction.\n","\n","The idea behind model stacking is that if several uncorrelated models agree on a prediction, then the prediction must be more robust than a prediction made by a singular model.\n","\n","The keyword in the sentence above is **uncorrelated**, which is another way of saying, different types of models. For example, in our case, we might combine our baseline, our bidirectional model and our TensorFlow Hub USE model.\n","\n","Although these models are all trained on the same data, they all have a different way of finding patterns.\n","\n","If we were to use three similarly trained models, such as three LSTM models, the predictions they output will likely be very similar.\n","\n","Think of it as trying to decide where to eat with your friends. If you all have similar tastes, you'll probably all pick the same restaurant. But if you've all got different tastes and still end up picking the same restaurant, the restaurant must be good.\n","\n","Since we're working with a classification problem, there are a few of ways we can combine our models:\n","1. **Averaging** - Take the output prediction probabilities of each model for each sample, combine them and then average them.\n","2. **Majority vote (mode)** - Make class predictions with each of your models on all samples, the predicted class is the one in majority. For example, if three different models predict `[1, 0, 1]` respectively, the majority class is `1`, therefore, that would be the predicted label.\n","3. **Model stacking** - Take the outputs of each of your chosen models and use them as inputs to another model.\n","\n","> üìñ **Resource:** The above methods for model stacking/ensembling were adapted from Chapter 6 of the [Machine Learning Engineering Book](http://www.mlebook.com/wiki/doku.php) by Andriy Burkov. If you're looking to enter the field of machine learning engineering, not only building models but production-scale machine learning systems, I'd highly recommend reading it in its entirety.\n","\n","Again, the concept of model stacking is best seen in action.\n","\n","We're going to combine our baseline model (`model_0`), LSTM model (`model_2`) and our USE model trained on the full training data (`model_6`) by averaging the combined prediction probabilities of each."]},{"cell_type":"code","source":["# Get mean pred probs for 3 models\n","baseline_pred_probs = np.max(model_0.predict_proba(val_sentences), axis=1) # get the prediction probabilities from baseline model\n","combined_pred_probs = baseline_pred_probs + tf.squeeze(model_2_pred_probs, axis=1) + tf.squeeze(model_6_pred_probs)\n","combined_preds = tf.round(combined_pred_probs/3) # average & round the prediction probabilities\n","combined_preds[:20]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k9zh6xWSWNUZ","executionInfo":{"status":"ok","timestamp":1641217306427,"user_tz":300,"elapsed":10,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"7ca99e60-2049-4337-cced-f7e6e23bdf40"},"execution_count":103,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(20,), dtype=float32, numpy=\n","array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0.,\n","       0., 0., 1.], dtype=float32)>"]},"metadata":{},"execution_count":103}]},{"cell_type":"markdown","metadata":{"id":"6abZa7wqlXSI"},"source":["Wonderful! We've got a combined predictions array of different classes, let's evaluate them against the true labels and add our stacked model's results to our `all_model_results` DataFrame."]},{"cell_type":"code","source":["# Calculate results from averaging the prediction probabilities\n","ensemble_results = calculate_results(val_labels, combined_preds)\n","ensemble_results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PrMLTS5NbIJd","executionInfo":{"status":"ok","timestamp":1641217306427,"user_tz":300,"elapsed":8,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"c6153f50-80ae-473b-f962-22c8ad8af589"},"execution_count":104,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'accuracy': 77.82152230971128,\n"," 'f1': 0.777818684489412,\n"," 'precision': 0.7778787744509671,\n"," 'recall': 0.7782152230971129}"]},"metadata":{},"execution_count":104}]},{"cell_type":"code","source":["# Add my combined results to the results DataFrame\n","all_model_results.loc[\"ensemble_results\"] = ensemble_results"],"metadata":{"id":"b-AP_IdHcWKN","executionInfo":{"status":"ok","timestamp":1641217306427,"user_tz":300,"elapsed":6,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":105,"outputs":[]},{"cell_type":"code","source":["# Convert the accuracy to the same scale as the rest of the results\n","all_model_results.loc[\"ensemble_results\"][\"accuracy\"] = all_model_results.loc[\"ensemble_results\"][\"accuracy\"]/100"],"metadata":{"id":"pxJgIwVxboAs","executionInfo":{"status":"ok","timestamp":1641217306428,"user_tz":300,"elapsed":7,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":106,"outputs":[]},{"cell_type":"code","source":["all_model_results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"CcQbq3IocH7J","executionInfo":{"status":"ok","timestamp":1641217306428,"user_tz":300,"elapsed":7,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"6cb165c7-abd6-4a94-ab53-7998260a79c6"},"execution_count":107,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-6a4f72ea-900f-4569-b5e9-5618e5f26cfb\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>accuracy</th>\n","      <th>precision</th>\n","      <th>recall</th>\n","      <th>f1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>baseline</th>\n","      <td>0.792651</td>\n","      <td>0.811139</td>\n","      <td>0.792651</td>\n","      <td>0.786219</td>\n","    </tr>\n","    <tr>\n","      <th>simple_dense</th>\n","      <td>0.787402</td>\n","      <td>0.791492</td>\n","      <td>0.787402</td>\n","      <td>0.784697</td>\n","    </tr>\n","    <tr>\n","      <th>lstm</th>\n","      <td>0.750656</td>\n","      <td>0.751008</td>\n","      <td>0.750656</td>\n","      <td>0.748927</td>\n","    </tr>\n","    <tr>\n","      <th>gru</th>\n","      <td>0.767717</td>\n","      <td>0.767545</td>\n","      <td>0.767717</td>\n","      <td>0.766793</td>\n","    </tr>\n","    <tr>\n","      <th>bidirectional</th>\n","      <td>0.766404</td>\n","      <td>0.766590</td>\n","      <td>0.766404</td>\n","      <td>0.765121</td>\n","    </tr>\n","    <tr>\n","      <th>conv1d</th>\n","      <td>0.783465</td>\n","      <td>0.787212</td>\n","      <td>0.783465</td>\n","      <td>0.780780</td>\n","    </tr>\n","    <tr>\n","      <th>tf_hub_sentence_encoder</th>\n","      <td>0.811024</td>\n","      <td>0.814034</td>\n","      <td>0.811024</td>\n","      <td>0.809202</td>\n","    </tr>\n","    <tr>\n","      <th>tf_hub_10_precent_data</th>\n","      <td>0.770341</td>\n","      <td>0.775133</td>\n","      <td>0.770341</td>\n","      <td>0.766871</td>\n","    </tr>\n","    <tr>\n","      <th>ensemble_results</th>\n","      <td>0.778215</td>\n","      <td>0.777879</td>\n","      <td>0.778215</td>\n","      <td>0.777819</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a4f72ea-900f-4569-b5e9-5618e5f26cfb')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6a4f72ea-900f-4569-b5e9-5618e5f26cfb button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6a4f72ea-900f-4569-b5e9-5618e5f26cfb');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                         accuracy  precision    recall        f1\n","baseline                 0.792651   0.811139  0.792651  0.786219\n","simple_dense             0.787402   0.791492  0.787402  0.784697\n","lstm                     0.750656   0.751008  0.750656  0.748927\n","gru                      0.767717   0.767545  0.767717  0.766793\n","bidirectional            0.766404   0.766590  0.766404  0.765121\n","conv1d                   0.783465   0.787212  0.783465  0.780780\n","tf_hub_sentence_encoder  0.811024   0.814034  0.811024  0.809202\n","tf_hub_10_precent_data   0.770341   0.775133  0.770341  0.766871\n","ensemble_results         0.778215   0.777879  0.778215  0.777819"]},"metadata":{},"execution_count":107}]},{"cell_type":"markdown","metadata":{"id":"HZwqwF_swdIA"},"source":["How did the stacked model go against the other models?\n","\n","> üîë **Note:** It seems many of our model's results are similar. This may mean there are some limitations to what can be learned from our data. When many of your modelling experiments return similar results, it's a good idea to revisit your data, we'll do this shortly."]},{"cell_type":"markdown","metadata":{"id":"UpwErZOgX_nC"},"source":["## Saving and loading a trained model\n","\n","Although training time didn't take very long, it's good practice to save your trained models to avoid having to retrain them.\n","\n","Saving your models also enables you to export them for use elsewhere outside of your notebooks, such as in a web application.\n","\n","There are two main ways of [saving a model in TensorFlow](https://www.tensorflow.org/tutorials/keras/save_and_load#save_the_entire_model):\n","1. The `HDF5` format. \n","2. The `SavedModel` format (default).\n","\n","Let's take a look at both."]},{"cell_type":"code","source":["# Save TF Hub Sentence Encoder model to HDF5 format\n","model_6.save(\"model_6.h5\")"],"metadata":{"id":"vxw2fC6fdatc","executionInfo":{"status":"ok","timestamp":1641217311301,"user_tz":300,"elapsed":4880,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":108,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Cp6zvmprm9A3"},"source":["If you save a model as a `HDF5`, when loading it back in, you need to let [TensorFlow know about any custom objects you've used](https://www.tensorflow.org/tutorials/keras/save_and_load#saving_custom_objects) (e.g. components which aren't built from pure TensorFlow, such as TensorFlow Hub components)."]},{"cell_type":"code","source":["# Load model with custom Hub layer (required with HDF5 format)\n","loaded_model_6 = tf.keras.models.load_model(\"model_6.h5\",\n","                                            custom_objects={\"KerasLayer\": hub.KerasLayer})"],"metadata":{"id":"e5goqZh2d6Qj","executionInfo":{"status":"ok","timestamp":1641217318000,"user_tz":300,"elapsed":6709,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":109,"outputs":[]},{"cell_type":"code","source":["# How does my loaded model preform?\n","loaded_model_6.evaluate(val_sentences, val_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j1XE9Pg8eV_R","executionInfo":{"status":"ok","timestamp":1641217319129,"user_tz":300,"elapsed":1137,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"b8539d30-cf4e-4670-ad91-45942b66486d"},"execution_count":110,"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 1s 11ms/step - loss: 0.4288 - accuracy: 0.8110\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.42878758907318115, 0.8110235929489136]"]},"metadata":{},"execution_count":110}]},{"cell_type":"markdown","metadata":{"id":"02rbT4fwn0It"},"source":["Calling the `save()` method on our target model and passing it a filepath allows us to save our model in the `SavedModel` format. "]},{"cell_type":"code","source":["# Save TF Hub Sentence Encoder model to SaveModel format (default)\n","model_6.save(\"model_6_SavedModel_format\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RGhT24FueiZp","executionInfo":{"status":"ok","timestamp":1641217329591,"user_tz":300,"elapsed":10464,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"a6e0cc06-c55f-4bb7-f825-902b7e68708c"},"execution_count":111,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Function `_wrapped_model` contains input name(s) USE_input with unsupported characters which will be renamed to use_input in the SavedModel.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: model_6_SavedModel_format/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: model_6_SavedModel_format/assets\n"]}]},{"cell_type":"markdown","metadata":{"id":"l-t01S-JoOqK"},"source":["If you use SavedModel format (default), you can reload your model without specifying custom objects using the [`tensorflow.keras.models.load_model()`](https://www.tensorflow.org/tutorials/keras/save_and_load) function."]},{"cell_type":"code","source":["# Load TF Hub Sentence Encoder SavedModel\n","loaded_model_6_SavedModel = tf.keras.models.load_model(\"model_6_SavedModel_format\")"],"metadata":{"id":"4iq3Eo-Re1qH","executionInfo":{"status":"ok","timestamp":1641217334855,"user_tz":300,"elapsed":5275,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":112,"outputs":[]},{"cell_type":"code","source":["# Evaluate the SavedModel\n","loaded_model_6_SavedModel.evaluate(val_sentences, val_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tjqOWk7EfIHf","executionInfo":{"status":"ok","timestamp":1641217335483,"user_tz":300,"elapsed":639,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"167f8615-8d04-4c6e-bf85-a8e885fa56cc"},"execution_count":113,"outputs":[{"output_type":"stream","name":"stdout","text":["24/24 [==============================] - 1s 10ms/step - loss: 0.4288 - accuracy: 0.8110\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.42878758907318115, 0.8110235929489136]"]},"metadata":{},"execution_count":113}]},{"cell_type":"markdown","metadata":{"id":"xzp3SHi3oQ3u"},"source":["As you can see saving and loading our model with either format results in the same performance.\n","\n","> ü§î **Question:** Should you used the `SavedModel` format or `HDF5` format?\n","\n","For most use cases, the `SavedModel` format will suffice. However, this is a TensorFlow specific standard. If you need a more general-purpose data standard, `HDF5` might be better. For more, check out the [TensorFlow documentation on saving and loading models](https://www.tensorflow.org/tutorials/keras/save_and_load)."]},{"cell_type":"markdown","metadata":{"id":"V5a1648rG3z1"},"source":["## Finding the most wrong examples\n","\n","We mentioned before that if many of our modelling experiments are returning similar results, despite using different kinds of models, it's a good idea to return to the data and inspect why this might be.\n","\n","One of the best ways to inspect your data is to sort your model's predictions and find the samples it got *most* wrong, meaning, what predictions had a high prediction probability but turned out to be wrong.\n","\n","Once again, visualization is your friend. Visualize, visualize, visualize.\n","\n","To make things visual, let's take our best performing model's prediction probabilities and classes along with the validation samples (text and ground truth labels) and combine them in a pandas DataFrame.\n","\n","* If our best model still isn't perfect, what examples is it getting wrong? \n","* Which ones are the *most* wrong?\n","* Are there some labels which are wrong? E.g. the model gets it right but the ground truth label doesn't reflect this"]},{"cell_type":"code","source":["# Create dataframe with validation sentences & best preforming model predictions\n","val_df = pd.DataFrame({\"text\": val_sentences,\n","                       \"target\": val_labels,\n","                       \"pred\": model_6_preds,\n","                       \"pred_prob\": tf.squeeze(model_6_pred_probs)})\n","val_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"qGUBJ5A7fR57","executionInfo":{"status":"ok","timestamp":1641217335483,"user_tz":300,"elapsed":10,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"d51cb69e-3a6e-4c82-a3f3-7eb5190baa2d"},"execution_count":114,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-4dd9d48b-9388-440a-954b-dec99f546c8d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>target</th>\n","      <th>pred</th>\n","      <th>pred_prob</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>DFR EP016 Monthly Meltdown - On Dnbheaven 2015...</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.153001</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>FedEx no longer to transport bioterror germs i...</td>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>0.736035</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Gunmen kill four in El Salvador bus attack: Su...</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","      <td>0.988608</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>@camilacabello97 Internally and externally scr...</td>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>0.197211</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Radiation emergency #preparedness starts with ...</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","      <td>0.729859</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4dd9d48b-9388-440a-954b-dec99f546c8d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4dd9d48b-9388-440a-954b-dec99f546c8d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4dd9d48b-9388-440a-954b-dec99f546c8d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                                text  target  pred  pred_prob\n","0  DFR EP016 Monthly Meltdown - On Dnbheaven 2015...       0   0.0   0.153001\n","1  FedEx no longer to transport bioterror germs i...       0   1.0   0.736035\n","2  Gunmen kill four in El Salvador bus attack: Su...       1   1.0   0.988608\n","3  @camilacabello97 Internally and externally scr...       1   0.0   0.197211\n","4  Radiation emergency #preparedness starts with ...       1   1.0   0.729859"]},"metadata":{},"execution_count":114}]},{"cell_type":"markdown","metadata":{"id":"SKJ9dTbPrIG4"},"source":["Oh yeah! Now let's find our model's wrong predictions (where `target != pred`) and sort them by their prediction probability (the `pred_prob` column)."]},{"cell_type":"code","source":["# Find the wrong predictions & sort by prediction probabilities\n","most_wrong = val_df[val_df[\"target\"] != val_df[\"pred\"]].sort_values(\"pred_prob\", ascending=False)\n","most_wrong[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"sDp0yKeigFmX","executionInfo":{"status":"ok","timestamp":1641217335483,"user_tz":300,"elapsed":9,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"38def095-6a7d-460a-e100-9264f6cacc6f"},"execution_count":115,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-4a7b5df1-0df1-47ad-855d-6d3e4437d62b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>target</th>\n","      <th>pred</th>\n","      <th>pred_prob</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>31</th>\n","      <td>? High Skies - Burning Buildings ? http://t.co...</td>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>0.921534</td>\n","    </tr>\n","    <tr>\n","      <th>759</th>\n","      <td>FedEx will no longer transport bioterror patho...</td>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>0.865690</td>\n","    </tr>\n","    <tr>\n","      <th>628</th>\n","      <td>@noah_anyname That's where the concentration c...</td>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>0.855621</td>\n","    </tr>\n","    <tr>\n","      <th>393</th>\n","      <td>@SonofLiberty357 all illuminated by the bright...</td>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>0.848242</td>\n","    </tr>\n","    <tr>\n","      <th>49</th>\n","      <td>@madonnamking RSPCA site multiple 7 story high...</td>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>0.824809</td>\n","    </tr>\n","    <tr>\n","      <th>209</th>\n","      <td>Ashes 2015: Australia¬â√õ¬™s collapse at Trent Br...</td>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>0.808441</td>\n","    </tr>\n","    <tr>\n","      <th>109</th>\n","      <td>[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...</td>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>0.798078</td>\n","    </tr>\n","    <tr>\n","      <th>251</th>\n","      <td>@AshGhebranious civil rights continued in the ...</td>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>0.788634</td>\n","    </tr>\n","    <tr>\n","      <th>144</th>\n","      <td>The Sound of Arson</td>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>0.778225</td>\n","    </tr>\n","    <tr>\n","      <th>695</th>\n","      <td>A look at state actions a year after Ferguson'...</td>\n","      <td>0</td>\n","      <td>1.0</td>\n","      <td>0.768311</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a7b5df1-0df1-47ad-855d-6d3e4437d62b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4a7b5df1-0df1-47ad-855d-6d3e4437d62b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4a7b5df1-0df1-47ad-855d-6d3e4437d62b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                                  text  target  pred  pred_prob\n","31   ? High Skies - Burning Buildings ? http://t.co...       0   1.0   0.921534\n","759  FedEx will no longer transport bioterror patho...       0   1.0   0.865690\n","628  @noah_anyname That's where the concentration c...       0   1.0   0.855621\n","393  @SonofLiberty357 all illuminated by the bright...       0   1.0   0.848242\n","49   @madonnamking RSPCA site multiple 7 story high...       0   1.0   0.824809\n","209  Ashes 2015: Australia¬â√õ¬™s collapse at Trent Br...       0   1.0   0.808441\n","109  [55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...       0   1.0   0.798078\n","251  @AshGhebranious civil rights continued in the ...       0   1.0   0.788634\n","144                                 The Sound of Arson       0   1.0   0.778225\n","695  A look at state actions a year after Ferguson'...       0   1.0   0.768311"]},"metadata":{},"execution_count":115}]},{"cell_type":"markdown","metadata":{"id":"r3VcRHOusB2D"},"source":["Finally, we can write some code to visualize the sample text, truth label, prediction class and prediction probability. Because we've sorted our samples by prediction probability, viewing samples from the head of our `most_wrong` DataFrame will show us false positives.\n","\n","A reminder:\n","* `0` = Not a real diaster Tweet\n","* `1` = Real diaster Tweet"]},{"cell_type":"code","source":["# Check the false positives (model predicted 1 when there should've been 0)\n","for row in most_wrong[:10].itertuples(): # loop through top 10 rows(changed index to view different rows)\n","  _, text, target, pred, prob = row\n","  print(f\"Target: {target}, Pred: {int(pred)}, Prob: {prob}\")\n","  print(f\"Text:\\n{text}\\n\")\n","  print(\"----\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jVTxSnhwhMrE","executionInfo":{"status":"ok","timestamp":1641217335484,"user_tz":300,"elapsed":8,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"b3442282-db4c-4960-dc9f-efe964da23ef"},"execution_count":116,"outputs":[{"output_type":"stream","name":"stdout","text":["Target: 0, Pred: 1, Prob: 0.9215342402458191\n","Text:\n","? High Skies - Burning Buildings ? http://t.co/uVq41i3Kx2 #nowplaying\n","\n","----\n","\n","Target: 0, Pred: 1, Prob: 0.8656902313232422\n","Text:\n","FedEx will no longer transport bioterror pathogens in wake of anthrax lab mishaps http://t.co/lHpgxc4b8J\n","\n","----\n","\n","Target: 0, Pred: 1, Prob: 0.8556209206581116\n","Text:\n","@noah_anyname That's where the concentration camps and mass murder come in. \n"," \n","EVERY. FUCKING. TIME.\n","\n","----\n","\n","Target: 0, Pred: 1, Prob: 0.8482416868209839\n","Text:\n","@SonofLiberty357 all illuminated by the brightly burning buildings all around the town!\n","\n","----\n","\n","Target: 0, Pred: 1, Prob: 0.8248089551925659\n","Text:\n","@madonnamking RSPCA site multiple 7 story high rise buildings next to low density character residential in an area that floods\n","\n","----\n","\n","Target: 0, Pred: 1, Prob: 0.8084411025047302\n","Text:\n","Ashes 2015: Australia¬â√õ¬™s collapse at Trent Bridge among worst in history: England bundled out Australia for 60 ... http://t.co/t5TrhjUAU0\n","\n","----\n","\n","Target: 0, Pred: 1, Prob: 0.7980775237083435\n","Text:\n","[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES WITH MAGNE-TRACTION INSTRUCTIONS http://t.co/xEZBs3sq0y http://t.co/C2x0QoKGlY\n","\n","----\n","\n","Target: 0, Pred: 1, Prob: 0.7886338233947754\n","Text:\n","@AshGhebranious civil rights continued in the 60s. And what about trans-generational trauma? if anything we should listen to the Americans.\n","\n","----\n","\n","Target: 0, Pred: 1, Prob: 0.7782250642776489\n","Text:\n","The Sound of Arson\n","\n","----\n","\n","Target: 0, Pred: 1, Prob: 0.7683106660842896\n","Text:\n","A look at state actions a year after Ferguson's upheaval http://t.co/GZEkQWzijq\n","\n","----\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"aXCH9J-UspWg"},"source":["We can view the bottom end of our `most_wrong` DataFrame to inspect false negatives (model predicts 0, not a real diaster Tweet, when it should've predicted 1, real diaster Tweet)."]},{"cell_type":"code","source":["# Check the most wrong false negatives (model predicted 0 when should've predicted 1)\n","for row in most_wrong[-10:].itertuples():\n","  _, text, target, pred, prob = row\n","  print(f\"Target: {target}, Pred: {int(pred)}, Prob: {prob}\")\n","  print(f\"Text:\\n{text}\\n\")\n","  print(\"----\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LySYye_aimP7","executionInfo":{"status":"ok","timestamp":1641217335790,"user_tz":300,"elapsed":312,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"39f1d57d-eb1e-46bd-fafe-a00d76b278c9"},"execution_count":117,"outputs":[{"output_type":"stream","name":"stdout","text":["Target: 1, Pred: 0, Prob: 0.06631091237068176\n","Text:\n","going to redo my nails and watch behind the scenes of desolation of smaug ayyy\n","\n","----\n","\n","Target: 1, Pred: 0, Prob: 0.05989748239517212\n","Text:\n","'The way you move is like a full on rainstorm and I'm a house of cards'\n","\n","----\n","\n","Target: 1, Pred: 0, Prob: 0.05881589651107788\n","Text:\n","@willienelson We need help! Horses will die!Please RT &amp; sign petition!Take a stand &amp; be a voice for them! #gilbert23 https://t.co/e8dl1lNCVu\n","\n","----\n","\n","Target: 1, Pred: 0, Prob: 0.05743184685707092\n","Text:\n","Lucas Duda is Ghost Rider. Not the Nic Cage version but an actual 'engulfed in flames' badass. #Mets\n","\n","----\n","\n","Target: 1, Pred: 0, Prob: 0.05466252565383911\n","Text:\n","You can never escape me. Bullets don't harm me. Nothing harms me. But I know pain. I know pain. Sometimes I share it. With someone like you.\n","\n","----\n","\n","Target: 1, Pred: 0, Prob: 0.048963695764541626\n","Text:\n","I get to smoke my shit in peace\n","\n","----\n","\n","Target: 1, Pred: 0, Prob: 0.04371175169944763\n","Text:\n","Why are you deluged with low self-image? Take the quiz: http://t.co/XsPqdOrIqj http://t.co/CQYvFR4UCy\n","\n","----\n","\n","Target: 1, Pred: 0, Prob: 0.041881293058395386\n","Text:\n","Reddit Will Now Quarantine¬â√õ_ http://t.co/pkUAMXw6pm #onlinecommunities #reddit #amageddon #freespeech #Business http://t.co/PAWvNJ4sAP\n","\n","----\n","\n","Target: 1, Pred: 0, Prob: 0.03972312808036804\n","Text:\n","@SoonerMagic_ I mean I'm a fan but I don't need a girl sounding off like a damn siren\n","\n","----\n","\n","Target: 1, Pred: 0, Prob: 0.03918871283531189\n","Text:\n","Ron &amp; Fez - Dave's High School Crush https://t.co/aN3W16c8F6 via @YouTube\n","\n","----\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"lRKQPEAgtpJq"},"source":["Do you notice anything interesting about the most wrong samples?\n","\n","Are the ground truth labels correct? What do you think would happen if we went back and corrected the labels which aren't?"]},{"cell_type":"markdown","metadata":{"id":"U0W3DWgWJCWs"},"source":["## Making predictions on the test dataset\n","\n","Alright we've seen how our model's perform on the validation set.\n","\n","But how about the test dataset?\n","\n","We don't have labels for the test dataset so we're going to have to make some predictions and inspect them for ourselves.\n","\n","Let's write some code to make predictions on random samples from the test dataset and visualize them."]},{"cell_type":"code","source":["# Making predictions on the test dataset\n","test_sentences = test_df[\"text\"].to_list()\n","test_samples = random.sample(test_sentences, 10)\n","for test_sample in test_samples:\n","  pred_prob = tf.squeeze(model_6.predict([test_sample])) # has to be list\n","  pred = tf.round(pred_prob)\n","  print(f\"Pred: {int(pred)}, Prob: {pred_prob}\")\n","  print(f\"Text:\\n{test_sample}\\n\")\n","  print(\"----\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VRGXWW5Ujfh2","executionInfo":{"status":"ok","timestamp":1641217336496,"user_tz":300,"elapsed":712,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"686954d4-c075-42c9-a32a-8a6c3ef73be7"},"execution_count":118,"outputs":[{"output_type":"stream","name":"stdout","text":["Pred: 0, Prob: 0.14816993474960327\n","Text:\n","@Brandon_Warne MLB has that ball at 462 feet.  Absolutely crushed.\n","\n","----\n","\n","Pred: 0, Prob: 0.4855524003505707\n","Text:\n","MEG issues Hazardous Weather Outlook (HWO) http://t.co/3X6RBQJHn3\n","\n","----\n","\n","Pred: 0, Prob: 0.29936906695365906\n","Text:\n","@fouseyTUBE @zaynmalik I would collapse\n","\n","----\n","\n","Pred: 1, Prob: 0.9439432621002197\n","Text:\n","Buildings on fire behind Tisa's in Niceville @tristapnwfdn https://t.co/ACl1baBacR\n","\n","----\n","\n","Pred: 1, Prob: 0.9484628438949585\n","Text:\n","#calgaryweather  It would be nice if they would fix radar before another violent storm  Uninformed citizens dangerous #YYC #yycweather\n","\n","----\n","\n","Pred: 0, Prob: 0.14931738376617432\n","Text:\n","@preeti_chopra2 @chinmaykrvd many predicted landslide for nitish nd told bjp will loose bihar nd won't even get upper castes votes\n","\n","----\n","\n","Pred: 0, Prob: 0.19857656955718994\n","Text:\n","Sammy is here in this war zone. Jamal spoke to me on the phone. Now my wife is next to speak to me ...what else can&gt; http://t.co/2CppfprxoG\n","\n","----\n","\n","Pred: 1, Prob: 0.8128272294998169\n","Text:\n","Do you know your hurricane evacuation route? Find it here: http://t.co/mWMVIcdW9O\n","\n","----\n","\n","Pred: 0, Prob: 0.2754998803138733\n","Text:\n","Newlyweds feed Syrian refugees at their wedding http://t.co/DGjBuGxH9E #changetheworld #SyrianRefugees\n","\n","----\n","\n","Pred: 1, Prob: 0.6154356002807617\n","Text:\n","#Turkey invades #Israel - Halfway to #Armageddon http://t.co/xUOh3sJNXF\n","\n","----\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"QcvI5zgJ0Tgp"},"source":["How do our model's predictions look on the test dataset?\n","\n","It's important to do these kind of visualization checks as often as possible to get a glance of how your model performs on unseen data and subsequently how it might perform on the real test: Tweets from the wild."]},{"cell_type":"markdown","metadata":{"id":"eT1jhk8xdod5"},"source":["## Predicting on Tweets from the wild\n","\n","How about we find some Tweets and use our model to predict whether or not they're about a diaster or not?\n","\n","To start, let's take one of my own [Tweets on living life like an ensemble model](https://twitter.com/mrdbourke/status/1313649328351662082). "]},{"cell_type":"code","source":["# Turn Tweet into string\n","daniels_tweet = \"Life like an ensemble: take the best choices from others and make them your own\""],"metadata":{"id":"2L5AN42vlEzc","executionInfo":{"status":"ok","timestamp":1641217336496,"user_tz":300,"elapsed":6,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":119,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uPbZaGznvbEx"},"source":["Now we'll write a small function to take a model and an example sentence and return a prediction."]},{"cell_type":"code","source":["def predict_on_sentence(model, sentence):\n","  \"\"\"\n","  Uses model to make a prediction on sentence.\n","\n","  Returns the sentence, the predicted label & the prediction probability.\n","  \"\"\"\n","  pred_prob = model.predict([sentence])\n","  pred_label = tf.squeeze(tf.round(pred_prob)).numpy()\n","  print(f\"Pred: {pred_label}\", \"(real disaster)\" if pred_label > 0 else \"(not real disaster)\", f\"Prob: {pred_prob[0][0]}\")\n","  print(f\"Text:\\n{sentence}\")"],"metadata":{"id":"N_ydYwlImFgf","executionInfo":{"status":"ok","timestamp":1641217336496,"user_tz":300,"elapsed":5,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":120,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IvCG4RuUvj6d"},"source":["Great! Time to test our model out."]},{"cell_type":"code","source":["# Make a predicton on Tweet from the wild!\n","predict_on_sentence(model=model_6, # use the USE model\n","                    sentence=\"Planet wide nuke. Billions dead. The imperium is calling for disaster relief.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dtl3sxhYnJGn","executionInfo":{"status":"ok","timestamp":1641217336496,"user_tz":300,"elapsed":5,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"06f5c926-7785-47bf-c72b-93c1c43e1aac"},"execution_count":121,"outputs":[{"output_type":"stream","name":"stdout","text":["Pred: 1.0 (real disaster) Prob: 0.5404251217842102\n","Text:\n","Planet wide nuke. Billions dead. The imperium is calling for disaster relief.\n"]}]},{"cell_type":"markdown","metadata":{"id":"tYOfNacw08Of"},"source":["Woohoo! Our model predicted correctly. My Tweet wasn't about a diaster.\n","\n","How about we find a few Tweets about actual diasters?\n","\n","Such as the following two Tweets about the 2020 Beirut explosions."]},{"cell_type":"code","source":["# source - https://twitter.com/BeirutCityGuide/status/1290696551376007168\n","beirut_tweet_1 = \"Reports that the smoke in Beirut sky contains nitric acid, which is toxic. Please share and refrain from stepping outside unless urgent. #Lebanon\"\n","\n","# Sourse - https://twitter.com/BeirutCityGuide/status/1290773498743476224\n","beirut_tweet_2 = \"#Beirut declared a ‚Äúdevastated city‚Äù, two-week state of emergency officially declared. #Lebanon\""],"metadata":{"id":"Yo30r1-Dn9ZO","executionInfo":{"status":"ok","timestamp":1641217336497,"user_tz":300,"elapsed":6,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":122,"outputs":[]},{"cell_type":"code","source":["# Predict on disaster Tweet 1\n","predict_on_sentence(model=model_6,\n","                    sentence=beirut_tweet_1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qnHSzgeFpnvG","executionInfo":{"status":"ok","timestamp":1641217336497,"user_tz":300,"elapsed":5,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"07d849ea-f809-4e40-d81f-9ff0bb9cf407"},"execution_count":123,"outputs":[{"output_type":"stream","name":"stdout","text":["Pred: 1.0 (real disaster) Prob: 0.967134952545166\n","Text:\n","Reports that the smoke in Beirut sky contains nitric acid, which is toxic. Please share and refrain from stepping outside unless urgent. #Lebanon\n"]}]},{"cell_type":"code","source":["# Predict on dissaster Tweet 2\n","predict_on_sentence(model=model_6,\n","                    sentence=beirut_tweet_2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dqZrAgPvrHl2","executionInfo":{"status":"ok","timestamp":1641217336497,"user_tz":300,"elapsed":5,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"22b8271f-2af1-4961-e776-99adfe0430bb"},"execution_count":124,"outputs":[{"output_type":"stream","name":"stdout","text":["Pred: 1.0 (real disaster) Prob: 0.9725768566131592\n","Text:\n","#Beirut declared a ‚Äúdevastated city‚Äù, two-week state of emergency officially declared. #Lebanon\n"]}]},{"cell_type":"markdown","metadata":{"id":"fczP1dFcwe98"},"source":["Looks like our model is performing as expected, predicting both of the diaster Tweets as actual diasters.\n","\n","> üîë **Note:** The above examples are cherry-picked and are cases where you'd expect a model to function at high performance. For actual production systems, you'll want to continaully perform tests to see how your model is performing."]},{"cell_type":"markdown","metadata":{"id":"Fp0fkK-tHPRE"},"source":["## The speed/score tradeoff\n","\n","One of the final tests we're going to do is to find the speed/score tradeoffs between our best model and baseline model.\n","\n","Why is this important?\n","\n","Although it can be tempting to just choose the best performing model you find through experimentation, this model might not actually work in a production setting.\n","\n","Put it this way, imagine you're Twitter and receive 1 million Tweets per hour (this is a made up number, the actual number is much higher). And you're trying to build a diaster detection system to read Tweets and alert authorities with details about a diaster in close to real-time.\n","\n","Compute power isn't free so you're limited to a single compute machine for the project. On that machine, one of your models makes 10,000 predictions per second at 80% accuracy where as another one of your models (a larger model) makes 100 predictions per second at 85% accuracy.\n","\n","Which model do you choose?\n","\n","Is the second model's performance boost worth missing out on the extra capacity?\n","\n","Of course, there are many options you could try here, such as sending as many Tweets as possible to the first model and then sending the ones which the model is least certain of to the second model. \n","\n","The point here is to illustrate the best model you find through experimentation, might not be the model you end up using in production.\n","\n","To make this more concrete, let's write a function to take a model and a number of samples and time how long the given model takes to make predictions on those samples."]},{"cell_type":"code","source":["# Calculate the time of predictions\n","import time\n","def pred_timer(model, samples):\n","  \"\"\"\n","  Times how long a model takes to make predictions on samples.\n","\n","  Args:\n","  ----\n","  model = a trained model\n","  sample = a list of samples\n","\n","  Returns:\n","  ----\n","  total_time = total elapsed time for model to make predictions on samples\n","  time_per_pred = time in seconds per single sample\n","  \"\"\"\n","  start_time = time.perf_counter() # get the start time\n","  model.predict(samples) # makes predictions\n","  end_time = time.perf_counter() # get finish time\n","  total_time = end_time-start_time # calculate how long it took to make predictions\n","  time_per_pred = total_time/len(samples) # find prediction time per sample\n","  return total_time, time_per_pred"],"metadata":{"id":"_dDKvUo6rYSw","executionInfo":{"status":"ok","timestamp":1641217336497,"user_tz":300,"elapsed":4,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":125,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GxWwS73hze6Z"},"source":["Looking good!\n","\n","Now let's use our `pred_timer()` function to evaluate the prediction times of our best performing model (`model_6`) and our baseline model (`model_0`)."]},{"cell_type":"code","source":["# Calculate TF Hub Sentence Encoder prediction times\n","model_6_total_pred_time, model_6_time_per_pred = pred_timer(model_6, val_sentences)\n","model_6_total_pred_time, model_6_time_per_pred"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CYreqQPTtWrN","executionInfo":{"status":"ok","timestamp":1641217336786,"user_tz":300,"elapsed":293,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"84d6c73b-5ab9-4e70-b4c6-ce6e71afe2f3"},"execution_count":126,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0.23660123700000213, 0.00031050031102362484)"]},"metadata":{},"execution_count":126}]},{"cell_type":"code","source":["# Calculate Naive Bayes prediction times\n","baseline_total_pred_time, baseline_time_per_pred = pred_timer(model_0, val_sentences)\n","baseline_total_pred_time, baseline_time_per_pred"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jcUIOg8Bt9lg","executionInfo":{"status":"ok","timestamp":1641217336786,"user_tz":300,"elapsed":3,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"90f1e3e7-90b0-4213-cb62-938df011c9f0"},"execution_count":127,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0.020263333999992028, 2.659230183725988e-05)"]},"metadata":{},"execution_count":127}]},{"cell_type":"markdown","metadata":{"id":"nqNnKMxhz8Kl"},"source":["It seems with our current hardware (in my case, I'm using a Google Colab notebook) our best performing model takes over 10x the time to make predictions as our baseline model.\n","\n","Is that extra prediction time worth it?\n","\n","Let's compare time per prediction versus our model's F1-scores."]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(10, 7))\n","plt.scatter(baseline_time_per_pred, baseline_results[\"f1\"], label=\"baseline\")\n","plt.scatter(model_6_time_per_pred, model_6_results[\"f1\"], label=\"tf_hub_sentence_encoder\")\n","plt.legend()\n","plt.title(\"F1-score vs. time per prediction\")\n","plt.xlabel(\"Time per prediction\")\n","plt.ylabel(\"F1-Score\");"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"s3kBtGszuV0f","executionInfo":{"status":"ok","timestamp":1641217337173,"user_tz":300,"elapsed":390,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"bea5329a-5653-4ae7-d044-13b648aa6bec"},"execution_count":128,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 720x504 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"QlHdTqTl0aOq"},"source":["![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/08-ideal-performance-speed-of-pred-tradeoff-highlighted.png)\n","*Ideal position for speed and performance tradeoff model (fast predictions with great results).*\n","\n","Of course, the ideal position for each of these dots is to be in the top left of the plot (low time per prediction, high F1-score). \n","\n","In our case, there's a clear tradeoff for time per prediction and performance. Our best performing model takes an order of magnitude longer per prediction but only results in a few F1-score point increase.\n","\n","This kind of tradeoff is something you'll need to keep in mind when incorporating machine learning models into your own applications."]},{"cell_type":"markdown","metadata":{"id":"DJWGI6GpH4Gl"},"source":["##Exercises\n","\n","1. Rebuild, compile and train `model_1`, `model_2` and `model_5` using the [Keras Sequential API](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) instead of the Functional API.\n","2. Retrain the baseline model with 10% of the training data. How does perform compared to the Universal Sentence Encoder model with 10% of the training data?\n","3. Try fine-tuning the TF Hub Universal Sentence Encoder model by setting `training=True` when instantiating it as a Keras layer.\n","\n","```\n","We can use this encoding layer in place of our text_vectorizer and embedding layer\n","\n","sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n","                                        input_shape=[],\n","                                        dtype=tf.string,\n","                                        trainable=True) # turn training on to fine-tune the TensorFlow Hub model\n","```\n","4. Retrain the best model you've got so far on the whole training set (no validation split). Then use this trained model to make predictions on the test dataset and format the predictions into the same format as the `sample_submission.csv` file from Kaggle (see the Files tab in Colab for what the `sample_submission.csv` file looks like). Once you've done this, [make a submission to the Kaggle competition](https://www.kaggle.com/c/nlp-getting-started/data), how did your model perform?\n","5. Combine the ensemble predictions using the majority vote (mode), how does this perform compare to averaging the prediction probabilities of each model?\n","6. Make a confusion matrix with the best performing model's predictions on the validation set and the validation ground truth labels."]},{"cell_type":"markdown","metadata":{"id":"BarVJji8H6M4"},"source":["##Extra-curriculum \n","\n","To practice what you've learned, a good idea would be to spend an hour on 3 of the following (3-hours total, you could through them all if you want) and then write a blog post about what you've learned.\n","\n","* For an overview of the different problems within NLP and how to solve them read through: \n"," * [A Simple Introduction to Natural Language Processing](https://becominghuman.ai/a-simple-introduction-to-natural-language-processing-ea66a1747b32)\n"," * [How to solve 90% of NLP problems: a step-by-step guide](https://blog.insightdatascience.com/how-to-solve-90-of-nlp-problems-a-step-by-step-guide-fda605278e4e)\n","* Go through [MIT's Recurrent Neural Networks lecture](https://youtu.be/SEnXr6v2ifU). This will be one of the greatest additions to what's happening behind the RNN model's you've been building.\n","* Read through the [word embeddings page on the TensorFlow website](https://www.tensorflow.org/tutorials/text/word_embeddings). Embeddings are such a large part of NLP. We've covered them throughout this notebook but extra practice would be well worth it. A good exercise would be to write out all the code in the guide in a new notebook. \n","* For more on RNN's in TensorFlow, read and reproduce [the TensorFlow RNN guide](https://www.tensorflow.org/guide/keras/rnn). We've covered many of the concepts in this guide, but it's worth writing the code again for yourself.\n","* Text data doesn't always come in a nice package like the data we've downloaded. So if you're after more on preparing different text sources for being with your TensorFlow deep learning models, it's worth checking out the following:\n"," * [TensorFlow text loading tutorial](https://www.tensorflow.org/tutorials/load_data/text).\n","  * [Reading text files with Python](https://realpython.com/read-write-files-python/) by Real Python.\n","* This notebook has focused on writing NLP code. For a mathematically rich overview of how NLP with Deep Learning happens, read [Standford's Natural Language Processing with Deep Learning lecture notes Part 1](https://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes01-wordvecs1.pdf).  \n","  * For an even deeper dive, you could even do the whole [CS224n](http://web.stanford.edu/class/cs224n/) (Natural Language Processing with Deep Learning) course. \n","* Great blog posts to read:\n","  * Andrei Karpathy's [The Unreasonable Effectiveness of RNNs](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) dives into generating Shakespeare text with RNNs.\n","  * [Text Classification with NLP: Tf-Idf vs Word2Vec vs BERT](https://towardsdatascience.com/text-classification-with-nlp-tf-idf-vs-word2vec-vs-bert-41ff868d1794) by Mauro Di Pietro. An overview of different techniques for turning text into numbers and then classifying it.\n","  * [What are word embeddings?](https://machinelearningmastery.com/what-are-word-embeddings/) by Machine Learning Mastery.\n","* Other topics worth looking into:\n","  * [Attention mechanisms](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/). These are a foundational component of the transformer architecture and also often add improvments to deep NLP models.\n","  * [Transformer architectures](http://jalammar.github.io/illustrated-transformer/). This model architecture has recently taken the NLP world by storm, achieving state of the art on many benchmarks. However, it does take a little more processing to get off the ground, the [HuggingFace Models (formerly HuggingFace Transformers) library](https://huggingface.co/models/) is probably your best quick start.\n","    * And now [HuggingFace even have their own course](https://huggingface.co/course/chapter1) on how their library works! I haven't done it but anything HuggingFace makes is world-class.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"CLzfxgXkzEdr"},"source":["> üìñ **Resource:** See the full set of course materials on GitHub: https://github.com/mrdbourke/tensorflow-deep-learning"]},{"cell_type":"markdown","metadata":{"id":"4NG3nevdEZBs"},"source":["## Confirm access to a GPU\n","\n","Since we're going to be building deep learning models, let's make sure we have a GPU.\n","\n","In Google Colab, you can set this up by going to Runtime -> Change runtime type -> Hardware accelerator -> GPU.\n","\n","If you don't have access to a GPU, the models we're building here will likely take up to 10x longer to run."]},{"cell_type":"code","source":["# Check for GPU\n","!nvidia-smi -L"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EPgRtoR5vgQo","executionInfo":{"status":"ok","timestamp":1641217337447,"user_tz":300,"elapsed":279,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"2b708d67-b28b-46f6-87bd-235a8b920f8d"},"execution_count":129,"outputs":[{"output_type":"stream","name":"stdout","text":["NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"2MdzfDdzaQCb"},"source":["## Get data\n","\n","Before we can start building a model, we've got to download the PubMed 200k RCT dataset.\n","\n","In a phenomenal act of kindness, the authors of the paper have made the data they used for their research availably publically and for free in the form of .txt files [on GitHub](https://github.com/Franck-Dernoncourt/pubmed-rct).\n","\n","We can copy them to our local directory using `git clone https://github.com/Franck-Dernoncourt/pubmed-rct`."]},{"cell_type":"code","source":["!git clone https://github.com/Franck-Dernoncourt/pubmed-rct.git\n","!ls pubmed-rct"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TBFZECXHfPLt","executionInfo":{"status":"ok","timestamp":1641217363000,"user_tz":300,"elapsed":25554,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"06a66bcc-c2b3-4c47-c1b5-7d648c2e58a5"},"execution_count":130,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'pubmed-rct'...\n","remote: Enumerating objects: 33, done.\u001b[K\n","remote: Counting objects: 100% (3/3), done.\u001b[K\n","remote: Compressing objects: 100% (3/3), done.\u001b[K\n","remote: Total 33 (delta 0), reused 0 (delta 0), pack-reused 30\u001b[K\n","Unpacking objects: 100% (33/33), done.\n","PubMed_200k_RCT\n","PubMed_200k_RCT_numbers_replaced_with_at_sign\n","PubMed_20k_RCT\n","PubMed_20k_RCT_numbers_replaced_with_at_sign\n","README.md\n"]}]},{"cell_type":"code","source":["!ls pubmed-rct"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hoXKP5BxfaRc","executionInfo":{"status":"ok","timestamp":1641217363301,"user_tz":300,"elapsed":310,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"c196c1ea-69ee-43c5-a667-bc2e078662d7"},"execution_count":131,"outputs":[{"output_type":"stream","name":"stdout","text":["PubMed_200k_RCT\n","PubMed_200k_RCT_numbers_replaced_with_at_sign\n","PubMed_20k_RCT\n","PubMed_20k_RCT_numbers_replaced_with_at_sign\n","README.md\n"]}]},{"cell_type":"markdown","metadata":{"id":"Y3Oe1F6e7y0E"},"source":["Checking the contents of the downloaded repository, you can see there are four folders.\n","\n","Each contains a different version of the PubMed 200k RCT dataset.\n","\n","Looking at the [README file](https://github.com/Franck-Dernoncourt/pubmed-rct) from the GitHub page, we get the following information:\n","* PubMed 20k is a subset of PubMed 200k. I.e., any abstract present in PubMed 20k is also present in PubMed 200k.\n","* `PubMed_200k_RCT` is the same as `PubMed_200k_RCT_numbers_replaced_with_at_sign`, except that in the latter all numbers had been replaced by `@`. (same for `PubMed_20k_RCT` vs. `PubMed_20k_RCT_numbers_replaced_with_at_sign`).\n","* Since Github file size limit is 100 MiB, we had to compress `PubMed_200k_RCT\\train.7z` and `PubMed_200k_RCT_numbers_replaced_with_at_sign\\train.zip`. To uncompress `train.7z`, you may use 7-Zip on Windows, Keka on Mac OS X, or p7zip on Linux.\n","\n","To begin with, the dataset we're going to be focused on is `PubMed_20k_RCT_numbers_replaced_with_at_sign`.\n","\n","Why this one?\n","\n","Rather than working with the whole 200k dataset, we'll keep our experiments quick by starting with a smaller subset. We could've chosen the dataset with numbers instead of having them replaced with `@` but we didn't.\n","\n","Let's check the file contents. "]},{"cell_type":"code","source":["# Check what files are in the PubMed_20K dataset\n","!ls pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3f77P1mVfiZJ","executionInfo":{"status":"ok","timestamp":1641217363636,"user_tz":300,"elapsed":336,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"5acf7e75-7b3b-4e5b-9458-a90571b3fdfa"},"execution_count":132,"outputs":[{"output_type":"stream","name":"stdout","text":["dev.txt  test.txt  train.txt\n"]}]},{"cell_type":"markdown","metadata":{"id":"joApaTyD_DYL"},"source":["Beautiful, looks like we've got three separate text files:\n","* `train.txt` - training samples.\n","* `dev.txt` - dev is short for development set, which is another name for validation set (in our case, we'll be using and referring to this file as our validation set).\n","* `test.txt` - test samples.\n","\n","To save ourselves typing out the filepath to our target directory each time, let's turn it into a variable."]},{"cell_type":"code","source":["# Start by using the 20k dataset\n","data_dir = \"pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/\""],"metadata":{"id":"c-1o3oWMgMbS","executionInfo":{"status":"ok","timestamp":1641217363636,"user_tz":300,"elapsed":6,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":133,"outputs":[]},{"cell_type":"code","source":["# Check all files in the target dir\n","import os\n","filenames = [data_dir + filename for filename in os.listdir(data_dir)]\n","filenames"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_bQzwYF2gleY","executionInfo":{"status":"ok","timestamp":1641217363637,"user_tz":300,"elapsed":5,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"f7326b6e-f7ce-4f96-dc57-e2d9c7b85649"},"execution_count":134,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt',\n"," 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt',\n"," 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt']"]},"metadata":{},"execution_count":134}]},{"cell_type":"markdown","metadata":{"id":"BTjZ9NziaeKU"},"source":["## Preprocess data\n","\n","Okay, now we've downloaded some text data, do you think we're ready to model it?\n","\n","Wait...\n","\n","We've downloaded the data but we haven't even looked at it yet.\n","\n","What's the motto for getting familiar with any new dataset?\n","\n","I'll give you a clue, the word begins with \"v\" and we say it three times.\n","\n","> Vibe, vibe, vibe?\n","\n","Sort of... we've definitely got to the feel the vibe of our data.\n","\n","> Values, values, values?\n","\n","Right again, we want to *see* lots of values but not quite what we're looking for.\n","\n","> Visualize, visualize, visualize?\n","\n","Boom! That's it. To get familiar and understand how we have to prepare our data for our deep learning models, we've got to visualize it.\n","\n","Because our data is in the form of text files, let's write some code to read each of the lines in a target file."]},{"cell_type":"code","source":["# Create function to read the lines of a document\n","def get_lines(filename):\n","  \"\"\"\n","  Reads filename (a text file) & returns the lines of text as list output.\n","\n","  Args:\n","      filename: a string contanining the target filepath to read.\n","\n","  Returns:\n","      A list of strings with one string per line from the target filename.\n","      For example:\n","        [\"this is the first line of filename\",\n","        \"this is the second line of filename\",\n","        \"...\"]\n","  \"\"\"\n","  with open(filename, \"r\") as f:\n","    return f.readlines()"],"metadata":{"id":"-m032kcdg5LI","executionInfo":{"status":"ok","timestamp":1641217363637,"user_tz":300,"elapsed":5,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":135,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jpeOUfnkCNII"},"source":["Alright, we've got a little function, `get_lines()` which takes the filepath of a text file, opens it, reads each of the lines and returns them.\n","\n","Let's try it out on the training data (`train.txt`)."]},{"cell_type":"code","source":["train_lines = get_lines(data_dir+\"train.txt\")\n","train_lines[:20] # the first 20 lines. They contain the first abstract & some of another"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-KwyeLRKiKb8","executionInfo":{"status":"ok","timestamp":1641217363637,"user_tz":300,"elapsed":4,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"c9c91f37-2228-421e-827f-c5931d75ad1f"},"execution_count":136,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['###24293578\\n',\n"," 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n"," 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n"," 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n"," 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n"," 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n"," 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n"," 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n"," 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n"," 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n',\n"," 'RESULTS\\tThese differences remained significant at @ weeks .\\n',\n"," 'RESULTS\\tThe Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .\\n',\n"," 'CONCLUSIONS\\tLow-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .\\n',\n"," '\\n',\n"," '###24854809\\n',\n"," 'BACKGROUND\\tEmotional eating is associated with overeating and the development of obesity .\\n',\n"," 'BACKGROUND\\tYet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .\\n',\n"," 'OBJECTIVE\\tThe aim of this study was to test if attention bias for food moderates the effect of self-reported emotional eating during sad mood ( vs neutral mood ) on actual food intake .\\n',\n"," 'OBJECTIVE\\tIt was expected that emotional eating is predictive of elevated attention for food and higher food intake after an experimentally induced sad mood and that attentional maintenance on food predicts food intake during a sad versus a neutral mood .\\n',\n"," 'METHODS\\tParticipants ( N = @ ) were randomly assigned to one of the two experimental mood induction conditions ( sad/neutral ) .\\n']"]},"metadata":{},"execution_count":136}]},{"cell_type":"markdown","metadata":{"id":"j-IfwKVAbJAy"},"source":["Reading the lines from the training text file results in a list of strings containing different abstract samples, the sentences in a sample along with the role the sentence plays in the abstract.\n","\n","The role of each sentence is prefixed at the start of each line separated by a tab (`\\t`) and each sentence finishes with a new line (`\\n`).\n","\n","Different abstracts are separated by abstract ID's (lines beginning with `###`) and newlines (`\\n`).\n","\n","Knowing this, it looks like we've got a couple of steps to do to get our samples ready to pass as training data to our future machine learning model.\n","\n","Let's write a function to perform the following steps:\n","* Take a target file of abstract samples.\n","* Read the lines in the target file.\n","* For each line in the target file:  \n","  * If the line begins with `###` mark it as an abstract ID and the beginning of a new abstract.\n","    * Keep count of the number of lines in a sample.\n","  * If the line begins with `\\n` mark it as the end of an abstract sample.\n","    * Keep count of the total lines in a sample.\n","  * Record the text before the `\\t` as the label of the line.\n","  * Record the text after the `\\t` as the text of the line.\n","* Return all of the lines in the target text file as a list of dictionaries containing the key/value pairs:\n","  * `\"line_number\"` - the position of the line in the abstract (e.g. `3`).\n","  * `\"target\"` - the role of the line in the abstract (e.g. `OBJECTIVE`).\n","  * `\"text\"` - the text of the line in the abstract.\n","  * `\"total_lines\"` - the total lines in an abstract sample (e.g. `14`).\n","* Abstract ID's and newlines should be omitted from the returned preprocessed data.\n","\n","Example returned preprocessed sample (a single line from an abstract):\n","\n","```\n","[{'line_number': 0,\n","  'target': 'OBJECTIVE',\n","  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n","  'total_lines': 11},\n","  ...]\n","```"]},{"cell_type":"code","source":["def preprocess_text_with_line_numbers(filename):\n","  \"\"\"Returns a list of dictionaries of abstract line data.\n","\n","  Takes in filename, reads its contents & sorts through each line,\n","  extracting things like the target label, the text of the next sentence,\n","  how many sentences are in the current abstract & what sentence number the target line is.\n","\n","  Args:\n","      filename: a string of the target text file to read & extract line data from.\n","\n","  Returns:\n","      A list of dictionaries each contaning a line from an abstract,\n","      the lines label, the lines position in the abstract & the total number of \n","      lines in the abstract where the line is from. For example:\n","\n","        [{\"target\": 'CONCLUSION',\n","          \"text\": \"The study couldn't have gone better, turns out people are kinder than you think\",\n","          \"line_number\": 8,\n","          \"total_lines\": 8}]\n","  \"\"\"\n","  input_lines = get_lines(filename) # get ALL the lines from the file\n","  abstract_lines = \"\" # Create empty abstract\n","  abstract_samples = [] # create an empty list of abstracts\n","\n","  # Loop through each line in target file\n","  for line in input_lines:\n","    if line.startswith(\"###\"): # Check to see if line is an ID line\n","      abstract_id = line\n","      abstract_lines = \"\" # reset abstract string\n","    elif line.isspace(): # check to see if line is a new line\n","      abstract_line_split = abstract_lines.splitlines() # split abstract into separate lines\n","\n","      # Iterate through each line in abstract & count them at the same time\n","      for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n","        line_data = {} # create empty dict to store data from line\n","        target_text_split = abstract_line.split(\"\\t\") # split target label from text\n","        line_data[\"target\"] = target_text_split[0] # get target label\n","        line_data[\"text\"] = target_text_split[1].lower() # get target text & lower it\n","        line_data[\"line_number\"] = abstract_line_number # what number line does the line appear in the abstract?\n","        line_data[\"total_lines\"] = len(abstract_line_split) - 1 # how many total lines are in the abstract? (start from 0)\n","        abstract_samples.append(line_data) # add line data to abstract samples list\n","\n","    else: # if the above conditions are unfulfilled, the line must contain a labelled sentence\n","      abstract_lines += line\n","  \n","  return abstract_samples"],"metadata":{"id":"g22kOadfiiJC","executionInfo":{"status":"ok","timestamp":1641217363637,"user_tz":300,"elapsed":3,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":137,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DwmUXHrigByo"},"source":["Beautiful! That's one good looking function. Let's use it to preprocess each of our RCT 20k datasets."]},{"cell_type":"code","source":["# Get data from file & preprocess it\n","%%time\n","train_samples = preprocess_text_with_line_numbers(data_dir + \"train.txt\")\n","val_samples = preprocess_text_with_line_numbers(data_dir + \"dev.txt\") # means validation\n","test_samples = preprocess_text_with_line_numbers(data_dir + \"test.txt\")\n","len(train_samples), len(val_samples), len(test_samples)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PnLbF4NYmvab","executionInfo":{"status":"ok","timestamp":1641217364229,"user_tz":300,"elapsed":595,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"16ce26a3-1ef6-40ea-bae9-e392037aad33"},"execution_count":138,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 510 ms, sys: 112 ms, total: 622 ms\n","Wall time: 617 ms\n"]}]},{"cell_type":"markdown","metadata":{"id":"vfFvPjTwgO7b"},"source":["How do our training samples look?"]},{"cell_type":"code","source":["# Check the first abstract of my training data\n","train_samples[:14]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tMV7qwhSrwtZ","executionInfo":{"status":"ok","timestamp":1641217364230,"user_tz":300,"elapsed":4,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"ffe7eb69-2ec1-4ce8-ea62-bbe1723301d6"},"execution_count":139,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'line_number': 0,\n","  'target': 'OBJECTIVE',\n","  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n","  'total_lines': 11},\n"," {'line_number': 1,\n","  'target': 'METHODS',\n","  'text': 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n","  'total_lines': 11},\n"," {'line_number': 2,\n","  'target': 'METHODS',\n","  'text': 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n","  'total_lines': 11},\n"," {'line_number': 3,\n","  'target': 'METHODS',\n","  'text': 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n","  'total_lines': 11},\n"," {'line_number': 4,\n","  'target': 'METHODS',\n","  'text': 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n","  'total_lines': 11},\n"," {'line_number': 5,\n","  'target': 'METHODS',\n","  'text': 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n","  'total_lines': 11},\n"," {'line_number': 6,\n","  'target': 'RESULTS',\n","  'text': 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n","  'total_lines': 11},\n"," {'line_number': 7,\n","  'target': 'RESULTS',\n","  'text': 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n","  'total_lines': 11},\n"," {'line_number': 8,\n","  'target': 'RESULTS',\n","  'text': 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n","  'total_lines': 11},\n"," {'line_number': 9,\n","  'target': 'RESULTS',\n","  'text': 'these differences remained significant at @ weeks .',\n","  'total_lines': 11},\n"," {'line_number': 10,\n","  'target': 'RESULTS',\n","  'text': 'the outcome measures in rheumatology clinical trials-osteoarthritis research society international responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .',\n","  'total_lines': 11},\n"," {'line_number': 11,\n","  'target': 'CONCLUSIONS',\n","  'text': 'low-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee oa ( clinicaltrials.gov identifier nct@ ) .',\n","  'total_lines': 11},\n"," {'line_number': 0,\n","  'target': 'BACKGROUND',\n","  'text': 'emotional eating is associated with overeating and the development of obesity .',\n","  'total_lines': 10},\n"," {'line_number': 1,\n","  'target': 'BACKGROUND',\n","  'text': 'yet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .',\n","  'total_lines': 10}]"]},"metadata":{},"execution_count":139}]},{"cell_type":"markdown","metadata":{"id":"wzFwgxkQhzJS"},"source":["Fantastic! Looks like our `preprocess_text_with_line_numbers()` function worked great. \n","\n","How about we turn our list of dictionaries into pandas DataFrame's so we visualize them better?"]},{"cell_type":"code","source":["import pandas as pd\n","train_df = pd.DataFrame(train_samples)\n","val_df = pd.DataFrame(val_samples)\n","test_df = pd.DataFrame(test_samples)\n","train_df.head(14)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"XrnIftOssG36","executionInfo":{"status":"ok","timestamp":1641217364789,"user_tz":300,"elapsed":562,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"41eed8e9-29fc-4994-a991-e97577a94924"},"execution_count":140,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-8dbbd16b-0d50-4aeb-ae08-f6b265e879cb\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>target</th>\n","      <th>text</th>\n","      <th>line_number</th>\n","      <th>total_lines</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>OBJECTIVE</td>\n","      <td>to investigate the efficacy of @ weeks of dail...</td>\n","      <td>0</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>METHODS</td>\n","      <td>a total of @ patients with primary knee oa wer...</td>\n","      <td>1</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>METHODS</td>\n","      <td>outcome measures included pain reduction and i...</td>\n","      <td>2</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>METHODS</td>\n","      <td>pain was assessed using the visual analog pain...</td>\n","      <td>3</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>METHODS</td>\n","      <td>secondary outcome measures included the wester...</td>\n","      <td>4</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>METHODS</td>\n","      <td>serum levels of interleukin @ ( il-@ ) , il-@ ...</td>\n","      <td>5</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>RESULTS</td>\n","      <td>there was a clinically relevant reduction in t...</td>\n","      <td>6</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>RESULTS</td>\n","      <td>the mean difference between treatment arms ( @...</td>\n","      <td>7</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>RESULTS</td>\n","      <td>further , there was a clinically relevant redu...</td>\n","      <td>8</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>RESULTS</td>\n","      <td>these differences remained significant at @ we...</td>\n","      <td>9</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>RESULTS</td>\n","      <td>the outcome measures in rheumatology clinical ...</td>\n","      <td>10</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>CONCLUSIONS</td>\n","      <td>low-dose oral prednisolone had both a short-te...</td>\n","      <td>11</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>BACKGROUND</td>\n","      <td>emotional eating is associated with overeating...</td>\n","      <td>0</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>BACKGROUND</td>\n","      <td>yet , empirical evidence for individual ( trai...</td>\n","      <td>1</td>\n","      <td>10</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8dbbd16b-0d50-4aeb-ae08-f6b265e879cb')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8dbbd16b-0d50-4aeb-ae08-f6b265e879cb button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8dbbd16b-0d50-4aeb-ae08-f6b265e879cb');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["         target  ... total_lines\n","0     OBJECTIVE  ...          11\n","1       METHODS  ...          11\n","2       METHODS  ...          11\n","3       METHODS  ...          11\n","4       METHODS  ...          11\n","5       METHODS  ...          11\n","6       RESULTS  ...          11\n","7       RESULTS  ...          11\n","8       RESULTS  ...          11\n","9       RESULTS  ...          11\n","10      RESULTS  ...          11\n","11  CONCLUSIONS  ...          11\n","12   BACKGROUND  ...          10\n","13   BACKGROUND  ...          10\n","\n","[14 rows x 4 columns]"]},"metadata":{},"execution_count":140}]},{"cell_type":"markdown","metadata":{"id":"BaVFf-qQg8xA"},"source":["Now our data is in DataFrame form, we can perform some data analysis on it. "]},{"cell_type":"code","source":["# Distrobution of labels in training data:\n","train_df.target.value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FWX_TtItssBU","executionInfo":{"status":"ok","timestamp":1641217364789,"user_tz":300,"elapsed":5,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"7888cb92-1116-4687-fd03-5c6c1f8b6a0c"},"execution_count":141,"outputs":[{"output_type":"execute_result","data":{"text/plain":["METHODS        59353\n","RESULTS        57953\n","CONCLUSIONS    27168\n","BACKGROUND     21727\n","OBJECTIVE      13839\n","Name: target, dtype: int64"]},"metadata":{},"execution_count":141}]},{"cell_type":"markdown","metadata":{"id":"HoZbOMqUhL2l"},"source":["Looks like sentences with the `OBJECTIVE` label are the least common.\n","\n","How about we check the distribution of our abstract lengths?"]},{"cell_type":"code","source":["train_df.total_lines.plot.hist();"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"_MWb4h6syINh","executionInfo":{"status":"ok","timestamp":1641217365088,"user_tz":300,"elapsed":302,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"00d133f6-f8ca-4326-f014-59bb84c619e7"},"execution_count":142,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"qt2kPnlNhy0L"},"source":["Okay, looks like most of the abstracts are around 7 to 15 sentences in length.\n","\n","It's good to check these things out to make sure when we do train a model or test it on unseen samples, our results aren't outlandish."]},{"cell_type":"markdown","metadata":{"id":"Eqps0Jw0wcQo"},"source":["### Get lists of sentences\n","\n","When we build our deep learning model, one of its main inputs will be a list of strings (the lines of an abstract).\n","\n","We can get these easily from our DataFrames by calling the `tolist()` method on our `\"text\"` columns."]},{"cell_type":"code","source":["# Convert abstract text lines into lists\n","train_sentences = train_df[\"text\"].tolist()\n","val_sentences = val_df[\"text\"].tolist()\n","test_sentences = test_df[\"text\"].tolist()\n","len(train_sentences), len(val_sentences), len(test_sentences)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gFFIaEUuyWfJ","executionInfo":{"status":"ok","timestamp":1641217365089,"user_tz":300,"elapsed":9,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"8a65d4a3-ee86-4510-ddc7-13a328ade744"},"execution_count":143,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(180040, 30212, 30135)"]},"metadata":{},"execution_count":143}]},{"cell_type":"code","source":["# View first 10 lines of training sentences\n","train_sentences[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rbru8uWjzRWN","executionInfo":{"status":"ok","timestamp":1641217365089,"user_tz":300,"elapsed":5,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"71017a36-ed1b-4ba1-c913-f5ea8415f253"},"execution_count":144,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n"," 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n"," 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n"," 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n"," 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n"," 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n"," 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n"," 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n"," 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n"," 'these differences remained significant at @ weeks .']"]},"metadata":{},"execution_count":144}]},{"cell_type":"markdown","metadata":{"id":"r36Ldgy2jDR6"},"source":["Alright, we've separated our text samples. As you might've guessed, we'll have to write code to convert the text to numbers before we can use it with our machine learning models, we'll get to this soon."]},{"cell_type":"markdown","metadata":{"id":"rk1tXXANaxhK"},"source":["## Make numeric labels (ML models require numeric labels)\n","\n","We're going to create one hot and label encoded labels.\n","\n","We could get away with just making label encoded labels, however, TensorFlow's CategoricalCrossentropy loss function likes to have one hot encoded labels (this will enable us to use label smoothing later on).\n","\n","To numerically encode labels we'll use Scikit-Learn's [`OneHotEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) and [`LabelEncoder`](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) classes."]},{"cell_type":"code","source":["# One-hot encode labels\n","from sklearn.preprocessing import OneHotEncoder\n","one_hot_encoder = OneHotEncoder(sparse=False)\n","train_labels_one_hot = one_hot_encoder.fit_transform(train_df[\"target\"].to_numpy().reshape(-1, 1))\n","val_labels_one_hot = one_hot_encoder.transform(val_df[\"target\"].to_numpy().reshape(-1, 1))\n","test_labels_one_hot = one_hot_encoder.transform(test_df[\"target\"].to_numpy().reshape(-1, 1))\n","\n","# Check what training labels look like\n","train_labels_one_hot"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4lA48GDazbds","executionInfo":{"status":"ok","timestamp":1641217365090,"user_tz":300,"elapsed":6,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"f513f707-6ffc-4f2a-b341-06974f9c6361"},"execution_count":145,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 0., 1., 0.],\n","       [0., 0., 1., 0., 0.],\n","       [0., 0., 1., 0., 0.],\n","       ...,\n","       [0., 0., 0., 0., 1.],\n","       [0., 1., 0., 0., 0.],\n","       [0., 1., 0., 0., 0.]])"]},"metadata":{},"execution_count":145}]},{"cell_type":"markdown","metadata":{"id":"bG-iZttkkCjL"},"source":["### Label encode labels"]},{"cell_type":"code","source":["# Extract labels (\"target\" colums) & encode them into integers\n","from sklearn.preprocessing import LabelEncoder\n","label_encoder = LabelEncoder()\n","train_labels_encoded = label_encoder.fit_transform(train_df[\"target\"].to_numpy())\n","val_labels_encoded = label_encoder.transform(val_df[\"target\"].to_numpy())\n","test_labels_encoded = label_encoder.transform(test_df[\"target\"].to_numpy())\n","\n","# Check what the training labels look like\n","train_labels_encoded"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6vIlh6N90wow","executionInfo":{"status":"ok","timestamp":1641217365539,"user_tz":300,"elapsed":454,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"63ecd6d1-4222-4f97-a83d-efe011b6770e"},"execution_count":146,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([3, 2, 2, ..., 4, 1, 1])"]},"metadata":{},"execution_count":146}]},{"cell_type":"markdown","metadata":{"id":"rd-uax-AkExg"},"source":["Now we've trained an instance of `LabelEncoder`, we can get the class names and number of classes using the `classes_` attribute."]},{"cell_type":"code","source":["# Get class names & number of classes from LabelEncoder instance\n","num_classes = len(label_encoder.classes_)\n","class_names = label_encoder.classes_\n","num_classes, class_names"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WbsTpzy25uGW","executionInfo":{"status":"ok","timestamp":1641217365539,"user_tz":300,"elapsed":3,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"58dc65f3-cd3f-4d34-9b01-7bf2ba4df8a0"},"execution_count":147,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5, array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS'],\n","       dtype=object))"]},"metadata":{},"execution_count":147}]},{"cell_type":"markdown","metadata":{"id":"gSGeXjbmlJar"},"source":["## Creating a series of model experiments\n","\n","We've proprocessed our data so now, in true machine learning fashion, it's time to setup a series of modelling experiments.\n","\n","We'll start by creating a simple baseline model to obtain a score we'll try to beat by building more and more complex models as we move towards replicating the sequence model outlined in [*Neural networks for joint sentence\n","classification in medical paper abstracts*](https://arxiv.org/pdf/1612.05251.pdf).\n","\n","For each model, we'll train it on the training data and evaluate it on the validation data."]},{"cell_type":"markdown","metadata":{"id":"dJD7X7atahFC"},"source":["## Model 0: Getting a baseline \n","\n","Our first model we'll be a TF-IDF Multinomial Naive Bayes as recommended by [Scikit-Learn's machine learning map](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html).\n","\n","To build it, we'll create a Scikit-Learn `Pipeline` which uses the [`TfidfVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) class to convert our abstract sentences to numbers using the TF-IDF (term frequency-inverse document frequecy) algorithm and then learns to classify our sentences using the [`MultinomialNB`](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html) aglorithm."]},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.pipeline import Pipeline\n","\n","# Create a pipeline\n","model_0 = Pipeline([\n","                    (\"tf-idf\", TfidfVectorizer()),\n","                    (\"clf\", MultinomialNB())\n","])\n","\n","# Fit the pipeline to the training data\n","model_0.fit(X=train_sentences,\n","            y=train_labels_encoded);"],"metadata":{"id":"RG7BTB9L6D0g","executionInfo":{"status":"ok","timestamp":1641217369963,"user_tz":300,"elapsed":4426,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":148,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GGUtAzKem-dO"},"source":["Due to the speed of the Multinomial Naive Bayes algorithm, it trains very quickly.\n","\n","We can evaluate our model's accuracy on the validation dataset using the `score()` method."]},{"cell_type":"code","source":["# Evaluate baseline on validation dataset\n","model_0.score(X=val_sentences,\n","              y=val_labels_encoded)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9nnRu2_Y8b7V","executionInfo":{"status":"ok","timestamp":1641217370259,"user_tz":300,"elapsed":303,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"1388511a-fd68-4298-f398-6fe12a992f58"},"execution_count":149,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7218323844829869"]},"metadata":{},"execution_count":149}]},{"cell_type":"markdown","metadata":{"id":"Mp0aq6XpnPCG"},"source":["Nice! Looks like 72.1% accuracy will be the number to beat with our deeper models.\n","\n","Now let's make some predictions with our baseline model to further evaluate it."]},{"cell_type":"code","source":["# Make predictions\n","baseline_preds = model_0.predict(val_sentences)\n","baseline_preds"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9cGQt9yS82Ss","executionInfo":{"status":"ok","timestamp":1641217370530,"user_tz":300,"elapsed":273,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"1ed3c1a8-71a9-4a61-de79-365f1842b54c"},"execution_count":150,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([4, 1, 3, ..., 4, 4, 1])"]},"metadata":{},"execution_count":150}]},{"cell_type":"markdown","metadata":{"id":"jh2K8p3sndlG"},"source":["To evaluate our baseline's predictions, we'll import the `calculate_results()` function we created in the [previous notebook](https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/08_introduction_to_nlp_in_tensorflow.ipynb) and added it to our [`helper_functions.py` script](https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/extras/helper_functions.py) to compare them to the ground truth labels.\n","\n","More specificially the `calculate_results()` function will help us obtain the following:\n","* Accuracy\n","* Precision\n","* Recall\n","* F1-score"]},{"cell_type":"markdown","metadata":{"id":"V5GaqHjtHWUM"},"source":["### Download helper functions script\n","\n","Let's get our `helper_functions.py` script we've been using to store helper functions we've created in previous notebooks."]},{"cell_type":"code","source":["# Download helper functions script\n","!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Kw77Z259GJX","executionInfo":{"status":"ok","timestamp":1641217371344,"user_tz":300,"elapsed":816,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"dcb94a04-bea8-492b-d3bb-f7e5305390cd"},"execution_count":151,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-01-03 13:42:49--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 10246 (10K) [text/plain]\n","Saving to: ‚Äòhelper_functions.py.1‚Äô\n","\n","helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n","\n","2022-01-03 13:42:49 (73.6 MB/s) - ‚Äòhelper_functions.py.1‚Äô saved [10246/10246]\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"nmXBYc5SHitH"},"source":["Now we've got the helper functions script we can import the `caculate_results()` function and see how our baseline model went."]},{"cell_type":"code","source":["# Import calculate_rsults helper function\n","from helper_functions import calculate_results"],"metadata":{"id":"amaXweFK9ZYD","executionInfo":{"status":"ok","timestamp":1641217371345,"user_tz":300,"elapsed":6,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":152,"outputs":[]},{"cell_type":"code","source":["# Calculate baseline results\n","baseline_results = calculate_results(y_true=val_labels_encoded,\n","                                     y_pred=baseline_preds)\n","baseline_results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aif5HEif9mqC","executionInfo":{"status":"ok","timestamp":1641217371345,"user_tz":300,"elapsed":6,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"e223ef81-c617-4e5b-c1c1-620dc07d0947"},"execution_count":153,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'accuracy': 72.1832384482987,\n"," 'f1': 0.6989250353450294,\n"," 'precision': 0.7186466952323352,\n"," 'recall': 0.7218323844829869}"]},"metadata":{},"execution_count":153}]},{"cell_type":"markdown","metadata":{"id":"MADIlN1QaiTW"},"source":["## Preparing our data for deep sequence models\n","\n","Excellent! We've got a working baseline to try and improve upon.\n","\n","But before we start building deeper models, we've got to create vectorization and embedding layers.\n","\n","The vectorization layer will convert our text to numbers and the embedding layer will capture the relationships between those numbers.\n","\n","To start creating our vectorization and embedding layers, we'll need to import the appropriate libraries (namely TensorFlow and NumPy)."]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras import layers"],"metadata":{"id":"u7sicRc396AC","executionInfo":{"status":"ok","timestamp":1641217371345,"user_tz":300,"elapsed":5,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":154,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JTEPCjOuUNdj"},"source":["Since we'll be turning our sentences into numbers, it's a good idea to figure out how many words are in each sentence.\n","\n","When our model goes through our sentences, it works best when they're all the same length (this is important for creating batches of the same size tensors).\n","\n","For example, if one sentence is eight words long and another is 29 words long, we want to pad the eight word sentence with zeros so it ends up being the same length as the 29 word sentence.\n","\n","Let's write some code to find the average length of sentences in the training set."]},{"cell_type":"code","source":["# how long is each sentance on average?\n","sent_lens = [len(sentence.split()) for sentence in train_sentences]\n","avg_sent_len = np.mean(sent_lens)\n","avg_sent_len # return average sentence length (in tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VzLzz_jt-Sgs","executionInfo":{"status":"ok","timestamp":1641217371345,"user_tz":300,"elapsed":4,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"b824ca4b-87bc-4211-a21b-ae51ca907a3f"},"execution_count":155,"outputs":[{"output_type":"execute_result","data":{"text/plain":["26.338269273494777"]},"metadata":{},"execution_count":155}]},{"cell_type":"markdown","metadata":{"id":"oToFcpVTU6fU"},"source":["How about the distribution of sentence lengths?"]},{"cell_type":"code","source":["# What's the distribution look like?\n","import matplotlib.pyplot as plt\n","plt.hist(sent_lens, bins=20);"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"Oayu0eI7-1Mc","executionInfo":{"status":"ok","timestamp":1641217371694,"user_tz":300,"elapsed":352,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"02ae38e3-3073-471a-94f4-16f110ef0285"},"execution_count":156,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"BH7_Yaz1U9yJ"},"source":["Looks like the vast majority of sentences are between 0 and 50 tokens in length.\n","\n","We can use NumPy's [`percentile`](https://numpy.org/doc/stable/reference/generated/numpy.percentile.html) to find the value which covers 95% of the sentence lengths."]},{"cell_type":"code","source":["# How long of a sentence covers 95% of the lengths\n","output_seq_len = int(np.percentile(sent_lens, 95))\n","output_seq_len"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vqVxpMKx_PeD","executionInfo":{"status":"ok","timestamp":1641217371694,"user_tz":300,"elapsed":9,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"d17a92fc-fdb3-4a32-9c61-eeb3e2b0f230"},"execution_count":157,"outputs":[{"output_type":"execute_result","data":{"text/plain":["55"]},"metadata":{},"execution_count":157}]},{"cell_type":"markdown","metadata":{"id":"Nhre7MPBVfK2"},"source":["Wonderful! It looks like 95% of the sentences in our training set have a length of 55 tokens or less.\n","\n","When we create our tokenization layer, we'll use this value to turn all of our sentences into the same length. Meaning sentences with a length below 55 get padded with zeros and sentences with a length above 55 get truncated (words after 55 get cut off).\n","\n","> ü§î **Question:** Why 95%?\n","\n","We could use the max sentence length of the sentences in the training set."]},{"cell_type":"code","source":["# Max sentence length in the training set\n","max(sent_lens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UYBUOtIY_qjY","executionInfo":{"status":"ok","timestamp":1641217371695,"user_tz":300,"elapsed":5,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"07932b44-5000-48dc-fa58-2180f2ff6eb9"},"execution_count":158,"outputs":[{"output_type":"execute_result","data":{"text/plain":["296"]},"metadata":{},"execution_count":158}]},{"cell_type":"markdown","metadata":{"id":"tIWIlFV4WF8R"},"source":["However, since hardly any sentences even come close to the max length, it would mean the majority of the data we pass to our model would be zeros (sinces all sentences below the max length would get padded with zeros).\n","\n","> üîë **Note:** The steps we've gone through are good practice when working with a text corpus for a NLP problem. You want to know how long your samples are and what the distribution of them is. See section 4 Data Analysis of the [PubMed 200k RCT paper](https://arxiv.org/pdf/1710.06071.pdf) for further examples."]},{"cell_type":"markdown","metadata":{"id":"uvhbRw7-uMwH"},"source":["### Create text vectorizer\n","\n","Now we've got a little more information about our texts, let's create a way to turn it into numbers.\n","\n","To do so, we'll use the [`TextVectorization`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/TextVectorization) layer from TensorFlow.\n","\n","We'll keep all the parameters default except for `max_tokens` (the number of unique words in our dataset) and `output_sequence_length` (our desired output length for each vectorized sentence).\n","\n","Section 3.2 of the [PubMed 200k RCT paper](https://arxiv.org/pdf/1710.06071.pdf) states the vocabulary size of the PubMed 20k dataset as 68,000. So we'll use that as our `max_tokens` parameter."]},{"cell_type":"code","source":["# How many words are in the vocabulary? (Taken from 3.2 in https://arxiv.org/pdf/1710.06071.pdf)\n","max_tokens = 68000"],"metadata":{"id":"XsliSsE8_8kY","executionInfo":{"status":"ok","timestamp":1641217371695,"user_tz":300,"elapsed":5,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":159,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tu25jIo-YSuW"},"source":["And since discovered a sentence length of 55 covers 95% of the training sentences, we'll use that as our `output_sequence_length` parameter."]},{"cell_type":"code","source":["# Create text vectorizer\n","from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n","\n","text_vectorizer = TextVectorization(max_tokens=max_tokens, # num of words in vocabulary\n","                                    output_sequence_length=55) # desired output lenght of vectorizor"],"metadata":{"id":"2S8eCi_eFlKb","executionInfo":{"status":"ok","timestamp":1641217371695,"user_tz":300,"elapsed":4,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":160,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y_Y7U8SdY0bO"},"source":["Great! Looks like our `text_vectorizer` is ready, let's adapt it to the training data (let it read the training data and figure out what number should represent what word) and then test it out. "]},{"cell_type":"code","source":["# Adapt text vectorizer to training sentences\n","text_vectorizer.adapt(train_sentences)"],"metadata":{"id":"YH2MKuuoGL-t","executionInfo":{"status":"ok","timestamp":1641217385574,"user_tz":300,"elapsed":13883,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":161,"outputs":[]},{"cell_type":"code","source":["# Test out text vectorizer\n","import random\n","target_sentence = random.choice(train_sentences)\n","print(f\"Text:\\n{target_sentence}\")\n","print(f\"\\nLenght of text: {len(target_sentence.split())}\")\n","print(f\"\\nVectorized text: \\n{text_vectorizer([target_sentence])}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C67GFR-3GdVv","executionInfo":{"status":"ok","timestamp":1641217385575,"user_tz":300,"elapsed":15,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"790a8ef4-382a-4056-c0fb-1b222f3dba40"},"execution_count":162,"outputs":[{"output_type":"stream","name":"stdout","text":["Text:\n","here we report efficacy and safety results from the paramount study for elderly ( @ years ) and non-elderly ( < @ years ) patients .\n","\n","Lenght of text: 26\n","\n","Vectorized text: \n","[[ 1759    43   787    79     3   136   117    27     2 11043    17    11\n","    836    64     3  8399    64    12     0     0     0     0     0     0\n","      0     0     0     0     0     0     0     0     0     0     0     0\n","      0     0     0     0     0     0     0     0     0     0     0     0\n","      0     0     0     0     0     0     0]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"wdKJpk-8sjYn"},"source":["Cool, we've now got a way to turn our sequences into numbers.\n","\n","> üõ† **Exercise:** Try running the cell above a dozen or so times. What do you notice about sequences with a length less than 55?\n","\n","Using the [`get_vocabulary()`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/TextVectorization) method of our `text_vectorizer` we can find out a few different tidbits about our text."]},{"cell_type":"code","source":["# How many words in the training vocabulary?\n","rct_20k_text_vocab = text_vectorizer.get_vocabulary()\n","print(f\"Number of words in vocabulary: {len(rct_20k_text_vocab)}\")\n","print(f\"Most common words in the vocabulary: {rct_20k_text_vocab[:50]}\")\n","print(f\"Least common words in the vocabulary: {rct_20k_text_vocab[-50:]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-R46aE_uHJAV","executionInfo":{"status":"ok","timestamp":1641217385575,"user_tz":300,"elapsed":10,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"33bdf53a-cd7f-4627-ff4f-9f2be53aecd3"},"execution_count":163,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of words in vocabulary: 64841\n","Most common words in the vocabulary: ['', '[UNK]', 'the', 'and', 'of', 'in', 'to', 'with', 'a', 'were', 'was', 'for', 'patients', 'group', 'p', 'at', 'or', 'study', 'on', 'treatment', 'is', 'after', 'by', 'this', 'groups', 'as', 'an', 'from', 'that', 'randomized', 'between', 'not', 'trial', 'no', 'compared', 'control', 'be', 'significant', 'intervention', 'significantly', 'n', 'months', 'than', 'we', 'vs', 'rsb', 'lsb', 'clinical', 'placebo', 'baseline']\n","Least common words in the vocabulary: ['abnormity', 'abnormalitylesion', 'abmsc', 'ablike', 'abliglutide', 'abler', 'ablbcrabl', 'abilitiesthe', 'abilhandkids', 'abigail', 'abidjan', 'aberrometer', 'abdullah', 'abdulaziz', 'abductionprovoked', 'abdominus', 'abdominals', 'abdominalpelvic', 'abctcbased', 'abch', 'abcelisa', 'abcdes', 'abcdefg', 'abcan', 'abcamediated', 'abbreviations', 'abbreviation', 'abba', 'abarticular', 'abandoning', 'abandon', 'abaloparatideinduced', 'abagovomabinduced', 'abacus', 'abacopd', 'abacavirlamivudinezidovudine', 'ababa', 'aavsercaa', 'aats', 'aartselaar', 'aarm', 'aaqol', 'aaq', 'aanhui', 'aana', 'aainduced', 'aaigroup', 'aachener', 'aachen', 'aaacp']\n"]}]},{"cell_type":"markdown","metadata":{"id":"w4F6atcSa26q"},"source":["And if we wanted to figure out the configuration of our `text_vectorizer` we can use the `get_config()` method."]},{"cell_type":"code","source":["# get the configuration of my text vectorizer\n","text_vectorizer.get_config()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wtXjyCOeIfTq","executionInfo":{"status":"ok","timestamp":1641217385576,"user_tz":300,"elapsed":10,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"f1a6165c-188b-460e-9611-dd50859b68ff"},"execution_count":164,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'batch_input_shape': (None,),\n"," 'dtype': 'string',\n"," 'idf_weights': None,\n"," 'max_tokens': 68000,\n"," 'name': 'text_vectorization_2',\n"," 'ngrams': None,\n"," 'output_mode': 'int',\n"," 'output_sequence_length': 55,\n"," 'pad_to_max_tokens': False,\n"," 'ragged': False,\n"," 'sparse': False,\n"," 'split': 'whitespace',\n"," 'standardize': 'lower_and_strip_punctuation',\n"," 'trainable': True,\n"," 'vocabulary': None}"]},"metadata":{},"execution_count":164}]},{"cell_type":"markdown","metadata":{"id":"GZvDSTrTp1Wy"},"source":["### Create custom text embedding\n","\n","Our `token_vectorization` layer maps the words in our text directly to numbers. However, this doesn't necessarily capture the relationships between those numbers.\n","\n","To create a richer numerical representation of our text, we can use an **embedding**.\n","\n","As our model learns (by going through many different examples of abstract sentences and their labels), it'll update its embedding to better represent the relationships between tokens in our corpus.\n","\n","We can create a trainable embedding layer using TensorFlow's [`Embedding`](https://www.tensorflow.org/tutorials/text/word_embeddings) layer.\n","\n","Once again, the main parameters we're concerned with here are the inputs and outputs of our `Embedding` layer.\n","\n","The `input_dim` parameter defines the size of our vocabulary. And the `output_dim` parameter defines the dimension of the embedding output.\n","\n","Once created, our embedding layer will take the integer outputs of our `text_vectorization` layer as inputs and convert them to feature vectors of size `output_dim`.\n","\n","Let's see it in action."]},{"cell_type":"code","source":["# Create token embedding layer\n","token_embed = layers.Embedding(input_dim=len(rct_20k_text_vocab), # lenght of vocabulary\n","                               output_dim=128, # Note: different embedding sizes result in drastically different nums of parameters to train\n","                               # Use making to handle variable sequence lengths (to save space)\n","                               mask_zero=True,\n","                               name=\"token_embedding\")\n","\n","# Show an example embedding\n","print(f\"Sentence before vectorization:\\n{target_sentence}\\n\")\n","vectorized_sentence = text_vectorizer([target_sentence])\n","print(f\"Sentence after vectorization (before embedding):\\n{vectorized_sentence}\\n\")\n","embedded_sentence = token_embed(vectorized_sentence)\n","print(f\"Sentence after embedding:\\n{embedded_sentence}\\n\")\n","print(f\"Embedded sentence shape: {embedded_sentence.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rdvlurPMJBBV","executionInfo":{"status":"ok","timestamp":1641217385889,"user_tz":300,"elapsed":322,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"9fa008ee-7e47-4324-e2ac-ef30708afbcb"},"execution_count":165,"outputs":[{"output_type":"stream","name":"stdout","text":["Sentence before vectorization:\n","here we report efficacy and safety results from the paramount study for elderly ( @ years ) and non-elderly ( < @ years ) patients .\n","\n","Sentence after vectorization (before embedding):\n","[[ 1759    43   787    79     3   136   117    27     2 11043    17    11\n","    836    64     3  8399    64    12     0     0     0     0     0     0\n","      0     0     0     0     0     0     0     0     0     0     0     0\n","      0     0     0     0     0     0     0     0     0     0     0     0\n","      0     0     0     0     0     0     0]]\n","\n","Sentence after embedding:\n","[[[ 0.00799588 -0.03746953 -0.01012652 ... -0.00749928 -0.00058006\n","   -0.0144294 ]\n","  [ 0.00798093 -0.0386881  -0.00979663 ... -0.00088469 -0.01804841\n","    0.01709202]\n","  [ 0.04622706  0.01461896 -0.01650665 ... -0.03051214 -0.01751399\n","   -0.00695404]\n","  ...\n","  [ 0.02634824 -0.03392482  0.00523535 ...  0.04244641 -0.00123214\n","    0.00760597]\n","  [ 0.02634824 -0.03392482  0.00523535 ...  0.04244641 -0.00123214\n","    0.00760597]\n","  [ 0.02634824 -0.03392482  0.00523535 ...  0.04244641 -0.00123214\n","    0.00760597]]]\n","\n","Embedded sentence shape: (1, 55, 128)\n"]}]},{"cell_type":"markdown","metadata":{"id":"l5tDy1PRfvZ0"},"source":["## Create datasets (as fast as possible)\n","\n","We've gone through all the trouble of preprocessing our datasets to be used with a machine learning model, however, there are still a few steps we can use to make them work faster with our models.\n","\n","Namely, the `tf.data` API provides methods which enable faster data loading.\n","\n","> üìñ **Resource:** For best practices on data loading in TensorFlow, check out the following:\n","* [tf.data: Build TensorFlow input pipelines](https://www.tensorflow.org/guide/data)\n","* [Better performance with the tf.data API](https://www.tensorflow.org/guide/data_performance)\n","\n","The main steps we'll want to use with our data is to turn it into a `PrefetchDataset` of batches.\n","\n","Doing so we'll ensure TensorFlow loads our data onto the GPU as fast as possible, in turn leading to faster training time.\n","\n","To create a batched `PrefetchDataset` we can use the methods [`batch()`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#batch) and [`prefetch()`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#prefetch), the parameter [`tf.data.AUTOTUNE`](https://www.tensorflow.org/api_docs/python/tf/data#AUTOTUNE) will also allow TensorFlow to determine the optimal amount of compute to use to prepare datasets."]},{"cell_type":"code","source":["# Turn the dataset into TensorFlow Datasets\n","train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences, train_labels_one_hot))\n","valid_dataset = tf.data.Dataset.from_tensor_slices((val_sentences, val_labels_one_hot))\n","test_dataset = tf.data.Dataset.from_tensor_slices((test_sentences, test_labels_one_hot))\n","\n","train_dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"esIyo3msLTYK","executionInfo":{"status":"ok","timestamp":1641217386847,"user_tz":300,"elapsed":959,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"461315bc-2f88-4293-f940-d8eb816104a4"},"execution_count":166,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<TensorSliceDataset shapes: ((), (5,)), types: (tf.string, tf.float64)>"]},"metadata":{},"execution_count":166}]},{"cell_type":"code","source":["# Take the TensorSliceDataset's & turn them into prefetched batches\n","train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n","valid_dataset = valid_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n","test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n","\n","train_dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H-EWtHFUMm3m","executionInfo":{"status":"ok","timestamp":1641217386848,"user_tz":300,"elapsed":10,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"0a5b7d89-43dc-43d1-c774-6db968ae550e"},"execution_count":167,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<PrefetchDataset shapes: ((None,), (None, 5)), types: (tf.string, tf.float64)>"]},"metadata":{},"execution_count":167}]},{"cell_type":"markdown","metadata":{"id":"HeE3wo4QvOlR"},"source":["## Model 1: Conv1D with token embeddings\n","\n","Alright, we've now got a way to numerically represent our text and labels, time to build a series of deep models to try and improve upon our baseline.\n","\n","All of our deep models will follow a similar structure:\n","\n","```\n","Input (text) -> Tokenize -> Embedding -> Layers -> Output (label probability)\n","```\n","\n","The main component we'll be changing throughout is the `Layers` component. Because any modern deep NLP model requires text to be converted into an embedding before meaningful patterns can be discovered within.\n","\n","The first model we're going to build is a 1-dimensional Convolutional Neural Network. \n","\n","We're also going to be following the standard machine learning workflow of:\n","- Build model\n","- Train model\n","- Evaluate model (make predictions and compare to ground truth)\n"]},{"cell_type":"code","source":["# Create 1D convolutional model to process sequences\n","inputs = layers.Input(shape=(1,), dtype=tf.string)\n","text_vectors = text_vectorizer(inputs) # vectorize text inputs\n","token_embeddings = token_embed(text_vectors) # create embedding\n","x = layers.Conv1D(64, kernel_size=5, padding=\"same\", activation=\"relu\")(token_embeddings)\n","x = layers.GlobalAveragePooling1D()(x) # condense feature vector output\n","outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n","model_1 = tf.keras.Model(inputs, outputs)\n","\n","# Compile\n","model_1.compile(loss=\"categorical_crossentropy\", # If labels are integer (not one-hot) use sparse_categorical_crossentropy\n","                optimizer=tf.keras.optimizers.Adam(),\n","                metrics=[\"accuracy\"])"],"metadata":{"id":"ZvFz01AFNpw-","executionInfo":{"status":"ok","timestamp":1641217386848,"user_tz":300,"elapsed":5,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":168,"outputs":[]},{"cell_type":"code","source":["# Get model summary\n","model_1.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zLAN3gMaYKEE","executionInfo":{"status":"ok","timestamp":1641217386848,"user_tz":300,"elapsed":4,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"3b0d9dad-ef8d-468c-bf6d-24e46e019cf2"},"execution_count":169,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_6 (InputLayer)        [(None, 1)]               0         \n","                                                                 \n"," text_vectorization_2 (TextV  (None, 55)               0         \n"," ectorization)                                                   \n","                                                                 \n"," token_embedding (Embedding)  (None, 55, 128)          8299648   \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 55, 64)            41024     \n","                                                                 \n"," global_average_pooling1d_1   (None, 64)               0         \n"," (GlobalAveragePooling1D)                                        \n","                                                                 \n"," dense_8 (Dense)             (None, 5)                 325       \n","                                                                 \n","=================================================================\n","Total params: 8,340,997\n","Trainable params: 8,340,997\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"-gZdAVJJ3vc2"},"source":["Wonderful! We've got our first deep sequence model built and ready to go. \n","\n","Checking out the model summary, you'll notice the majority of the trainable parameters are within the embedding layer. If we were to increase the size of the embedding (by increasing the `output_dim` parameter of the `Embedding` layer), the number of trainable parameters would increase dramatically.\n","\n","It's time to fit our model to the training data but we're going to make a mindful change.\n","\n","Since our training data contains nearly 200,000 sentences, fitting a deep model may take a while even with a GPU. So to keep our experiments swift, we're going to run them on a subset of the training dataset.\n","\n","More specifically, we'll only use the first 10% of batches (about 18,000 samples) of the training set to train on and the first 10% of batches from the validation set to validate on.\n","\n","> üîë **Note:** It's a standard practice in machine learning to test your models on smaller subsets of data first to make sure they work before scaling them to larger amounts of data. You should aim to run many smaller experiments rather than only a handful of large experiments. And since your time is limited, one of the best ways to run smaller experiments is to reduce the amount of data you're working with (10% of the full dataset is usually a good amount, as long as it covers a similar distribution)."]},{"cell_type":"code","source":["# Fit the model\n","model_1_history = model_1.fit(train_dataset,\n","                              steps_per_epoch=int(0.1 * len(train_dataset)), # only fit on 10% of batches for faster training time\n","                              epochs=3,\n","                              validation_data=valid_dataset,\n","                              validation_steps=int(0.1 * len(valid_dataset))) # only validate on 10% of batches"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DIyhQzBHYRhh","executionInfo":{"status":"ok","timestamp":1641217573818,"user_tz":300,"elapsed":186973,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"216aee42-af69-4121-a549-9fabb08c023d"},"execution_count":170,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","562/562 [==============================] - 62s 110ms/step - loss: 0.9144 - accuracy: 0.6396 - val_loss: 0.6862 - val_accuracy: 0.7380\n","Epoch 2/3\n","562/562 [==============================] - 62s 110ms/step - loss: 0.6573 - accuracy: 0.7562 - val_loss: 0.6364 - val_accuracy: 0.7736\n","Epoch 3/3\n","562/562 [==============================] - 63s 111ms/step - loss: 0.6162 - accuracy: 0.7757 - val_loss: 0.5974 - val_accuracy: 0.7846\n"]}]},{"cell_type":"markdown","metadata":{"id":"RQrRp3ar8GQV"},"source":["Brilliant! We've got our first trained deep sequence model, and it didn't take too long (and if we didn't prefetch our batched data, it would've taken longer).\n","\n","Time to make some predictions with our model and then evaluate them."]},{"cell_type":"code","source":["# Evaluate on whole validation dataset (only used 10% of validation set during training)\n","model_1.evaluate(valid_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h1k0LrcAZZvS","executionInfo":{"status":"ok","timestamp":1641217583942,"user_tz":300,"elapsed":10141,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"1848f82a-dba7-4942-e562-70c9fc2ccbb5"},"execution_count":171,"outputs":[{"output_type":"stream","name":"stdout","text":["945/945 [==============================] - 5s 6ms/step - loss: 0.5969 - accuracy: 0.7868\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.5968714952468872, 0.7867734432220459]"]},"metadata":{},"execution_count":171}]},{"cell_type":"code","source":["# Make predictions (our model outputs prediction probabilities for each class)\n","model_1_pred_probs = model_1.predict(valid_dataset)\n","model_1_pred_probs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9zxqTKHjZxtU","executionInfo":{"status":"ok","timestamp":1641217588238,"user_tz":300,"elapsed":4304,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"ba08bb91-1b94-4a49-bb26-87c95d201c91"},"execution_count":172,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[4.6777785e-01, 1.0809363e-01, 5.5915564e-02, 3.4510031e-01,\n","        2.3112589e-02],\n","       [4.2350721e-01, 2.9766646e-01, 1.3401766e-02, 2.5110027e-01,\n","        1.4324428e-02],\n","       [1.6738634e-01, 8.8945851e-03, 1.3980061e-03, 8.2228017e-01,\n","        4.0864903e-05],\n","       ...,\n","       [1.0695966e-05, 5.3729542e-04, 7.6061400e-04, 7.0825522e-06,\n","        9.9868435e-01],\n","       [6.4722456e-02, 4.7488195e-01, 8.0096975e-02, 7.7345386e-02,\n","        3.0295321e-01],\n","       [1.2945326e-01, 7.4956691e-01, 4.5990095e-02, 4.0132921e-02,\n","        3.4856685e-02]], dtype=float32)"]},"metadata":{},"execution_count":172}]},{"cell_type":"code","source":["# Convert pred_probs to classes\n","model_1_preds = tf.argmax(model_1_pred_probs, axis=1)\n","model_1_preds"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4JPv_o-AaEau","executionInfo":{"status":"ok","timestamp":1641217588238,"user_tz":300,"elapsed":10,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"0002db3d-65d6-413d-9c24-54d9ac576e08"},"execution_count":173,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 0, 3, ..., 4, 1, 1])>"]},"metadata":{},"execution_count":173}]},{"cell_type":"code","source":["# Calculate model_1 results\n","model_1_results = calculate_results(y_true=val_labels_encoded,\n","                                    y_pred=model_1_preds)\n","model_1_results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I4q6_lZbaSii","executionInfo":{"status":"ok","timestamp":1641217588555,"user_tz":300,"elapsed":324,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"ab93a8e7-c4f2-42b0-80bd-7ee0be9649b0"},"execution_count":174,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'accuracy': 78.6773467496359,\n"," 'f1': 0.7846311613159648,\n"," 'precision': 0.7837206094760445,\n"," 'recall': 0.786773467496359}"]},"metadata":{},"execution_count":174}]},{"cell_type":"markdown","source":["Wow. I already beat my baseline?"],"metadata":{"id":"3o08RhWkaxfS"}},{"cell_type":"markdown","metadata":{"id":"qU1u4KlWvAQa"},"source":["## Model 2: Feature extraction with pretrained token embeddings\n","\n","Training our own embeddings took a little while to run, slowing our experiments down.\n","\n","Since we're moving towards replicating the model architecture in [*Neural Networks for Joint Sentence Classification\n","in Medical Paper Abstracts*](https://arxiv.org/pdf/1612.05251.pdf), it mentions they used a [pretrained GloVe embedding](https://nlp.stanford.edu/projects/glove/) as a way to initialise their token embeddings.\n","\n","To emulate this, let's see what results we can get with the [pretrained Universal Sentence Encoder embeddings from TensorFlow Hub](https://tfhub.dev/google/universal-sentence-encoder/4).\n","\n","> üîë **Note:** We could use GloVe embeddings as per the paper but since we're working with TensorFlow, we'll use what's available from TensorFlow Hub (GloVe embeddings aren't). We'll save [using pretrained GloVe embeddings](https://keras.io/examples/nlp/pretrained_word_embeddings/) as an extension.\n","\n","The model structure will look like:\n","\n","```\n","Inputs (string) -> Pretrained embeddings from TensorFlow Hub (Universal Sentence Encoder) -> Layers -> Output (prediction probabilities)\n","```\n","\n","You'll notice the lack of tokenization layer we've used in a previous model. This is because the Universal Sentence Encoder (USE) takes care of tokenization for us.\n","\n","This type of model is called transfer learning, or more specifically, **feature extraction transfer learning**. In other words, taking the patterns a model has learned elsewhere and applying it to our own problem.\n","\n","![TensorFlow Hub Universal Feature Encoder feature extractor model we're building](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/09-model-tf-hub-USE-to-dense-layer.png)\n","*The feature extractor model we're building using a pretrained embedding from TensorFlow Hub.*\n","\n","To download the pretrained USE into a layer we can use in our model, we can use the [`hub.KerasLayer`](https://www.tensorflow.org/hub/api_docs/python/hub/KerasLayer) class.\n","\n","We'll keep the pretrained embeddings frozen (by setting `trainable=False`) and add a trainable couple of layers on the top to tailor the model outputs to our own data.\n","\n","> üîë **Note:** Due to having to download a relatively large model (~916MB), the cell below may take a little while to run."]},{"cell_type":"code","source":["# Download pretrained TensorFlow Hub USE\n","import tensorflow_hub as hub\n","tf_hub_embedding_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n","                                        trainable=False,\n","                                        name=\"universal_sentence_encoder\")"],"metadata":{"id":"6x_Ts2GVamra","executionInfo":{"status":"ok","timestamp":1641217593442,"user_tz":300,"elapsed":4888,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":175,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qOv1JQh1JdW0"},"source":["Beautiful, now our pretrained USE is downloaded and instantiated as a `hub.KerasLayer` instance, let's test it out on a random sentence."]},{"cell_type":"code","source":["# Test out the embedding on a random sentence\n","random_training_sentence = random.choice(train_sentences)\n","print(f\"Random training sentence:\\n{random_training_sentence}\\n\")\n","use_embedded_sentence = tf_hub_embedding_layer([random_training_sentence])\n","print(f\"Sentence after embedding:\\n{use_embedded_sentence[0][:30]} (truncated output)...\\n \")\n","print(f\"Length of sentence embedding:\\n{len(use_embedded_sentence[0])}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r94i5QdDcbV7","executionInfo":{"status":"ok","timestamp":1641217593727,"user_tz":300,"elapsed":299,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"473a5b7c-e1b1-43c8-c2e3-ce159c3b0eaf"},"execution_count":176,"outputs":[{"output_type":"stream","name":"stdout","text":["Random training sentence:\n","plasma concentrations of erlotinib were determined using liquid chromatography-tandem mass spectrometry .\n","\n","Sentence after embedding:\n","[ 0.04972843  0.0245137  -0.00262448 -0.03598287 -0.0114791  -0.06060038\n","  0.08276705  0.0240502  -0.02924722  0.04389771  0.04470181  0.08329217\n"," -0.03589243  0.05233528 -0.01691744 -0.0874229  -0.02156726 -0.00449972\n","  0.02769672 -0.01868165 -0.08169562 -0.04626799 -0.01458014  0.03514554\n","  0.00757863  0.01085587 -0.01551721  0.04785957 -0.07610201 -0.05667822] (truncated output)...\n"," \n","Length of sentence embedding:\n","512\n"]}]},{"cell_type":"markdown","metadata":{"id":"rB98xmH4KO-0"},"source":["Nice! As we mentioned before the pretrained USE module from TensorFlow Hub takes care of tokenizing our text for us and outputs a 512 dimensional embedding vector.\n","\n","Let's put together and compile a model using our `tf_hub_embedding_layer`."]},{"cell_type":"markdown","metadata":{"id":"uJue6QIthOZD"},"source":["### Building and fitting an NLP feature extraction model from TensorFlow Hub"]},{"cell_type":"code","source":["# Define feature extractor model using IF Hub layer\n","inputs = layers.Input(shape=[], dtype=tf.string)\n","pretrained_embedding = tf_hub_embedding_layer(inputs) # tokenizes text & pretrained embedding layer\n","x = layers.Dense(128, activation=\"relu\")(pretrained_embedding) # add a fully connected layer on top of the embedding layer for feature extraction\n","# Note: more layers can be added here\n","outputs = layers.Dense(5, activation=\"softmax\")(x) # create the output layer\n","model_2 = tf.keras.Model(inputs=inputs,\n","                         outputs=outputs)\n","\n","# Compile the model\n","model_2.compile(loss=\"categorical_crossentropy\",\n","                optimizer=tf.keras.optimizers.Adam(),\n","                metrics=[\"accuracy\"])"],"metadata":{"id":"xzGRDFppff0x","executionInfo":{"status":"ok","timestamp":1641217593727,"user_tz":300,"elapsed":9,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":177,"outputs":[]},{"cell_type":"code","source":["# Get a summary of the model\n","model_2.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6ZPhXKCXhHL0","executionInfo":{"status":"ok","timestamp":1641217593727,"user_tz":300,"elapsed":9,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"6c44102d-af66-4425-9d3c-3ba60d00196a"},"execution_count":178,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_7 (InputLayer)        [(None,)]                 0         \n","                                                                 \n"," universal_sentence_encoder   (None, 512)              256797824 \n"," (KerasLayer)                                                    \n","                                                                 \n"," dense_9 (Dense)             (None, 128)               65664     \n","                                                                 \n"," dense_10 (Dense)            (None, 5)                 645       \n","                                                                 \n","=================================================================\n","Total params: 256,864,133\n","Trainable params: 66,309\n","Non-trainable params: 256,797,824\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"5Exs-vDmLIs6"},"source":["Checking the summary of our model we can see there's a large number of total parameters, however, the majority of these are non-trainable. This is because we set `training=False` when we instatiated our USE feature extractor layer.\n","\n","So when we train our model, only the top two output layers will be trained."]},{"cell_type":"code","source":["# Fit feature extractor model for 3 epochs\n","model_2.fit(train_dataset,\n","            steps_per_epoch=int(0.1 * len(train_dataset)),\n","            epochs=3,\n","            validation_data=valid_dataset,\n","            validation_steps=int(0.1 * len(valid_dataset)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IVOS5yh6hLXZ","executionInfo":{"status":"ok","timestamp":1641217618965,"user_tz":300,"elapsed":25240,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"eef408aa-7167-4b95-dafe-26c986c58292"},"execution_count":179,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","562/562 [==============================] - 11s 15ms/step - loss: 0.9163 - accuracy: 0.6520 - val_loss: 0.7968 - val_accuracy: 0.6908\n","Epoch 2/3\n","562/562 [==============================] - 7s 12ms/step - loss: 0.7688 - accuracy: 0.7020 - val_loss: 0.7557 - val_accuracy: 0.7041\n","Epoch 3/3\n","562/562 [==============================] - 7s 13ms/step - loss: 0.7524 - accuracy: 0.7117 - val_loss: 0.7390 - val_accuracy: 0.7148\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f7f6181b150>"]},"metadata":{},"execution_count":179}]},{"cell_type":"code","source":["# Evaluate on whole validation datset\n","model_2.evaluate(valid_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nnLB_btrhqxT","executionInfo":{"status":"ok","timestamp":1641217629778,"user_tz":300,"elapsed":10825,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"5863e435-17dc-4dd4-d17b-5d338c809ee5"},"execution_count":180,"outputs":[{"output_type":"stream","name":"stdout","text":["945/945 [==============================] - 11s 11ms/step - loss: 0.7408 - accuracy: 0.7132\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.740763783454895, 0.7132265567779541]"]},"metadata":{},"execution_count":180}]},{"cell_type":"markdown","metadata":{"id":"YmLdj-1tLk3X"},"source":["Since we aren't training our own custom embedding layer, training is much quicker.\n","\n","Let's make some predictions and evaluate our feature extraction model."]},{"cell_type":"code","source":["# Make predictions with feature extraction model\n","model_2_pred_probs = model_2.predict(valid_dataset)\n","model_2_pred_probs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"INqgnHa7hyW5","executionInfo":{"status":"ok","timestamp":1641217640390,"user_tz":300,"elapsed":10614,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"36c983ac-b03e-4c53-8c31-ab42ad5382fd"},"execution_count":181,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[4.4079965e-01, 3.2960761e-01, 2.9858768e-03, 2.1891186e-01,\n","        7.6949145e-03],\n","       [3.2807097e-01, 5.0468475e-01, 3.7274780e-03, 1.6080135e-01,\n","        2.7154416e-03],\n","       [2.4853162e-01, 1.5558259e-01, 2.2599561e-02, 5.3446454e-01,\n","        3.8821690e-02],\n","       ...,\n","       [1.7762600e-03, 6.6153156e-03, 4.6216473e-02, 9.4314635e-04,\n","        9.4444889e-01],\n","       [3.8911819e-03, 4.5958024e-02, 2.0982710e-01, 1.4559544e-03,\n","        7.3886776e-01],\n","       [1.9202676e-01, 2.5820789e-01, 4.7484791e-01, 7.9252981e-03,\n","        6.6992141e-02]], dtype=float32)"]},"metadata":{},"execution_count":181}]},{"cell_type":"code","source":["# Convert the predictions with feature extraction model to classes\n","model_2_preds = tf.argmax(model_2_pred_probs, axis=1)\n","model_2_preds"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3SrvgiqciHOq","executionInfo":{"status":"ok","timestamp":1641217640391,"user_tz":300,"elapsed":12,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"0da9b0d3-4a7e-447e-dbe4-393ef3915a23"},"execution_count":182,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 1, 3, ..., 4, 4, 2])>"]},"metadata":{},"execution_count":182}]},{"cell_type":"code","source":["# Calculate results from TF Hub pretrained embeddings results on validation set\n","model_2_results = calculate_results(y_true=val_labels_encoded,\n","                                    y_pred=model_2_preds)\n","model_2_results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9f14NPNDiYFu","executionInfo":{"status":"ok","timestamp":1641217640391,"user_tz":300,"elapsed":11,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"365487f7-2254-4079-a480-095c7c7ad26c"},"execution_count":183,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'accuracy': 71.3226532503641,\n"," 'f1': 0.7101543640152472,\n"," 'precision': 0.7136587137369151,\n"," 'recall': 0.713226532503641}"]},"metadata":{},"execution_count":183}]},{"cell_type":"markdown","metadata":{"id":"EL6wApSH0ltW"},"source":["## Model 3: Conv1D with character embeddings\n","\n"]},{"cell_type":"markdown","metadata":{"id":"-q-BYLq6d1me"},"source":["### Creating a character-level tokenizer\n","\n","The [*Neural Networks for Joint Sentence Classification\n","in Medical Paper Abstracts*](https://arxiv.org/pdf/1612.05251.pdf) paper mentions their model uses a hybrid of token and character embeddings.\n","\n","We've built models with a custom token embedding and a pretrained token embedding, how about we build one using a character embedding?\n","\n","The difference between a character and token embedding is that the **character embedding** is created using sequences split into characters (e.g. `hello` -> [`h`, `e`, `l`, `l`, `o`]) where as a **token embedding** is created on sequences split into tokens.\n","\n","![example of difference between token level and character level embeddings](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/09-token-vs-character-embeddings.png)\n","*Token level embeddings split sequences into tokens (words) and embeddings each of them, character embeddings split sequences into characters and creates a feature vector for each.*\n","\n","We can create a character-level embedding by first vectorizing our sequences (after they've been split into characters) using the [`TextVectorization`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/TextVectorization) class and then passing those vectorized sequences through an [`Embedding`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding) layer.\n","\n","Before we can vectorize our sequences on a character-level we'll need to split them into characters. Let's write a function to do so."]},{"cell_type":"code","source":["# Make function to split sentences into characters\n","def split_chars(text):\n","  return \" \".join(list(text))\n","\n","# test splitting non-character-level sequence into characters\n","split_chars(random_training_sentence)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"claaqDCGi-Vr","executionInfo":{"status":"ok","timestamp":1641217640391,"user_tz":300,"elapsed":10,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"bca486ba-4b5c-43d2-cbfe-61a5b49296ee"},"execution_count":184,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'p l a s m a   c o n c e n t r a t i o n s   o f   e r l o t i n i b   w e r e   d e t e r m i n e d   u s i n g   l i q u i d   c h r o m a t o g r a p h y - t a n d e m   m a s s   s p e c t r o m e t r y   .'"]},"metadata":{},"execution_count":184}]},{"cell_type":"markdown","metadata":{"id":"NyfYyWOvx2BB"},"source":["Great! Looks like our character-splitting function works. Let's create character-level datasets by splitting our sequence datasets into characters."]},{"cell_type":"code","source":["# Split sequence-level data splits into character-level data splits\n","train_chars = [split_chars(sentence) for sentence in train_sentences]\n","val_chars = [split_chars(sentence) for sentence in val_sentences]\n","test_chars = [split_chars(sentence) for sentence in val_sentences]\n","print(train_chars[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_UzhT26Vj1rl","executionInfo":{"status":"ok","timestamp":1641217641520,"user_tz":300,"elapsed":1133,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"a6ef2d8c-07bc-48c7-f7bc-89a6f138df8d"},"execution_count":185,"outputs":[{"output_type":"stream","name":"stdout","text":["t o   i n v e s t i g a t e   t h e   e f f i c a c y   o f   @   w e e k s   o f   d a i l y   l o w - d o s e   o r a l   p r e d n i s o l o n e   i n   i m p r o v i n g   p a i n   ,   m o b i l i t y   ,   a n d   s y s t e m i c   l o w - g r a d e   i n f l a m m a t i o n   i n   t h e   s h o r t   t e r m   a n d   w h e t h e r   t h e   e f f e c t   w o u l d   b e   s u s t a i n e d   a t   @   w e e k s   i n   o l d e r   a d u l t s   w i t h   m o d e r a t e   t o   s e v e r e   k n e e   o s t e o a r t h r i t i s   (   o a   )   .\n"]}]},{"cell_type":"markdown","metadata":{"id":"vkLTb7FkyFPh"},"source":["To figure out how long our vectorized character sequences should be, let's check the distribution of our character sequence lengths."]},{"cell_type":"code","source":["# what's the average character length?\n","char_lens = [len(sentence) for sentence in train_sentences]\n","mean_char_len = np.mean(char_lens)\n","max_char_len = np.max(char_lens)\n","mean_char_len, max_char_len"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bGDk5iQ8kswI","executionInfo":{"status":"ok","timestamp":1641217641520,"user_tz":300,"elapsed":2,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"8c394eda-f972-4cb5-be9e-3cabd27a69ab"},"execution_count":186,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(149.3662574983337, 1386)"]},"metadata":{},"execution_count":186}]},{"cell_type":"code","source":["# Check the distribution of my sequences at char-level\n","import matplotlib.pyplot as plt\n","plt.hist(char_lens, bins=20);"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"RfiTuatUlJyD","executionInfo":{"status":"ok","timestamp":1641217641883,"user_tz":300,"elapsed":364,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"91cdfb48-e0d0-4cb7-9153-f7be22304fc9"},"execution_count":187,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"pV8yNV6l1hO4"},"source":["Okay, looks like most of our sequences are between 0 and 200 characters long.\n","\n","Let's use NumPy's percentile to figure out what length covers 95% of our sequences."]},{"cell_type":"code","source":["# Find what character length covers 95% of sequences\n","output_seq_char_len = int(np.percentile(char_lens, 95))\n","output_seq_char_len"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Zt3dc7tlaZh","executionInfo":{"status":"ok","timestamp":1641217641883,"user_tz":300,"elapsed":9,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"56230a64-83b3-4359-a1a6-567847b14da0"},"execution_count":188,"outputs":[{"output_type":"execute_result","data":{"text/plain":["290"]},"metadata":{},"execution_count":188}]},{"cell_type":"markdown","metadata":{"id":"4dDBUHMT3QwS"},"source":["Wonderful, now we know the sequence length which covers 95% of sequences, we'll use that in our `TextVectorization` layer as the `output_sequence_length` parameter.\n","\n","> üîë **Note:** You can experiment here to figure out what the optimal `output_sequence_length` should be, perhaps using the mean results in as good results as using the 95% percentile.\n","\n","We'll set `max_tokens` (the total number of different characters in our sequences) to 28, in other words, 26 letters of the alphabet + space + OOV (out of vocabulary or unknown) tokens."]},{"cell_type":"markdown","source":["(I want to do an alphabet of 42)"],"metadata":{"id":"JInH8xGImuS8"}},{"cell_type":"code","source":["# Get all keyword characters for char-level embedding\n","import string\n","alphabet = string.ascii_lowercase + string.digits + string.punctuation\n","alphabet # I think 'string.digits' is unessesary"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"9nUwpxdJmTZk","executionInfo":{"status":"ok","timestamp":1641217641884,"user_tz":300,"elapsed":6,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"d7003c11-8ae6-4a69-80a6-2ee94017e2ee"},"execution_count":189,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'abcdefghijklmnopqrstuvwxyz0123456789!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"]},"metadata":{},"execution_count":189}]},{"cell_type":"code","source":["# Create char-level token vectorizer instance\n","NUM_CHAR_TOKENS = len(alphabet) + 2 # num characters in alphabet + space + OOV token\n","char_vectorizer = TextVectorization(max_tokens=NUM_CHAR_TOKENS,\n","                                    output_sequence_length=output_seq_char_len,\n","                                    standardize=\"lower_and_strip_punctuation\",\n","                                    name=\"char_vectorizer\")\n","\n","# Adapt character vectorizer to training characters\n","char_vectorizer.adapt(train_chars)"],"metadata":{"id":"IsgfjJVZnHYf","executionInfo":{"status":"ok","timestamp":1641217728327,"user_tz":300,"elapsed":86448,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":190,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u5YsVAJ25JKI"},"source":["Nice! Now we've adapted our `char_vectorizer` to our character-level sequences, let's check out some characteristics about it using the [`get_vocabulary()`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/TextVectorization#get_vocabulary) method."]},{"cell_type":"code","source":["# Check character vocabulary characteristics\n","char_vocab = char_vectorizer.get_vocabulary()\n","print(f\"Number of different characters in character vocab: {len(char_vocab)}\")\n","print(f\"5 most common characters: {char_vocab[:5]}\")\n","print(f\"5 least common characters: {char_vocab[-5:]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3pRZgG8BoHHk","executionInfo":{"status":"ok","timestamp":1641217728328,"user_tz":300,"elapsed":19,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"4f570327-1c74-4019-c904-53efdc0725cf"},"execution_count":191,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of different characters in character vocab: 28\n","5 most common characters: ['', '[UNK]', 'e', 't', 'i']\n","5 least common characters: ['k', 'x', 'z', 'q', 'j']\n"]}]},{"cell_type":"markdown","metadata":{"id":"sFYO0vav51zl"},"source":["We can also test it on random sequences of characters to make sure it's working."]},{"cell_type":"code","source":["# Test out character vectorizer\n","random_train_chars = random.choice(train_chars)\n","print(f\"Charified text:\\n{random_train_chars}\")\n","print(f\"\\nLenght of chars: {len(random_train_chars.split())}\")\n","vectorized_chars = char_vectorizer([random_train_chars])\n","print(f\"\\nVectorized chars:\\n{vectorized_chars}\")\n","print(f\"\\nLenght of vectorized chars: {len(vectorized_chars[0])}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hij2lzLXpaAy","executionInfo":{"status":"ok","timestamp":1641217728328,"user_tz":300,"elapsed":13,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"526efdbf-063b-481b-d228-2691e17914af"},"execution_count":192,"outputs":[{"output_type":"stream","name":"stdout","text":["Charified text:\n","w e   (   @   )   a s s e s s e d   o s   o f   p a t i e n t s   t o   d e t e r m i n e   i f   l e s s   i n t e n s i v e   f o l l o w u p   r e g i m e n s   l e d   t o   w o r s e n e d   s u r v i v a l   a n d   a s k e d   (   @   )   w h e t h e r   c h e s t   r a d i o g r a p h   f o l l o w u p   g r o u p   w a s   i n f e r i o r   t o   c t   s c a n   f o l l o w u p   g r o u p   i n   d e t e c t i n g   p u l m o n a r y   m e t a s t a s i s   ;   a n d   (   @   )   w h e t h e r   l e s s   f r e q u e n t   (   @ - m o n t h l y   )   f o l l o w u p   i n t e r v a l   w a s   i n f e r i o r   t o   m o r e   f r e q u e n t   (   @ - m o n t h l y   )   f o l l o w u p   i n   d e t e c t i n g   p u l m o n a r y   m e t a s t a s i s   a n d   l o c a l   r e c u r r e n c e   .\n","\n","Lenght of chars: 342\n","\n","Vectorized chars:\n","[[20  2  5  9  9  2  9  9  2 10  7  9  7 17 14  5  3  4  2  6  3  9  3  7\n","  10  2  3  2  8 15  4  6  2  4 17 12  2  9  9  4  6  3  2  6  9  4 21  2\n","  17  7 12 12  7 20 16 14  8  2 18  4 15  2  6  9 12  2 10  3  7 20  7  8\n","   9  2  6  2 10  9 16  8 21  4 21  5 12  5  6 10  5  9 23  2 10 20 13  2\n","   3 13  2  8 11 13  2  9  3  8  5 10  4  7 18  8  5 14 13 17  7 12 12  7\n","  20 16 14 18  8  7 16 14 20  5  9  4  6 17  2  8  4  7  8  3  7 11  3  9\n","  11  5  6 17  7 12 12  7 20 16 14 18  8  7 16 14  4  6 10  2  3  2 11  3\n","   4  6 18 14 16 12 15  7  6  5  8 19 15  2  3  5  9  3  5  9  4  9  5  6\n","  10 20 13  2  3 13  2  8 12  2  9  9 17  8  2 26 16  2  6  3 15  7  6  3\n","  13 12 19 17  7 12 12  7 20 16 14  4  6  3  2  8 21  5 12 20  5  9  4  6\n","  17  2  8  4  7  8  3  7 15  7  8  2 17  8  2 26 16  2  6  3 15  7  6  3\n","  13 12 19 17  7 12 12  7 20 16 14  4  6 10  2  3  2 11  3  4  6 18 14 16\n","  12 15]]\n","\n","Lenght of vectorized chars: 290\n"]}]},{"cell_type":"markdown","metadata":{"id":"aT_OiBd_6j8W"},"source":["You'll notice sequences with a length shorter than 290 (`output_seq_char_length`) get padded with zeros on the end, this ensures all sequences passed to our model are the same length.\n","\n","Also, due to the `standardize` parameter of `TextVectorization` being `\"lower_and_strip_punctuation\"` and the `split` parameter being `\"whitespace\"` by default, symbols (such as `@`) and spaces are removed.\n","\n","> üîë **Note:** If you didn't want punctuation to be removed (keep the `@`, `%` etc), you can create a custom standardization callable and pass it as the `standardize` parameter. See the [`TextVectorization`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/TextVectorization) class documentation for more.\n"]},{"cell_type":"markdown","metadata":{"id":"m8WEfkrDeNIm"},"source":["### Creating a character-level embedding\n","We've got a way to vectorize our character-level sequences, now's time to create a character-level embedding.\n","\n","Just like our custom token embedding, we can do so using the [`tensorflow.keras.layers.Embedding`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding) class.\n","\n","Our character-level embedding layer requires an input dimension and output dimension. \n","\n","The input dimension (`input_dim`) will be equal to the number of different characters in our `char_vocab` (28). And since we're following the structure of the model in Figure 1 of [*Neural Networks for Joint Sentence Classification\n","in Medical Paper Abstracts*](https://arxiv.org/pdf/1612.05251.pdf), the output dimension of the character embedding (`output_dim`) will be 25."]},{"cell_type":"code","source":["# Create char embedding layer\n","char_embed = layers.Embedding(input_dim=NUM_CHAR_TOKENS, # number of different characters\n","                              output_dim=25, # embedding dim of each char (same as Fig 1 in https://arxiv.org/pdf/1612.05251.pdf)\n","                              mask_zero=False, # don't use masks (masks will mess up model_5)\n","                              name=\"char_embed\")\n","\n","# Test out character embedding layer\n","print(f\"Charified text (before vectorization & embedding):\\n{random_train_chars}\\n\")\n","char_embed_example = char_embed(char_vectorizer([random_train_chars]))\n","print(f\"Embeded chars (after vectorization & embedding):\\n{char_embed_example}\\n\")\n","print(f\"Character embedding shape: {char_embed_example.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EOx97R_zp-Xf","executionInfo":{"status":"ok","timestamp":1641217728328,"user_tz":300,"elapsed":11,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"87422be5-b917-4a61-afd4-beccea70ff3f"},"execution_count":193,"outputs":[{"output_type":"stream","name":"stdout","text":["Charified text (before vectorization & embedding):\n","w e   (   @   )   a s s e s s e d   o s   o f   p a t i e n t s   t o   d e t e r m i n e   i f   l e s s   i n t e n s i v e   f o l l o w u p   r e g i m e n s   l e d   t o   w o r s e n e d   s u r v i v a l   a n d   a s k e d   (   @   )   w h e t h e r   c h e s t   r a d i o g r a p h   f o l l o w u p   g r o u p   w a s   i n f e r i o r   t o   c t   s c a n   f o l l o w u p   g r o u p   i n   d e t e c t i n g   p u l m o n a r y   m e t a s t a s i s   ;   a n d   (   @   )   w h e t h e r   l e s s   f r e q u e n t   (   @ - m o n t h l y   )   f o l l o w u p   i n t e r v a l   w a s   i n f e r i o r   t o   m o r e   f r e q u e n t   (   @ - m o n t h l y   )   f o l l o w u p   i n   d e t e c t i n g   p u l m o n a r y   m e t a s t a s i s   a n d   l o c a l   r e c u r r e n c e   .\n","\n","Embeded chars (after vectorization & embedding):\n","[[[-2.9396821e-02 -2.0747984e-02  2.1821294e-02 ... -9.2093945e-03\n","    1.3117567e-03 -1.5984178e-03]\n","  [ 1.5442912e-02  1.2016486e-02 -4.5299828e-02 ...  1.4579598e-02\n","    3.5699978e-03 -3.0641401e-02]\n","  [ 3.5814557e-02  5.2632019e-04 -2.9298291e-03 ...  3.5606395e-02\n","   -1.9062310e-05 -2.9633272e-02]\n","  ...\n","  [ 3.4296703e-02 -3.3688262e-02 -4.2173207e-02 ... -3.0726267e-02\n","    2.1807663e-03  1.9204747e-02]\n","  [-6.8425424e-03 -2.0754112e-02 -2.2525048e-02 ... -3.8750172e-02\n","   -4.1754186e-02  9.3943253e-03]\n","  [ 4.5205001e-02  3.2655742e-02 -2.6229490e-02 ...  6.9969296e-03\n","    6.3091740e-03 -3.5839461e-02]]]\n","\n","Character embedding shape: (1, 290, 25)\n"]}]},{"cell_type":"markdown","metadata":{"id":"bXuuUjDHPG-J"},"source":["Wonderful! Each of the characters in our sequences gets turned into a 25 dimension embedding.\n"," "]},{"cell_type":"markdown","metadata":{"id":"1bzv_FmFd9bN"},"source":["### Building a Conv1D model to fit on character embeddings\n","Now we've got a way to turn our character-level sequences into numbers (`char_vectorizer`) as well as numerically represent them as an embedding (`char_embed`) let's test how effective they are at encoding the information in our sequences by creating a character-level sequence model.\n","\n","The model will have the same structure as our custom token embedding model (`model_1`) except it'll take character-level sequences as input instead of token-level sequences.\n","\n","```\n","Input (character-level text) -> Tokenize -> Embedding -> Layers (Conv1D, GlobalMaxPool1D) -> Output (label probability)\n","```\n"]},{"cell_type":"code","source":["# Make Conv1D on chars only\n","inputs = layers.Input(shape=(1,), dtype=\"string\")\n","char_vectors = char_vectorizer(inputs)\n","char_embeddings = char_embed(char_vectors)\n","x = layers.Conv1D(64, kernel_size=5, padding=\"same\", activation=\"relu\")(char_embeddings)\n","x = layers.GlobalMaxPool1D()(x)\n","outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n","model_3 = tf.keras.Model(inputs=inputs, \n","                         outputs=outputs,\n","                         name=\"model_3_conv1D_char_embedding\")\n","\n","# Compile model\n","model_3.compile(loss=\"categorical_crossentropy\",\n","                optimizer=tf.keras.optimizers.Adam(),\n","                metrics=[\"accuracy\"])"],"metadata":{"id":"39hXYAFq7Syk","executionInfo":{"status":"ok","timestamp":1641217728329,"user_tz":300,"elapsed":12,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":194,"outputs":[]},{"cell_type":"code","source":["# Check the summary of conv1d_char_model\n","model_3.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nUXxatIC9JbW","executionInfo":{"status":"ok","timestamp":1641217728329,"user_tz":300,"elapsed":11,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"51f02c18-34cf-45e1-f866-5313354db273"},"execution_count":195,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_3_conv1D_char_embedding\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_8 (InputLayer)        [(None, 1)]               0         \n","                                                                 \n"," char_vectorizer (TextVector  (None, 290)              0         \n"," ization)                                                        \n","                                                                 \n"," char_embed (Embedding)      (None, 290, 25)           1750      \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 290, 64)           8064      \n","                                                                 \n"," global_max_pooling1d_2 (Glo  (None, 64)               0         \n"," balMaxPooling1D)                                                \n","                                                                 \n"," dense_11 (Dense)            (None, 5)                 325       \n","                                                                 \n","=================================================================\n","Total params: 10,139\n","Trainable params: 10,139\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"Sr9rNkxAkURZ"},"source":["Before fitting our model on the data, we'll create char-level batched `PrefetchedDataset`'s."]},{"cell_type":"code","source":["# Create chat datasets\n","train_char_dataset = tf.data.Dataset.from_tensor_slices((train_chars, train_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n","val_char_dataset = tf.data.Dataset.from_tensor_slices((val_chars, val_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n","\n","train_char_dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vj69jsXj9Pak","executionInfo":{"status":"ok","timestamp":1641217729434,"user_tz":300,"elapsed":1117,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"afdac8d6-16fb-4107-b4cc-1c925a60c422"},"execution_count":196,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<PrefetchDataset shapes: ((None,), (None, 5)), types: (tf.string, tf.float64)>"]},"metadata":{},"execution_count":196}]},{"cell_type":"markdown","metadata":{"id":"8qpv1NR_cC1h"},"source":["Just like our token-level sequence model, to save time with our experiments, we'll fit the character-level model on 10% of batches."]},{"cell_type":"code","source":["# Fit the model on chars only\n","model_3_history = model_3.fit(train_char_dataset,\n","                              steps_per_epoch=int(0.1 * len(train_char_dataset)),\n","                              epochs=3,\n","                              validation_data=val_char_dataset,\n","                              validation_steps=int(0.1 * len(val_char_dataset)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4RW8uG43-AKh","executionInfo":{"status":"ok","timestamp":1641217769487,"user_tz":300,"elapsed":40054,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"bfb334c0-dc18-4307-d742-fc07274ddec6"},"execution_count":197,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","562/562 [==============================] - 14s 23ms/step - loss: 1.2551 - accuracy: 0.4954 - val_loss: 1.0463 - val_accuracy: 0.5878\n","Epoch 2/3\n","562/562 [==============================] - 13s 23ms/step - loss: 1.0125 - accuracy: 0.5959 - val_loss: 0.9477 - val_accuracy: 0.6257\n","Epoch 3/3\n","562/562 [==============================] - 13s 23ms/step - loss: 0.9313 - accuracy: 0.6362 - val_loss: 0.8704 - val_accuracy: 0.6619\n"]}]},{"cell_type":"code","source":["# Evaluate model_3 on whole validation char dataset\n","model_3.evaluate(val_char_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-nV2r1CP-ocW","executionInfo":{"status":"ok","timestamp":1641217775907,"user_tz":300,"elapsed":6429,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"d0070482-1e93-48d2-a23a-a28a387c9400"},"execution_count":198,"outputs":[{"output_type":"stream","name":"stdout","text":["945/945 [==============================] - 7s 7ms/step - loss: 0.8902 - accuracy: 0.6568\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.8902265429496765, 0.6568251252174377]"]},"metadata":{},"execution_count":198}]},{"cell_type":"markdown","metadata":{"id":"8sMIB_nXJd-M"},"source":["Nice! Looks like our character-level model is working, let's make some predictions with it and evaluate them."]},{"cell_type":"code","source":["# Make predictions with char model only\n","model_3_pred_probs = model_3.predict(val_char_dataset)\n","model_3_pred_probs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QhMC2NTI-1a8","executionInfo":{"status":"ok","timestamp":1641217786510,"user_tz":300,"elapsed":10612,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"874a8df2-ef0f-4c40-e71b-bada31456b93"},"execution_count":199,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.11112556, 0.4120063 , 0.16145857, 0.25167203, 0.06373744],\n","       [0.12867764, 0.57099175, 0.00643006, 0.2616002 , 0.03230033],\n","       [0.08782197, 0.39612794, 0.24262679, 0.1880367 , 0.08538657],\n","       ...,\n","       [0.01315636, 0.02405709, 0.1643889 , 0.00907296, 0.7893247 ],\n","       [0.01826041, 0.12870584, 0.24802442, 0.01806302, 0.58694625],\n","       [0.2624265 , 0.45525974, 0.20376684, 0.05709464, 0.02145229]],\n","      dtype=float32)"]},"metadata":{},"execution_count":199}]},{"cell_type":"code","source":["# Conver predictions to classes\n","model_3_preds = tf.argmax(model_3_pred_probs, axis=1)\n","model_3_preds"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FHt-sXua_I16","executionInfo":{"status":"ok","timestamp":1641217786511,"user_tz":300,"elapsed":19,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"0a958390-0694-4ce8-8121-9dbd60a97091"},"execution_count":200,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([1, 1, 1, ..., 4, 4, 1])>"]},"metadata":{},"execution_count":200}]},{"cell_type":"code","source":["# Calculate Conv1D char only model results\n","model_3_results = calculate_results(y_true=val_labels_encoded,\n","                                    y_pred=model_3_preds)\n","model_3_results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a2-KReoX_UI1","executionInfo":{"status":"ok","timestamp":1641217786511,"user_tz":300,"elapsed":12,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"d57f42dd-8694-4574-97d5-6e6d80111145"},"execution_count":201,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'accuracy': 65.6825102608235,\n"," 'f1': 0.6450198238264204,\n"," 'precision': 0.646753998240745,\n"," 'recall': 0.6568251026082351}"]},"metadata":{},"execution_count":201}]},{"cell_type":"markdown","metadata":{"id":"1krE-3csz3N-"},"source":["## Model 4: Combining pretrained token embeddings + character embeddings (hybrid embedding layer)\n","\n","Alright, now things are going to get spicy.\n","\n","In moving closer to build a model similar to the one in Figure 1 of [*Neural Networks for Joint Sentence Classification\n","in Medical Paper Abstracts*](https://arxiv.org/pdf/1612.05251.pdf), it's time we tackled the hybrid token embedding layer they speak of.\n","\n","This hybrid token embedding layer is a combination of token embeddings and character embeddings. In other words, they create a stacked embedding to represent sequences before passing them to the sequence label prediction layer.\n","\n","So far we've built two models which have used token and character-level embeddings, however, these two models have used each of these embeddings exclusively.\n","\n","To start replicating (or getting close to replicating) the model in Figure 1, we're going to go through the following steps:\n","1. Create a token-level model (similar to `model_1`)\n","2. Create a character-level model (similar to `model_3` with a slight modification to reflect the paper)\n","3. Combine (using [`layers.Concatenate`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Concatenate)) the outputs of 1 and 2\n","4. Build a series of output layers on top of 3 similar to Figure 1 and section 4.2 of [*Neural Networks for Joint Sentence Classification\n","in Medical Paper Abstracts*](https://arxiv.org/pdf/1612.05251.pdf)\n","5. Construct a model which takes token and character-level sequences as input and produces sequence label probabilities as output"]},{"cell_type":"code","source":["# 1. Set up token-level inputs/model\n","token_inputs = layers.Input(shape=[], dtype=tf.string, name=\"token_input\")\n","token_embeddings = tf_hub_embedding_layer(token_inputs)\n","token_output = layers.Dense(128, activation=\"relu\")(token_embeddings)\n","token_model = tf.keras.Model(inputs=token_inputs,\n","                             outputs=token_output)\n","\n","# 2. Setup char inputs/model\n","char_inputs = layers.Input(shape=(1,), dtype=tf.string, name=\"char_input\")\n","char_vectors = char_vectorizer(char_inputs)\n","char_embeddings = char_embed(char_vectors)\n","char_bi_lstm = layers.Bidirectional(layers.LSTM(25))(char_embeddings) # bi-LSTM shown in Figure 1 of https://arxiv.org/pdf/1612.05251.pdf\n","char_model = tf.keras.Model(inputs=char_inputs,\n","                            outputs=char_bi_lstm)\n","\n","# 3. Concatenate toke & char input layers (create hybrid token embedding)\n","token_char_concat = layers.Concatenate(name=\"token_char_hybrid\")([token_model.output, \n","                                                                  char_model.output])\n","\n","# 4. Create output layers -  addition of dropout discussed in 4.2 of https://arxiv.org/pdf/1612.05251.pdf\n","combined_dropout = layers.Dropout(0.5)(token_char_concat)\n","combined_dense = layers.Dense(200, activation=\"relu\")(combined_dropout) # slightly different to Figure 1 due to different shapes of token/char embedding layers\n","final_dropout = layers.Dropout(0.5)(combined_dense)\n","output_layer = layers.Dense(num_classes, activation=\"softmax\")(final_dropout)\n","\n","# 5. Construct model with char & token inputs\n","model_4 = tf.keras.Model(inputs=[token_model.input, char_model.input],\n","                         outputs=output_layer,\n","                         name=\"model_4_token_and_char_embeddings\")"],"metadata":{"id":"KbJuwZ0J_kNa","executionInfo":{"status":"ok","timestamp":1641217787279,"user_tz":300,"elapsed":778,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":202,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ODM7t4aaVhcO"},"source":["Woah... There's a lot going on here, let's get a summary and plot our model to visualize what's happening."]},{"cell_type":"code","source":["# get token & char model summary\n","model_4.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-KmCtj5cBVMo","executionInfo":{"status":"ok","timestamp":1641217787279,"user_tz":300,"elapsed":10,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"8ba4a8a1-ca97-48af-b2a0-4d959c888eeb"},"execution_count":203,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_4_token_and_char_embeddings\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," char_input (InputLayer)        [(None, 1)]          0           []                               \n","                                                                                                  \n"," token_input (InputLayer)       [(None,)]            0           []                               \n","                                                                                                  \n"," char_vectorizer (TextVectoriza  (None, 290)         0           ['char_input[0][0]']             \n"," tion)                                                                                            \n","                                                                                                  \n"," universal_sentence_encoder (Ke  (None, 512)         256797824   ['token_input[0][0]']            \n"," rasLayer)                                                                                        \n","                                                                                                  \n"," char_embed (Embedding)         (None, 290, 25)      1750        ['char_vectorizer[1][0]']        \n","                                                                                                  \n"," dense_12 (Dense)               (None, 128)          65664       ['universal_sentence_encoder[1][0\n","                                                                 ]']                              \n","                                                                                                  \n"," bidirectional_1 (Bidirectional  (None, 50)          10200       ['char_embed[1][0]']             \n"," )                                                                                                \n","                                                                                                  \n"," token_char_hybrid (Concatenate  (None, 178)         0           ['dense_12[0][0]',               \n"," )                                                                'bidirectional_1[0][0]']        \n","                                                                                                  \n"," dropout (Dropout)              (None, 178)          0           ['token_char_hybrid[0][0]']      \n","                                                                                                  \n"," dense_13 (Dense)               (None, 200)          35800       ['dropout[0][0]']                \n","                                                                                                  \n"," dropout_1 (Dropout)            (None, 200)          0           ['dense_13[0][0]']               \n","                                                                                                  \n"," dense_14 (Dense)               (None, 5)            1005        ['dropout_1[0][0]']              \n","                                                                                                  \n","==================================================================================================\n","Total params: 256,912,243\n","Trainable params: 114,419\n","Non-trainable params: 256,797,824\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["# Plot hybrid token & char model\n","from tensorflow.keras.utils import plot_model\n","plot_model(model_4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":794},"id":"e9Atc0g-BknW","executionInfo":{"status":"ok","timestamp":1641217788288,"user_tz":300,"elapsed":1012,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"1b523d37-d2e0-4da6-c92b-8932b223825d"},"execution_count":204,"outputs":[{"output_type":"execute_result","data":{"image/png":"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\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{},"execution_count":204}]},{"cell_type":"markdown","metadata":{"id":"oPPfr_cTWmEH"},"source":["Now that's a good looking model. Let's compile it just as we have the rest of our models.\n","\n","> üîë **Note:** Section 4.2 of [*Neural Networks for Joint Sentence Classification\n","in Medical Paper Abstracts*](https://arxiv.org/pdf/1612.05251.pdf) mentions using the SGD (stochastic gradient descent) optimizer, however, to stay consistent with our other models, we're going to use the Adam optimizer. As an exercise, you could try using [`tf.keras.optimizers.SGD`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD) instead of [`tf.keras.optimizers.Adam`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) and compare the results."]},{"cell_type":"code","source":["# Compile token char model\n","model_4.compile(loss=\"categorical_crossentropy\",\n","                optimizer=tf.keras.optimizers.Adam(), # section 4.2 of https://arxiv.org/pdf/1612.05251.pdf mentions SGD, I will use Adam\n","                metrics=[\"accuracy\"])"],"metadata":{"id":"yDOp-DC9CJ0u","executionInfo":{"status":"ok","timestamp":1641217788288,"user_tz":300,"elapsed":4,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":205,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f-bD7bL-UIn3"},"source":["And again, to keep our experiments fast, we'll fit our token-character-hybrid model on 10% of training and validate on 10% of validation batches. However, the difference with this model is that it requires two inputs, token-level sequences and character-level sequences.\n","\n","We can do this by create a `tf.data.Dataset` with a tuple as it's first input, for example:\n","* `((token_data, char_data), (label))`\n","\n","Let's see it in action.\n","\n","### Combining token and character data into a `tf.data` dataset"]},{"cell_type":"code","source":["# Combine chars & tokens into a dataset\n","train_char_token_data = tf.data.Dataset.from_tensor_slices((train_sentences, train_chars)) # make data\n","train_char_token_labels = tf.data.Dataset.from_tensor_slices(train_labels_one_hot) # make labels\n","train_char_token_dataset = tf.data.Dataset.zip((train_char_token_data, train_char_token_labels)) # combine data and labels\n","\n","# Prefetch & batch train data\n","train_char_token_dataset = train_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE) \n","\n","# Repeat same steps for validation data\n","val_char_token_data = tf.data.Dataset.from_tensor_slices((val_sentences, val_chars))\n","val_char_token_labels = tf.data.Dataset.from_tensor_slices(val_labels_one_hot)\n","val_char_token_dataset = tf.data.Dataset.zip((val_char_token_data, val_char_token_labels))\n","val_char_token_dataset = val_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"],"metadata":{"id":"0Ti_v5GgC_df","executionInfo":{"status":"ok","timestamp":1641217790276,"user_tz":300,"elapsed":1991,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":206,"outputs":[]},{"cell_type":"code","source":["# Check my train char & token datasets\n","train_char_token_dataset, val_char_token_dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wVD-xYcvFkND","executionInfo":{"status":"ok","timestamp":1641217790279,"user_tz":300,"elapsed":13,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"5fdb408b-b5cd-4fa8-c360-eb3733f7e55a"},"execution_count":207,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(<PrefetchDataset shapes: (((None,), (None,)), (None, 5)), types: ((tf.string, tf.string), tf.float64)>,\n"," <PrefetchDataset shapes: (((None,), (None,)), (None, 5)), types: ((tf.string, tf.string), tf.float64)>)"]},"metadata":{},"execution_count":207}]},{"cell_type":"markdown","metadata":{"id":"ANLBMpRlfA73"},"source":["### Fitting a model on token and character-level sequences"]},{"cell_type":"code","source":["# Fit model on tokens & chars\n","model_4_history = model_4.fit(train_char_token_dataset, # train on dataset of tokens & chars\n","                              steps_per_epoch=int(0.1 * len(train_char_token_dataset)),\n","                              epochs=3,\n","                              validation_data=val_char_token_dataset,\n","                              validation_steps=int(0.1 * len(val_char_token_dataset)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FIQPr-6tFyh-","executionInfo":{"status":"ok","timestamp":1641218225583,"user_tz":300,"elapsed":435313,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"1975edf2-c789-4b65-ba8c-e8fafc72a624"},"execution_count":208,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","562/562 [==============================] - 170s 294ms/step - loss: 0.9685 - accuracy: 0.6177 - val_loss: 0.7780 - val_accuracy: 0.6975\n","Epoch 2/3\n","562/562 [==============================] - 134s 238ms/step - loss: 0.7899 - accuracy: 0.6932 - val_loss: 0.7112 - val_accuracy: 0.7317\n","Epoch 3/3\n","562/562 [==============================] - 131s 234ms/step - loss: 0.7652 - accuracy: 0.7040 - val_loss: 0.6835 - val_accuracy: 0.7420\n"]}]},{"cell_type":"code","source":["# Evaluate on whole validation dataset\n","model_4.evaluate(val_char_token_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RuqCf8qUGiA8","executionInfo":{"status":"ok","timestamp":1641218267674,"user_tz":300,"elapsed":42103,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"f6c6aba4-cb54-4d50-b1fd-a16f45079c80"},"execution_count":209,"outputs":[{"output_type":"stream","name":"stdout","text":["945/945 [==============================] - 42s 45ms/step - loss: 0.6916 - accuracy: 0.7357\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.6915848255157471, 0.7357010245323181]"]},"metadata":{},"execution_count":209}]},{"cell_type":"markdown","metadata":{"id":"uSimi5vYY2xF"},"source":["Nice! Our token-character hybrid model has come to life!\n","\n","To make predictions with it, since it takes multiplie inputs, we can pass the `predict()` method a tuple of token-level sequences and character-level sequences.\n","\n","We can then evaluate the predictions as we've done before."]},{"cell_type":"code","source":["# Make predictions using the token-char model hybrid\n","model_4_pred_probs = model_4.predict(val_char_token_dataset)\n","model_4_pred_probs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SaVum68HJnq_","executionInfo":{"status":"ok","timestamp":1641218350827,"user_tz":300,"elapsed":83162,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"6bcd4060-e476-457c-9daa-04b3cbd3168b"},"execution_count":210,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[4.0368378e-01, 4.1148064e-01, 3.7419798e-03, 1.7316227e-01,\n","        7.9314057e-03],\n","       [3.3663523e-01, 4.3840927e-01, 2.5213112e-03, 2.2095793e-01,\n","        1.4761747e-03],\n","       [2.8420451e-01, 1.5068494e-01, 5.3969689e-02, 4.8416993e-01,\n","        2.6970958e-02],\n","       ...,\n","       [3.7947283e-04, 5.1394301e-03, 3.7072953e-02, 9.4709008e-05,\n","        9.5731342e-01],\n","       [6.3558887e-03, 9.0108782e-02, 1.7287159e-01, 2.7666588e-03,\n","        7.2789711e-01],\n","       [3.2207310e-01, 4.5110589e-01, 1.6279064e-01, 2.7483471e-02,\n","        3.6546964e-02]], dtype=float32)"]},"metadata":{},"execution_count":210}]},{"cell_type":"code","source":["# Turn prediction probabilities into prediction classes\n","model_4_preds = tf.argmax(model_4_pred_probs, axis=1)\n","model_4_preds"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C2RnYEd5J7qx","executionInfo":{"status":"ok","timestamp":1641218350828,"user_tz":300,"elapsed":21,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"bb15bfb5-e697-430b-841a-c73172aa20b8"},"execution_count":211,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([1, 1, 3, ..., 4, 4, 1])>"]},"metadata":{},"execution_count":211}]},{"cell_type":"code","source":["# Get results of token-char-hybrid model\n","model_4_results = calculate_results(y_true=val_labels_encoded,\n","                                    y_pred=model_4_preds)\n","model_4_results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_l_mYRFKKIxv","executionInfo":{"status":"ok","timestamp":1641218350828,"user_tz":300,"elapsed":14,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"09f9a028-c605-48c2-b50b-9d0b1524835a"},"execution_count":212,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'accuracy': 73.57010459420098,\n"," 'f1': 0.7320303543211234,\n"," 'precision': 0.7381974867445853,\n"," 'recall': 0.7357010459420098}"]},"metadata":{},"execution_count":212}]},{"cell_type":"markdown","metadata":{"id":"wU5ctbxCih6Z"},"source":["## Model 5: Transfer Learning with pretrained token embeddings + character embeddings + positional embeddings \n","\n","It seems like combining token embeddings and character embeddings gave our model a little performance boost.\n","\n","But there's one more piece of the puzzle we can add in.\n","\n","What if we engineered our own features into the model?\n","\n","Meaning, what if we took our own knowledge about the data and encoded it in a numerical way to give our model more information about our samples?\n","\n","The process of applying your own knowledge to build features as input to a model is called **feature engineering**.\n","\n","Can you think of something important about the sequences we're trying to classify?\n","\n","If you were to look at an abstract, would you expect the sentences to appear in order? Or does it make sense if they were to appear sequentially? For example, sequences labelled `CONCLUSIONS` at the beggining and sequences labelled `OBJECTIVE` at the end?\n","\n","Abstracts typically come in a sequential order, such as:\n","* `OBJECTIVE` ...\n","* `METHODS` ...\n","* `METHODS` ...\n","* `METHODS` ...\n","* `RESULTS` ...\n","* `CONCLUSIONS` ...\n","\n","Or\n","\n","* `BACKGROUND` ...\n","* `OBJECTIVE` ...\n","* `METHODS` ...\n","* `METHODS` ...\n","* `RESULTS` ...\n","* `RESULTS` ...\n","* `CONCLUSIONS` ...\n","* `CONCLUSIONS` ...\n","\n","Of course, we can't engineer the sequence labels themselves into the training data (we don't have these at test time), but we can encode the order of a set of sequences in an abstract.\n","\n","For example,\n","* `Sentence 1 of 10` ...\n","* `Sentence 2 of 10` ...\n","* `Sentence 3 of 10` ...\n","* `Sentence 4 of 10` ...\n","* ...\n","\n","\n","You might've noticed this when we created our `preprocess_text_with_line_numbers()` function. When we read in a text file of abstracts, we counted the number of lines in an abstract as well as the number of each line itself.\n","\n","Doing this led to the `\"line_number\"` and `\"total_lines\"` columns of our DataFrames."]},{"cell_type":"code","source":["# Inspect training dataframe:\n","train_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":302},"id":"0pPLjwFvKdSI","executionInfo":{"status":"ok","timestamp":1641218350828,"user_tz":300,"elapsed":11,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"4004d011-2762-41aa-dc5d-64b5391d1f87"},"execution_count":213,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-7486010d-b4bc-4e70-9020-2d5077ecbd2a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>target</th>\n","      <th>text</th>\n","      <th>line_number</th>\n","      <th>total_lines</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>OBJECTIVE</td>\n","      <td>to investigate the efficacy of @ weeks of dail...</td>\n","      <td>0</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>METHODS</td>\n","      <td>a total of @ patients with primary knee oa wer...</td>\n","      <td>1</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>METHODS</td>\n","      <td>outcome measures included pain reduction and i...</td>\n","      <td>2</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>METHODS</td>\n","      <td>pain was assessed using the visual analog pain...</td>\n","      <td>3</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>METHODS</td>\n","      <td>secondary outcome measures included the wester...</td>\n","      <td>4</td>\n","      <td>11</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7486010d-b4bc-4e70-9020-2d5077ecbd2a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7486010d-b4bc-4e70-9020-2d5077ecbd2a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7486010d-b4bc-4e70-9020-2d5077ecbd2a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["      target  ... total_lines\n","0  OBJECTIVE  ...          11\n","1    METHODS  ...          11\n","2    METHODS  ...          11\n","3    METHODS  ...          11\n","4    METHODS  ...          11\n","\n","[5 rows x 4 columns]"]},"metadata":{},"execution_count":213}]},{"cell_type":"markdown","metadata":{"id":"IZ5HvKoiGU6m"},"source":["The `\"line_number\"` and `\"total_lines\"` columns are features which didn't necessarily come with the training data but can be passed to our model as a **positional embedding**. In other words, the positional embedding is where the sentence appears in an abstract.\n","\n","We can use these features because they will be available at test time. \n","\n","![example of engineering features into our dataset to help our model](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/09-engineered-features-at-test-time.png)\n","*Since abstracts typically have a sequential order about them (for example, background, objective, methods, results, conclusion), it makes sense to add the line number of where a particular sentence occurs to our model. The beautiful thing is, these features will be available at test time (we can just count the number of sentences in an abstract and the number of each one).*\n","\n","Meaning, if we were to predict the labels of sequences in an abstract our model had never seen, we could count the number of lines and the track the position of each individual line and pass it to our model.\n","\n","> üõ† **Exercise:** Another way of creating our positional embedding feature would be to combine the `\"line_number\"` and `\"total_lines\"` columns into one, for example a `\"line_position\"` column may contain values like `1_of_11`, `2_of_11`, etc. Where `1_of_11` would be the first line in an abstract 11 sentences long. After going through the following steps, you might want to revisit this positional embedding stage and see how a combined column of `\"line_position\"` goes against two separate columns."]},{"cell_type":"markdown","metadata":{"id":"ABuz5baDJwY-"},"source":["### Create positional embeddings\n","\n","Okay, enough talk about positional embeddings, let's create them.\n","\n","Since our `\"line_number\"` and `\"total_line\"` columns are already numerical, we could pass them as they are to our model.\n","\n","But to avoid our model thinking a line with `\"line_number\"=5` is five times greater than a line with `\"line_number\"=1`, we'll use one-hot-encoding to encode our `\"line_number\"` and `\"total_lines\"` features.\n","\n","To do this, we can use the [`tf.one_hot`](https://www.tensorflow.org/api_docs/python/tf/one_hot) utility.\n","\n","`tf.one_hot` returns a one-hot-encoded tensor. It accepts an array (or tensor) as input and the `depth` parameter determines the dimension of the returned tensor.\n","\n","To figure out what we should set the `depth` parameter to, let's investigate the distribution of the `\"line_number\"` column.\n","\n","> üîë **Note:** When it comes to one-hot-encoding our features, Scikit-Learn's [`OneHotEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) class is another viable option here."]},{"cell_type":"code","source":["# How many different line nums are there?\n","train_df[\"line_number\"].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TcILqicLCiF8","executionInfo":{"status":"ok","timestamp":1641218350829,"user_tz":300,"elapsed":11,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"06525a0f-1e70-47d8-ee19-1db12e027ae4"},"execution_count":214,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0     15000\n","1     15000\n","2     15000\n","3     15000\n","4     14992\n","5     14949\n","6     14758\n","7     14279\n","8     13346\n","9     11981\n","10    10041\n","11     7892\n","12     5853\n","13     4152\n","14     2835\n","15     1861\n","16     1188\n","17      751\n","18      462\n","19      286\n","20      162\n","21      101\n","22       66\n","23       33\n","24       22\n","25       14\n","26        7\n","27        4\n","28        3\n","29        1\n","30        1\n","Name: line_number, dtype: int64"]},"metadata":{},"execution_count":214}]},{"cell_type":"code","source":["# Check the distribution of \"line_number\" colums\n","train_df.line_number.plot.hist()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"id":"3DxvckimDVbS","executionInfo":{"status":"ok","timestamp":1641218351150,"user_tz":300,"elapsed":329,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"4025e7c8-aea5-4f77-d007-85b420c2abbd"},"execution_count":215,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f7f58186ad0>"]},"metadata":{},"execution_count":215},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"pPnEkJvXKuf9"},"source":["Looking at the distribution of the `\"line_number\"` column, it looks like the majority of lines have a position of 15 or less.\n","\n","Knowing this, let's set the `depth` parameter of `tf.one_hot` to 15."]},{"cell_type":"code","source":["# Use TensorFlow to create one-hot-encoded tensors of my \"line_number\" column\n","train_line_numbers_one_hot = tf.one_hot(train_df[\"line_number\"].to_numpy(), depth=15)\n","val_line_numbers_one_hot = tf.one_hot(val_df[\"line_number\"].to_numpy(), depth=15)\n","test_line_numbers_one_hot = tf.one_hot(test_df[\"line_number\"].to_numpy(), depth=15)"],"metadata":{"id":"QH5yHtb9Dhan","executionInfo":{"status":"ok","timestamp":1641218351150,"user_tz":300,"elapsed":13,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":216,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7MTRSo_OLWGS"},"source":["Setting the `depth` parameter of `tf.one_hot` to 15 means any sample with a `\"line_number\"` value of over 15 gets set to a tensor of all 0's, where as any sample with a `\"line_number\"` of under 15 gets turned into a tensor of all 0's but with a 1 at the index equal to the `\"line_number\"` value.\n","\n","> üîë **Note:** We could create a one-hot tensor which has room for all of the potential values of `\"line_number\"` (`depth=30`), however, this would end up in a tensor of double the size of our current one (`depth=15`) where the vast majority of values are 0. Plus, only ~2,000/180,000 samples have a `\"line_number\"` value of over 15. So we would not be gaining much information about our data for doubling our feature space. This kind of problem is called the **curse of dimensionality**. However, since this we're working with deep models, it might be worth trying to throw as much information at the model as possible and seeing what happens. I'll leave exploring values of the `depth` parameter as an extension."]},{"cell_type":"code","source":["# Check one-hot encoded \"line_number\" feature samples\n","train_line_numbers_one_hot.shape, train_line_numbers_one_hot[:20]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IF7ZCzASEbGb","executionInfo":{"status":"ok","timestamp":1641218351151,"user_tz":300,"elapsed":14,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"ab9141ff-a9fc-4706-d278-2d736445e897"},"execution_count":217,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(TensorShape([180040, 15]), <tf.Tensor: shape=(20, 15), dtype=float32, numpy=\n"," array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]],\n","       dtype=float32)>)"]},"metadata":{},"execution_count":217}]},{"cell_type":"markdown","metadata":{"id":"CxYgKu6tMBbg"},"source":["We can do the same as we've done for our `\"line_number\"` column witht he `\"total_lines\"` column. First, let's find an appropriate value for the `depth` parameter of `tf.one_hot`."]},{"cell_type":"code","source":["# How many different numbers of lines are there?\n","train_df[\"total_lines\"].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fZS1LiovFMkf","executionInfo":{"status":"ok","timestamp":1641218351151,"user_tz":300,"elapsed":8,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"816371e8-998a-4762-bc47-d059594c5d2a"},"execution_count":218,"outputs":[{"output_type":"execute_result","data":{"text/plain":["11    24468\n","10    23639\n","12    22113\n","9     19400\n","13    18438\n","14    14610\n","8     12285\n","15    10768\n","7      7464\n","16     7429\n","17     5202\n","6      3353\n","18     3344\n","19     2480\n","20     1281\n","5      1146\n","21      770\n","22      759\n","23      264\n","4       215\n","24      200\n","25      182\n","26       81\n","28       58\n","3        32\n","30       31\n","27       28\n","Name: total_lines, dtype: int64"]},"metadata":{},"execution_count":218}]},{"cell_type":"code","source":["# Check the distrobution of total lines\n","train_df.total_lines.plot.hist();"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":267},"id":"NfDorwyDFcer","executionInfo":{"status":"ok","timestamp":1641218351508,"user_tz":300,"elapsed":361,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"4647bd1a-22d4-4825-e7e2-39dd52f8a079"},"execution_count":219,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"iBWX2cIHN_1J"},"source":["Looking at the distribution of our `\"total_lines\"` column, a value of 20 looks like it covers the majority of samples.\n","\n","We can confirm this with [`np.percentile()`](https://numpy.org/doc/stable/reference/generated/numpy.percentile.html)."]},{"cell_type":"code","source":["# Check the coverage of a \"total_lines\" value of 20\n","np.percentile(train_df.total_lines, 98) # a value of 20 covers 98% of samples"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GuTStOH_F3YM","executionInfo":{"status":"ok","timestamp":1641218351508,"user_tz":300,"elapsed":12,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"5b324780-f97b-4c57-f076-181d86918fbd"},"execution_count":220,"outputs":[{"output_type":"execute_result","data":{"text/plain":["20.0"]},"metadata":{},"execution_count":220}]},{"cell_type":"markdown","metadata":{"id":"dy8Ds74HOLXQ"},"source":["Beautiful! Plenty of converage. Let's one-hot-encode our `\"total_lines\"` column just as we did our `\"line_number\"` column."]},{"cell_type":"code","source":["# Use TensorFlow to create one-hot-encoded tensors of my \"total_lines\" colum\n","train_total_lines_one_hot = tf.one_hot(train_df[\"total_lines\"].to_numpy(), depth=20)\n","val_total_lines_one_hot = tf.one_hot(val_df[\"total_lines\"].to_numpy(), depth=20)\n","test_total_lines_one_hot = tf.one_hot(test_df[\"total_lines\"].to_numpy(), depth=20)\n","\n","# Check shape & samples of total lines one-hot tensor\n","train_total_lines_one_hot.shape, train_total_lines_one_hot[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cjNS3GVPGQOH","executionInfo":{"status":"ok","timestamp":1641218351508,"user_tz":300,"elapsed":8,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"65849c68-71ec-4add-8f38-ce26f93679c2"},"execution_count":221,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(TensorShape([180040, 20]), <tf.Tensor: shape=(10, 20), dtype=float32, numpy=\n"," array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n","         0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n","         0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n","         0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n","         0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n","         0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n","         0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n","         0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n","         0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n","         0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n","         0., 0., 0., 0.]], dtype=float32)>)"]},"metadata":{},"execution_count":221}]},{"cell_type":"markdown","metadata":{"id":"JVJWCANtQMiJ"},"source":["### Building a tribrid embedding model\n","\n","Woohoo! Positional embedding tensors ready.\n","\n","It's time to build the biggest model we've built yet. One which incorporates token embeddings, character embeddings and our newly crafted positional embeddings.\n","\n","We'll be venturing into uncovered territory but there will be nothing here you haven't practiced before.\n","\n","More specifically we're going to go through the following steps:\n","\n","1. Create a token-level model (similar to `model_1`)\n","2. Create a character-level model (similar to `model_3` with a slight modification to reflect the paper)\n","3. Create a `\"line_number\"` model (takes in one-hot-encoded `\"line_number\"` tensor and passes it through a non-linear layer)\n","4. Create a `\"total_lines\"` model (takes in one-hot-encoded `\"total_lines\"` tensor and passes it through a non-linear layer)\n","5. Combine (using [`layers.Concatenate`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Concatenate)) the outputs of 1 and 2 into a token-character-hybrid embedding and pass it series of output to Figure 1 and section 4.2 of [*Neural Networks for Joint Sentence Classification\n","in Medical Paper Abstracts*](https://arxiv.org/pdf/1612.05251.pdf)\n","6. Combine (using [`layers.Concatenate`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Concatenate)) the outputs of 3, 4 and 5 into a token-character-positional tribrid embedding \n","7. Create an output layer to accept the tribrid embedding and output predicted label probabilities\n","8. Combine the inputs of 1, 2, 3, 4 and outputs of 7 into a [`tf.keras.Model`](https://www.tensorflow.org/api_docs/python/tf/keras/Model)\n","\n","Woah! That's alot... but nothing we're not capable of. Let's code it."]},{"cell_type":"code","source":["# 1. Token inputs\n","token_inputs = layers.Input(shape=[], dtype=\"string\", name=\"token_inputs\")\n","token_embeddings = tf_hub_embedding_layer(token_inputs)\n","token_outputs = layers.Dense(128, activation=\"relu\")(token_embeddings)\n","token_model = tf.keras.Model(inputs=token_inputs,\n","                             outputs=token_outputs)\n","\n","# 2. Char inputs\n","char_inputs = layers.Input(shape=(1,), dtype=\"string\", name=\"char_inputs\")\n","char_vectors = char_vectorizer(char_inputs)\n","char_embeddings = char_embed(char_vectors)\n","char_bi_lstm = layers.Bidirectional(layers.LSTM(32))(char_embeddings)\n","char_model = tf.keras.Model(inputs=char_inputs,\n","                            outputs=char_bi_lstm)\n","\n","# 3. Line numbers inputs\n","line_number_inputs = layers.Input(shape=(15,), dtype=tf.int32, name=\"line_number_input\")\n","x = layers.Dense(32, activation=\"relu\")(line_number_inputs)\n","line_number_model = tf.keras.Model(inputs=line_number_inputs,\n","                                   outputs=x)\n","\n","# 4. Total lines inputs\n","total_lines_inputs = layers.Input(shape=(20,), dtype=tf.int32, name=\"total_lines_input\")\n","y = layers.Dense(32, activation=\"relu\")(total_lines_inputs)\n","total_line_model = tf.keras.Model(inputs=total_lines_inputs,\n","                                  outputs=y)\n","\n","# 5. Combine token and char embeddings into a hybrid embedding\n","combined_embeddings = layers.Concatenate(name=\"token_char_hybrid_embedding\")([token_model.output, \n","                                                                              char_model.output])\n","z = layers.Dense(256, activation=\"relu\")(combined_embeddings)\n","z = layers.Dropout(0.5)(z)\n","\n","# 6. Combine positional embeddings with combined token and char embeddings into a tribrid embedding\n","z = layers.Concatenate(name=\"token_char_positional_embedding\")([line_number_model.output,\n","                                                                total_line_model.output,\n","                                                                z])\n","\n","# 7. Create output layer\n","output_layer = layers.Dense(5, activation=\"softmax\", name=\"output_layer\")(z)\n","\n","# 8. Put together model\n","model_5 = tf.keras.Model(inputs=[line_number_model.input,\n","                                 total_line_model.input,\n","                                 token_model.input, \n","                                 char_model.input],\n","                         outputs=output_layer)"],"metadata":{"id":"Y98ph_D7HQEK","executionInfo":{"status":"ok","timestamp":1641218352140,"user_tz":300,"elapsed":636,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":222,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KVhTeiveWf4X"},"source":["There's a lot going on here... let's visualize what's happening with a summary by plotting our model."]},{"cell_type":"code","source":["# Get a summary of my token, char & positional embedding model\n","model_5.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DIZ_MTu4PiE6","executionInfo":{"status":"ok","timestamp":1641218352140,"user_tz":300,"elapsed":7,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"ff752b08-71f6-4631-945f-e52b4f559f90"},"execution_count":223,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_8\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," char_inputs (InputLayer)       [(None, 1)]          0           []                               \n","                                                                                                  \n"," token_inputs (InputLayer)      [(None,)]            0           []                               \n","                                                                                                  \n"," char_vectorizer (TextVectoriza  (None, 290)         0           ['char_inputs[0][0]']            \n"," tion)                                                                                            \n","                                                                                                  \n"," universal_sentence_encoder (Ke  (None, 512)         256797824   ['token_inputs[0][0]']           \n"," rasLayer)                                                                                        \n","                                                                                                  \n"," char_embed (Embedding)         (None, 290, 25)      1750        ['char_vectorizer[2][0]']        \n","                                                                                                  \n"," dense_15 (Dense)               (None, 128)          65664       ['universal_sentence_encoder[2][0\n","                                                                 ]']                              \n","                                                                                                  \n"," bidirectional_2 (Bidirectional  (None, 64)          14848       ['char_embed[2][0]']             \n"," )                                                                                                \n","                                                                                                  \n"," token_char_hybrid_embedding (C  (None, 192)         0           ['dense_15[0][0]',               \n"," oncatenate)                                                      'bidirectional_2[0][0]']        \n","                                                                                                  \n"," line_number_input (InputLayer)  [(None, 15)]        0           []                               \n","                                                                                                  \n"," total_lines_input (InputLayer)  [(None, 20)]        0           []                               \n","                                                                                                  \n"," dense_18 (Dense)               (None, 256)          49408       ['token_char_hybrid_embedding[0][\n","                                                                 0]']                             \n","                                                                                                  \n"," dense_16 (Dense)               (None, 32)           512         ['line_number_input[0][0]']      \n","                                                                                                  \n"," dense_17 (Dense)               (None, 32)           672         ['total_lines_input[0][0]']      \n","                                                                                                  \n"," dropout_2 (Dropout)            (None, 256)          0           ['dense_18[0][0]']               \n","                                                                                                  \n"," token_char_positional_embeddin  (None, 320)         0           ['dense_16[0][0]',               \n"," g (Concatenate)                                                  'dense_17[0][0]',               \n","                                                                  'dropout_2[0][0]']              \n","                                                                                                  \n"," output_layer (Dense)           (None, 5)            1605        ['token_char_positional_embedding\n","                                                                 [0][0]']                         \n","                                                                                                  \n","==================================================================================================\n","Total params: 256,932,283\n","Trainable params: 134,459\n","Non-trainable params: 256,797,824\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["# Plot the token, char, & positional embedding model\n","from tensorflow.keras.utils import plot_model\n","plot_model(model_5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":537},"id":"HC8tycukPtK-","executionInfo":{"status":"ok","timestamp":1641218353202,"user_tz":300,"elapsed":1064,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"ff1ae887-b515-4d4d-9ed6-e569c4b458d2"},"execution_count":224,"outputs":[{"output_type":"execute_result","data":{"image/png":"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\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{},"execution_count":224}]},{"cell_type":"markdown","metadata":{"id":"G8B73w06Wxxm"},"source":["Visualizing the model makes it much easier to understand.\n","\n","Essentially what we're doing is trying to encode as much information about our sequences as possible into various embeddings (the inputs to our model) so our model has the best chance to figure out what label belongs to a sequence (the outputs of our model).\n","\n","You'll notice our model is looking very similar to the model shown in Figure 1 of [*Neural Networks for Joint Sentence Classification\n","in Medical Paper Abstracts*](https://arxiv.org/pdf/1612.05251.pdf). However, a few differences still remain:\n","* We're using pretrained TensorFlow Hub token embeddings instead of GloVe emebddings.\n","* We're using a Dense layer on top of our token-character hybrid embeddings instead of a bi-LSTM layer.\n","* Section 3.1.3 of the paper mentions a label sequence optimization layer (which helps to make sure sequence labels come out in a respectable order) but it isn't shown in Figure 1. To makeup for the lack of this layer in our model, we've created the positional embeddings layers.\n","* Section 4.2 of the paper mentions the token and character embeddings are updated during training, our pretrained TensorFlow Hub embeddings remain frozen.\n","* The paper uses the [`SGD`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD) optimizer, we're going to stick with [`Adam`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam).\n","\n","All of the differences above are potential extensions of this project."]},{"cell_type":"code","source":["# Check which layers of model_5 are trainable\n","for layer in model_5.layers:\n","  print(layer, layer.trainable)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iLGLbK2YP5Xp","executionInfo":{"status":"ok","timestamp":1641218353203,"user_tz":300,"elapsed":14,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"f5065950-16c8-4a02-923f-24ef9bb15110"},"execution_count":225,"outputs":[{"output_type":"stream","name":"stdout","text":["<keras.engine.input_layer.InputLayer object at 0x7f7f57761fd0> True\n","<keras.engine.input_layer.InputLayer object at 0x7f7f577ec450> True\n","<keras.layers.preprocessing.text_vectorization.TextVectorization object at 0x7f7f729318d0> True\n","<tensorflow_hub.keras_layer.KerasLayer object at 0x7f7f6e972b10> False\n","<keras.layers.embeddings.Embedding object at 0x7f7f76395850> True\n","<keras.layers.core.dense.Dense object at 0x7f7f578329d0> True\n","<keras.layers.wrappers.Bidirectional object at 0x7f7f57783f90> True\n","<keras.layers.merge.Concatenate object at 0x7f7f577b0e10> True\n","<keras.engine.input_layer.InputLayer object at 0x7f7f57769290> True\n","<keras.engine.input_layer.InputLayer object at 0x7f7f626797d0> True\n","<keras.layers.core.dense.Dense object at 0x7f7f5767fd90> True\n","<keras.layers.core.dense.Dense object at 0x7f7f576b8dd0> True\n","<keras.layers.core.dense.Dense object at 0x7f7f57683490> True\n","<keras.layers.core.dropout.Dropout object at 0x7f7f575e6790> True\n","<keras.layers.merge.Concatenate object at 0x7f7f576c0710> True\n","<keras.layers.core.dense.Dense object at 0x7f7f62679750> True\n"]}]},{"cell_type":"markdown","metadata":{"id":"RqUCaJPKY9o_"},"source":["Now our model is constructed, let's compile it.\n","\n","This time, we're going to introduce a new parameter to our loss function called `label_smoothing`. Label smoothing helps to regularize our model (prevent overfitting) by making sure it doesn't get too focused on applying one particular label to a sample.\n","\n","For example, instead of having an output prediction of: \n","* `[0.0, 0.0, 1.0, 0.0, 0.0]` for a sample (the model is very confident the right label is index 2).\n","\n","It's predictions will get smoothed to be something like:\n","* `[0.01, 0.01, 0.096, 0.01, 0.01]` giving a small activation to each of the other labels, in turn, hopefully improving generalization.\n","\n","> üìñ **Resource:** For more on label smoothing, see the great blog post by PyImageSearch, [*Label smoothing with Keras, TensorFlow, and Deep Learning*](https://www.pyimagesearch.com/2019/12/30/label-smoothing-with-keras-tensorflow-and-deep-learning/)."]},{"cell_type":"code","source":["# Compile token, char, positional embedding model\n","model_5.compile(loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.2), # add label smoothing (this smooths example predictions that are really confident)\n","                optimizer=tf.keras.optimizers.Adam(),\n","                metrics=[\"accuracy\"])"],"metadata":{"id":"O44x-mwCQtFA","executionInfo":{"status":"ok","timestamp":1641218353203,"user_tz":300,"elapsed":6,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":226,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vrXEGlcUZXAE"},"source":["### Create tribrid embedding datasets and fit tribrid model\n","\n","Model compiled!\n","\n","Again, to keep our experiments swift, let's fit on 20,000 examples for 3 epochs.\n","\n","This time our model requires four feature inputs:\n","1. Train line numbers one-hot tensor (`train_line_numbers_one_hot`)\n","2. Train total lines one-hot tensor (`train_total_lines_one_hot`)\n","3. Token-level sequences tensor (`train_sentences`)\n","4. Char-level sequences tensor (`train_chars`)\n","\n","We can pass these as tuples to our `tf.data.Dataset.from_tensor_slices()` method to create appropriately shaped and batched `PrefetchedDataset`'s."]},{"cell_type":"code","source":["# Create training & validation datasets (all four kinds of inputs)\\\n","train_pos_char_token_data = tf.data.Dataset.from_tensor_slices((train_line_numbers_one_hot, # Line nums\n","                                                               train_total_lines_one_hot, # total lines\n","                                                               train_sentences,  # train tokens\n","                                                               train_chars)) # train chars\n","train_pos_char_token_labels = tf.data.Dataset.from_tensor_slices(train_labels_one_hot) # train labels\n","train_pos_char_token_dataset = tf.data.Dataset.zip((train_pos_char_token_data, train_pos_char_token_labels)) # combine data and labels\n","train_pos_char_token_dataset = train_pos_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE) # turn into batches & prefetch appropriately\n","\n","# Validation dataset\n","val_pos_char_token_data = tf.data.Dataset.from_tensor_slices((val_line_numbers_one_hot,\n","                                                              val_total_lines_one_hot,\n","                                                              val_sentences,\n","                                                              val_chars))\n","val_pos_char_token_labels = tf.data.Dataset.from_tensor_slices(val_labels_one_hot)\n","val_pos_char_token_dataset = tf.data.Dataset.zip((val_pos_char_token_data, val_pos_char_token_labels))\n","val_pos_char_token_dataset = val_pos_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE) # turn into batches and prefetch appropriately\n","\n","# Check input shapes\n","train_pos_char_token_dataset, val_pos_char_token_dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ie9y62QLRv1D","executionInfo":{"status":"ok","timestamp":1641218355144,"user_tz":300,"elapsed":1946,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"1aa5685e-e7e0-47aa-b691-8d91ef1c1998"},"execution_count":227,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(<PrefetchDataset shapes: (((None, 15), (None, 20), (None,), (None,)), (None, 5)), types: ((tf.float32, tf.float32, tf.string, tf.string), tf.float64)>,\n"," <PrefetchDataset shapes: (((None, 15), (None, 20), (None,), (None,)), (None, 5)), types: ((tf.float32, tf.float32, tf.string, tf.string), tf.float64)>)"]},"metadata":{},"execution_count":227}]},{"cell_type":"code","source":["# Fit the token, char & positional embedding model\n","history_model_5 = model_5.fit(train_pos_char_token_dataset,\n","                              steps_per_epoch=int(0.1 * len(train_pos_char_token_dataset)),\n","                              epochs=3,\n","                              validation_data=val_pos_char_token_dataset,\n","                              validation_steps=int(0.1 * len(val_pos_char_token_dataset)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sNMiawojYFY_","executionInfo":{"status":"ok","timestamp":1641218766089,"user_tz":300,"elapsed":410946,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"f7333951-fcfd-44c9-dbdb-02e43870d1cc"},"execution_count":228,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","562/562 [==============================] - 147s 254ms/step - loss: 1.1014 - accuracy: 0.7241 - val_loss: 0.9845 - val_accuracy: 0.8022\n","Epoch 2/3\n","562/562 [==============================] - 131s 233ms/step - loss: 0.9693 - accuracy: 0.8146 - val_loss: 0.9485 - val_accuracy: 0.8281\n","Epoch 3/3\n","562/562 [==============================] - 133s 236ms/step - loss: 0.9518 - accuracy: 0.8225 - val_loss: 0.9407 - val_accuracy: 0.8281\n"]}]},{"cell_type":"markdown","metadata":{"id":"fS88IaN_auu8"},"source":["Tribrid model trained! Time to make some predictions with it and evaluate them just as we've done before."]},{"cell_type":"code","source":["# Make predictions with token-char-positional hybrid model\n","model_5_pred_probs = model_5.predict(val_pos_char_token_dataset, verbose=1)\n","model_5_pred_probs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DyLBqh0nbuzm","executionInfo":{"status":"ok","timestamp":1641218849184,"user_tz":300,"elapsed":83104,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"30b24bd0-ab96-4535-91eb-9d5f5cd20e7e"},"execution_count":229,"outputs":[{"output_type":"stream","name":"stdout","text":["945/945 [==============================] - 56s 58ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[0.46315384, 0.11787526, 0.01166219, 0.38447213, 0.02283658],\n","       [0.46672624, 0.11941695, 0.06355265, 0.33655217, 0.01375204],\n","       [0.26305157, 0.13000965, 0.09379255, 0.45391908, 0.05922717],\n","       ...,\n","       [0.03556203, 0.10767174, 0.04432823, 0.0328336 , 0.7796044 ],\n","       [0.02776127, 0.29562312, 0.08848145, 0.02514313, 0.562991  ],\n","       [0.26574624, 0.5300502 , 0.10922012, 0.04296412, 0.05201931]],\n","      dtype=float32)"]},"metadata":{},"execution_count":229}]},{"cell_type":"code","source":["# Turn prediction probabilities into prediction classes\n","model_5_preds = tf.argmax(model_5_pred_probs, axis=1)\n","model_5_preds"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"emLR4ivNcO7N","executionInfo":{"status":"ok","timestamp":1641218849184,"user_tz":300,"elapsed":17,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"bed5d942-22a7-4340-f139-2e258e49e415"},"execution_count":230,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 0, 3, ..., 4, 4, 1])>"]},"metadata":{},"execution_count":230}]},{"cell_type":"code","source":["# Calculate results of token-char-positional hybrid model\n","model_5_results = calculate_results(y_true=val_labels_encoded,\n","                                    y_pred=model_5_preds)\n","model_5_results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gkE9rJSscjOL","executionInfo":{"status":"ok","timestamp":1641218849185,"user_tz":300,"elapsed":11,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"fb0a81c3-0bca-4438-f4b5-aecc9d47af98"},"execution_count":231,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'accuracy': 83.11598040513704,\n"," 'f1': 0.8303720560771667,\n"," 'precision': 0.8303582822891686,\n"," 'recall': 0.8311598040513704}"]},"metadata":{},"execution_count":231}]},{"cell_type":"markdown","metadata":{"id":"yranVE5soBdf"},"source":["## Compare model results \n","\n","Far out, we've come a long way. From a baseline model to training a model containing three different kinds of embeddings.\n","\n","Now it's time to compare each model's performance against each other.\n","\n","We'll also be able to compare our model's to the [*PubMed 200k RCT:\n","a Dataset for Sequential Sentence Classification in Medical Abstracts*](https://arxiv.org/pdf/1710.06071.pdf) paper.\n","\n","Since all of our model results are in dictionaries, let's combine them into a pandas DataFrame to visualize them."]},{"cell_type":"code","source":["# Combine model results into a DataFrame\n","all_model_results = pd.DataFrame({\"baseline\": baseline_results,\n","                                 \"custom_token_embed_conv1d\": model_1_results,\n","                                 \"pretrained_token_embed\": model_2_results,\n","                                 \"custom_char_embed_conv1d\": model_3_results,\n","                                 \"hybrid_char_token_embed\": model_4_results,\n","                                 \"traibrid_pos_char_token_embed\": model_5_results})\n","all_model_results = all_model_results.transpose()\n","all_model_results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"id":"adt7P6JEc0rg","executionInfo":{"status":"ok","timestamp":1641218849185,"user_tz":300,"elapsed":8,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"e1f1163a-27aa-49dd-b37d-1662702808a3"},"execution_count":232,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-f88e49a7-5682-4b05-9a5a-e699e000d3d0\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>accuracy</th>\n","      <th>precision</th>\n","      <th>recall</th>\n","      <th>f1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>baseline</th>\n","      <td>72.183238</td>\n","      <td>0.718647</td>\n","      <td>0.721832</td>\n","      <td>0.698925</td>\n","    </tr>\n","    <tr>\n","      <th>custom_token_embed_conv1d</th>\n","      <td>78.677347</td>\n","      <td>0.783721</td>\n","      <td>0.786773</td>\n","      <td>0.784631</td>\n","    </tr>\n","    <tr>\n","      <th>pretrained_token_embed</th>\n","      <td>71.322653</td>\n","      <td>0.713659</td>\n","      <td>0.713227</td>\n","      <td>0.710154</td>\n","    </tr>\n","    <tr>\n","      <th>custom_char_embed_conv1d</th>\n","      <td>65.682510</td>\n","      <td>0.646754</td>\n","      <td>0.656825</td>\n","      <td>0.645020</td>\n","    </tr>\n","    <tr>\n","      <th>hybrid_char_token_embed</th>\n","      <td>73.570105</td>\n","      <td>0.738197</td>\n","      <td>0.735701</td>\n","      <td>0.732030</td>\n","    </tr>\n","    <tr>\n","      <th>traibrid_pos_char_token_embed</th>\n","      <td>83.115980</td>\n","      <td>0.830358</td>\n","      <td>0.831160</td>\n","      <td>0.830372</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f88e49a7-5682-4b05-9a5a-e699e000d3d0')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f88e49a7-5682-4b05-9a5a-e699e000d3d0 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f88e49a7-5682-4b05-9a5a-e699e000d3d0');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                accuracy  precision    recall        f1\n","baseline                       72.183238   0.718647  0.721832  0.698925\n","custom_token_embed_conv1d      78.677347   0.783721  0.786773  0.784631\n","pretrained_token_embed         71.322653   0.713659  0.713227  0.710154\n","custom_char_embed_conv1d       65.682510   0.646754  0.656825  0.645020\n","hybrid_char_token_embed        73.570105   0.738197  0.735701  0.732030\n","traibrid_pos_char_token_embed  83.115980   0.830358  0.831160  0.830372"]},"metadata":{},"execution_count":232}]},{"cell_type":"code","source":["# Reduce the accuracy to same scale as other metrics\n","all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100"],"metadata":{"id":"zAbQmYhwqK2C","executionInfo":{"status":"ok","timestamp":1641218849186,"user_tz":300,"elapsed":8,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":233,"outputs":[]},{"cell_type":"code","source":["# Plot & compare all of the model results\n","all_model_results.plot(kind=\"bar\", figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 1.0));"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":534},"id":"rPOVTO7Hqe90","executionInfo":{"status":"ok","timestamp":1641218850625,"user_tz":300,"elapsed":1446,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"9df73496-5c6c-4128-9034-5d8218bf1f95"},"execution_count":234,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 720x504 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"PI36lZHpcE53"},"source":["Since the [*PubMed 200k RCT:\n","a Dataset for Sequential Sentence Classification in Medical Abstracts*](https://arxiv.org/pdf/1710.06071.pdf) paper compares their tested model's F1-scores on the test dataset, let's take at our model's F1-scores.\n","\n","> üîë **Note:** We could've also made these comparisons in TensorBoard using the [`TensorBoard`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard) callback during training."]},{"cell_type":"code","source":["# Sort model results by f1-score\n","all_model_results.sort_values(\"f1\", ascending=False)[\"f1\"].plot(kind=\"bar\", figsize=(10, 7));"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":577},"id":"h41fPhdWquzq","executionInfo":{"status":"ok","timestamp":1641218850626,"user_tz":300,"elapsed":4,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"f2392000-7dbc-4617-a102-c6487de987f7"},"execution_count":235,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 720x504 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"iEoLsCNbwNRA"},"source":["Nice! Based on F1-scores, it looks like our tribrid embedding model performs the best by a fair margin.\n","\n","Though, in comparison to the results reported in Table 3 of the [*PubMed 200k RCT:\n","a Dataset for Sequential Sentence Classification in Medical Abstracts*](https://arxiv.org/pdf/1710.06071.pdf) paper, our model's F1-score is still underperforming (the authors model achieves an F1-score of 90.0 on the 20k RCT dataset versus our F1-score of ~82.6).\n","\n","There are some things to note about this difference:\n","* Our models (with an exception for the baseline) have been trained on ~18,000 (10% of batches) samples of sequences and labels rather than the full ~180,000 in the 20k RCT dataset.\n","  * This is often the case in machine learning experiments though, make sure training works on a smaller number of samples, then upscale when needed (an extension to this project will be training a model on the full dataset).\n","* Our model's prediction performance levels have been evaluated on the validation dataset not the test dataset (we'll evaluate our best model on the test dataset shortly)."]},{"cell_type":"markdown","metadata":{"id":"pk5rMP0rarWG"},"source":["## Save and load best performing model\n","\n","Since we've been through a fair few experiments, it's a good idea to save our best performing model so we can reuse it without having to retrain it.\n","\n","We can save our best performing model by calling the [`save()`](https://www.tensorflow.org/guide/keras/save_and_serialize#the_short_answer_to_saving_loading) method on it."]},{"cell_type":"code","source":["# Save best preforming model to SavedModel format (default)\n","model_5.save(\"skimlit_tribrid_model\") # model will be saved to path specified by string"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qM4JvOmUra-y","executionInfo":{"status":"ok","timestamp":1641218874482,"user_tz":300,"elapsed":23859,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"a3bfbe13-b98d-4049-e270-e369c708c479"},"execution_count":236,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn, lstm_cell_9_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: skimlit_tribrid_model/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: skimlit_tribrid_model/assets\n","WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f7f57783b10> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f7f57778e10> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]}]},{"cell_type":"markdown","metadata":{"id":"RMzS3dWPx9xu"},"source":["Optional: If you're using Google Colab, you might want to copy your saved model to Google Drive (or [download it](https://colab.research.google.com/notebooks/io.ipynb#scrollTo=hauvGV4hV-Mh)) for more permanent storage (Google Colab files disappear after you disconnect)."]},{"cell_type":"code","source":["# Example of copying saved model from Google Colab to Drive (requires Google Drive to be mounted)\n","!cp skim_lit_best_model -r /content/drive/MyDrive/tensorflow_course/skim_lit"],"metadata":{"id":"I3srH0NHsFlY","executionInfo":{"status":"ok","timestamp":1641218874482,"user_tz":300,"elapsed":14,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":237,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5Go3DCssvA1o"},"source":["\n","Like all good cooking shows, we've got a pretrained model (exactly the same kind of model we built for `model_5` [saved and stored on Google Storage](https://storage.googleapis.com/ztm_tf_course/skimlit/skimlit_best_model.zip)). \n","\n","So to make sure we're all using the same model for evaluation, we'll download it and load it in. \n","\n","And when loading in our model, since it uses a couple of [custom objects](https://www.tensorflow.org/guide/keras/save_and_serialize#custom_objects) (our TensorFlow Hub layer and `TextVectorization` layer), we'll have to load it in by specifying them in the `custom_objects` parameter of [`tf.keras.models.load_model()`](https://www.tensorflow.org/api_docs/python/tf/keras/models/load_model). \n","\n"]},{"cell_type":"code","source":["# Download pretrained model from Google Storage\n","!wget https://storage.googleapis.com/ztm_tf_course/skimlit/skimlit_tribrid_model.zip\n","!mkdir skimlit_gs_model\n","!unzip skimlit_tribrid_model.zip -d skimlit_gs_model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-NEJj_Tnse1A","executionInfo":{"status":"ok","timestamp":1641218914958,"user_tz":300,"elapsed":40488,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}},"outputId":"2903b0c4-ce60-4cc2-c2a4-fa3c539ccb92"},"execution_count":238,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-01-03 14:07:53--  https://storage.googleapis.com/ztm_tf_course/skimlit/skimlit_tribrid_model.zip\n","Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.189.128, 108.177.97.128, 108.177.125.128, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.189.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 962561955 (918M) [application/zip]\n","Saving to: ‚Äòskimlit_tribrid_model.zip‚Äô\n","\n","skimlit_tribrid_mod 100%[===================>] 917.97M  53.3MB/s    in 14s     \n","\n","2022-01-03 14:08:08 (67.2 MB/s) - ‚Äòskimlit_tribrid_model.zip‚Äô saved [962561955/962561955]\n","\n","Archive:  skimlit_tribrid_model.zip\n","   creating: skimlit_gs_model/skimlit_tribrid_model/\n","   creating: skimlit_gs_model/skimlit_tribrid_model/variables/\n","  inflating: skimlit_gs_model/skimlit_tribrid_model/variables/variables.index  \n","  inflating: skimlit_gs_model/skimlit_tribrid_model/variables/variables.data-00000-of-00001  \n","  inflating: skimlit_gs_model/skimlit_tribrid_model/keras_metadata.pb  \n","  inflating: skimlit_gs_model/skimlit_tribrid_model/saved_model.pb  \n","   creating: skimlit_gs_model/skimlit_tribrid_model/assets/\n"]}]},{"cell_type":"code","source":["# Import TensorFlow model dependencies (if needed) - https://github.com/tensorflow/tensorflow/issues/38250 \n","import tensorflow_hub as hub\n","import tensorflow as tf\n","from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n","\n","model_path = \"skimlit_gs_model/skimlit_tribrid_model\"\n","\n","# Load downloaded model from Google Storage\n","loaded_model = tf.keras.models.load_model(model_path,\n","                                          # Note: add this code if TensorFlow verson is < 2.5\n","                                          custom_objects={\"TestVectorization\": TextVectorization, # required for char vectorization\n","                                                          \"KerasLayer\": hub.KerasLayer}) # required for token embedding "],"metadata":{"id":"uf8q_uq_tEr0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GOY7As4Dxdn_"},"source":["### Make predictions and evalaute them against the truth labels\n","\n","To make sure our model saved and loaded correctly, let's make predictions with it, evaluate them and then compare them to the prediction results we calculated earlier."]},{"cell_type":"code","source":["# Make predictions with the loaded model on the vectorization set\n","loaded_pred_probs = loaded_model.predict(val_pos_char_token_dataset, verbose=1)\n","loaded_preds = tf.argmax(loaded_pred_probs, axis=1)\n","loaded_preds[:10]"],"metadata":{"id":"cbQ9sCp7ui3H","executionInfo":{"status":"aborted","timestamp":1641218932708,"user_tz":300,"elapsed":596,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate loaded model's predictions\n","loaded_model_results = calculate_results(val_labels_encoded,\n","                                         loaded_preds)\n","loaded_model_results"],"metadata":{"id":"6EBRLme8voae","executionInfo":{"status":"aborted","timestamp":1641218932710,"user_tz":300,"elapsed":597,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a_zJXe1v1Evs"},"source":["Now let's compare our loaded model's predictions with the prediction results we obtained before saving our model."]},{"cell_type":"code","source":["# Compare loaded model results with original trained model results (should be quite close)\n","np.isclose(list(model_5_results.values()), list(loaded_model_results.values()), rtol=1e-02)"],"metadata":{"id":"XQ9RJgA8v2dJ","executionInfo":{"status":"aborted","timestamp":1641218932711,"user_tz":300,"elapsed":598,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C5EMfCId1WKr"},"source":["It's worth noting that loading in a SavedModel unfreezes all layers (makes them all trainable). So if you want to freeze any layers, you'll have to set their trainable attribute to `False`."]},{"cell_type":"code","source":["# Check loaded model summary (note the number of trainable parameters)\n","loaded_model.summary()"],"metadata":{"id":"fbgTFq4bx7ZH","executionInfo":{"status":"aborted","timestamp":1641218932711,"user_tz":300,"elapsed":598,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5uq0MFPiaoUb"},"source":["## Evaluate model on test dataset\n","\n","To make our model's performance more comparable with the results reported in Table 3 of the [*PubMed 200k RCT:\n","a Dataset for Sequential Sentence Classification in Medical Abstracts*](https://arxiv.org/pdf/1710.06071.pdf) paper, let's make predictions on the test dataset and evaluate them."]},{"cell_type":"code","source":["# Create test dataset batch & prefetched\n","test_pos_char_token_data = tf.data.Dataset.from_tensor_slices((test_line_numbers_one_hot,\n","                                                               test+total_lines_one_hot,\n","                                                               test_sentences,\n","                                                               test_chars))\n","test_pos_char_token_labels = tf.data.Dataset.from_tensor_slices(test_labels_one_hot)\n","test_pos_char_token_dataset = tf.data.Dataset.zip((test_pos_char_token_data, test_pos_char_token_labels))\n","test_pos_char_token_dataset = test_pos_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n","\n","# Check shapes\n","test_pos_char_token_dataset"],"metadata":{"id":"Lh2rgC8gyLaq","executionInfo":{"status":"aborted","timestamp":1641218932712,"user_tz":300,"elapsed":599,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Make predictions on the test dataset\n","test_pred_probs = loaded_model.predict(test_pos_char_token_dataset,\n","                                       verbose=1)\n","test_preds = tf.argmax(test_pred_probs, axis=1)\n","test_preds[:10]"],"metadata":{"id":"DKgl1BW__IeC","executionInfo":{"status":"aborted","timestamp":1641218932712,"user_tz":300,"elapsed":599,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate loade model test predictions\n","loaded_model_test_results = calculate_results(y_true=test_labels_encoded,\n","                                              y_pred=test_preds)\n","loaded_model_test_resuts"],"metadata":{"id":"smfCkwWY_pAq","executionInfo":{"status":"aborted","timestamp":1641218932713,"user_tz":300,"elapsed":599,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eupgOniJ3rLr"},"source":["It seems our best model (so far) still has some ways to go to match the performance of the results in the paper (their model gets 90.0 F1-score on the test dataset, where as ours gets ~82.1 F1-score).\n","\n","However, as we discussed before our model has only been trained on 20,000 out of the total ~180,000 sequences in the RCT 20k dataset. We also haven't fine-tuned our pretrained embeddings (the paper fine-tunes GloVe embeddings). So there's a couple of extensions we could try to improve our results."]},{"cell_type":"markdown","metadata":{"id":"B8orhq8dPAuW"},"source":["## Find most wrong\n","\n","One of the best ways to investigate where your model is going wrong (or potentially where your data is wrong) is to visualize the \"most wrong\" predictions.\n","\n","The most wrong predictions are samples where the model has made a prediction with a high probability but has gotten it wrong (the model's prediction disagreess with the ground truth label).\n","\n","Looking at the most wrong predictions can give us valuable information on how to improve further models or fix the labels in our data.\n","\n","Let's write some code to help us visualize the most wrong predictions from the test dataset.\n","\n","First we'll convert all of our integer-based test predictions into their string-based class names."]},{"cell_type":"code","source":["%%time\n","# Get list of class names of test predictions\n","test_pred_classes = [label_encoder.classes_[pred] for pred in test_preds]\n","test_pred_classes"],"metadata":{"id":"UostRJfT_655","executionInfo":{"status":"aborted","timestamp":1641218932713,"user_tz":300,"elapsed":599,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0B41eg6O6DbQ"},"source":["Now we'll enrich our test DataFame with a few values:\n","* A `\"prediction\"` (string) column containing our model's prediction for a given sample.\n","* A `\"pred_prob\"` (float) column containing the model's maximum prediction probabiliy for a given sample.\n","* A `\"correct\"` (bool) column to indicate whether or not the model's prediction matches the sample's target label."]},{"cell_type":"code","source":["# Create prediction-enriched test dataframe\n","test_df[\"prediction\"] = test_pred_classes # create colum with test prediction class names\n","test_df[\"pred_prob\"] = tf.reduce_max(test_pred_probs, axis=1).numpy() # get the maximum prediction probability\n","test_df[\"correct\"] = test_df[\"prediction\"] == test_df[\"target\"] # create binary colum for if the prediction is correct\n","test_df.head(20)"],"metadata":{"id":"xqBHvZRhAilw","executionInfo":{"status":"aborted","timestamp":1641218932714,"user_tz":300,"elapsed":600,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"63aVn69B6sWe"},"source":["Looking good! Having our data like this, makes it very easy to manipulate and view in different ways.\n","\n","How about we sort our DataFrame to find the samples with the highest `\"pred_prob\"` and where the prediction was wrong (`\"correct\" == False`)?"]},{"cell_type":"code","source":["# Find top 100 most wrong samples (note: 100 is an abitrary num, it can be any num if I wanted)\n","top_100_wrong = test_df[test_df[\"correct\"] == False].sort_values(\"pred_prob\", ascending=False)[:100]\n","top_100_wrong"],"metadata":{"id":"z-P69vDVBqgi","executionInfo":{"status":"aborted","timestamp":1641218932714,"user_tz":300,"elapsed":600,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yKc6UJwZ7dHu"},"source":["Great (or not so great)! Now we've got a subset of our model's most wrong predictions, let's write some code to visualize them."]},{"cell_type":"code","source":["# Investigate top wrong preds\n","for row in top_100_wrong[0:10].itertuples(): # adjust indexes to view different samples\n","  _, target, text, line_number, total_lines, prediction, pred_prob, = row\n","  print(f\"Target: {target}, Pred: {prediction}, Prob: {pred_prob}, Line Number: {line_number}, Total lines: {total_lines}\\n\")\n","  print(f\"Text:\\n{text}\\n\")\n","  print(\"------\\n\")"],"metadata":{"id":"olp803BFCboR","executionInfo":{"status":"aborted","timestamp":1641218932715,"user_tz":300,"elapsed":601,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wMbQeX-M7sYV"},"source":["What do you notice about the most wrong predictions? Does the model make silly mistakes? Or are some of the labels incorrect/ambiguous (e.g. a line in an abstract could potentially be labelled `OBJECTIVE` or `BACKGROUND` and make sense).\n","\n","A next step here would be if there are a fair few samples with inconsistent labels, you could go through your training dataset, update the labels and then retrain a model. The process of using a model to help improve/investigate your dataset's labels is often referred to as **active learning**."]},{"cell_type":"markdown","metadata":{"id":"Pfz_b-Tmapdz"},"source":["## Make example predictions\n","\n","Okay, we've made some predictions on the test dataset, now's time to really test our model out.\n","\n","To do so, we're going to get some data from the wild and see how our model performs.\n","\n","In other words, were going to find an RCT abstract from PubMed, preprocess the text so it works with our model, then pass each sequence in the wild abstract through our model to see what label it predicts.\n","\n","For an appropriate sample, we'll need to search PubMed for RCT's (randomized controlled trials) without abstracts which have been split up (on exploring PubMed you'll notice many of the abstracts are already preformatted into separate sections, this helps dramatically with readability).\n","\n","Going through various PubMed studies, I managed to find the following unstructured abstract from [*RCT of a manualized social treatment for high-functioning autism spectrum disorders*](https://pubmed.ncbi.nlm.nih.gov/20232240/):\n","\n","> This RCT examined the efficacy of a manualized social intervention for children with HFASDs. Participants were randomly assigned to treatment or wait-list conditions. Treatment included instruction and therapeutic activities targeting social skills, face-emotion recognition, interest expansion, and interpretation of non-literal language. A response-cost program was applied to reduce problem behaviors and foster skills acquisition. Significant treatment effects were found for five of seven primary outcome measures (parent ratings and direct child measures). Secondary measures based on staff ratings (treatment group only) corroborated gains reported by parents. High levels of parent, child and staff satisfaction were reported, along with high levels of treatment fidelity. Standardized effect size estimates were primarily in the medium and large ranges and favored the treatment group.\n","\n","Looking at the large chunk of text can seem quite intimidating. Now imagine you're a medical researcher trying to skim through the literature to find a study relevant to your work.\n","\n","Sounds like quite the challenge right?\n","\n","Enter SkimLit ü§ìüî•!\n","\n","Let's see what our best model so far (`model_5`) makes of the above abstract.\n","\n","But wait...\n","\n","As you might've guessed the above abstract hasn't been formatted in the same structure as the data our model has been trained on. Therefore, before we can make a prediction on it, we need to preprocess it just as we have our other sequences.\n","\n","More specifically, for each abstract, we'll need to:\n","\n","1. Split it into sentences (lines).\n","2. Split it into characters.\n","3. Find the number of each line.\n","4. Find the total number of lines.\n","\n","Starting with number 1, there are a couple of ways to split our abstracts into actual sentences. A simple one would be to use Python's in-built `split()` string method, splitting the abstract wherever a fullstop appears. However, can you imagine where this might go wrong? \n","\n","Another more advanced option would be to leverage [spaCy's](https://spacy.io/) (a very powerful NLP library) [`sentencizer`](https://spacy.io/usage/linguistic-features#sbd) class. Which is an easy to use sentence splitter based on spaCy's English language model.\n","\n","I've prepared some abstracts from PubMed RCT papers to try our model on, we can download them [from GitHub](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/skimlit_example_abstracts.json).\n"]},{"cell_type":"code","source":["# Download and open example abstracts (copy & paseted from PubMed)\n","!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/skimlit_example_abstracts.json\n","\n","with open(\"skimlit_example_abstracts.json\", \"r\") as f:\n","  example_abstracts = json.load(f)\n","\n","example_abstracts"],"metadata":{"id":"m1gBKxDKDqIe","executionInfo":{"status":"aborted","timestamp":1641218932715,"user_tz":300,"elapsed":601,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# See what my example abstracts look like\n","abstracts = pd.DataFrame(example_abstracts)\n","abstracts"],"metadata":{"id":"TriG62K0Ifw4","executionInfo":{"status":"aborted","timestamp":1641218932716,"user_tz":300,"elapsed":602,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CnZWtDki9uxc"},"source":["Now we've downloaded some example abstracts, let's see how one of them goes with our trained model.\n","\n","First, we'll need to parse it using spaCy to turn it from a big chunk of text into sentences."]},{"cell_type":"code","source":["# Create sentencizer - Source: https://spacy.io/usage/linguistic-features#sbd \n","from spacy.lang.en import English\n","nlp = English() # Setup English sentence parser\n","sentencizer = nlp.create_pipe(\"sentencizer\") # Create sentence splitting pipeline object\n","nlp.add_pipe(sentencizer) # add sentence splitting pipeline object to sentence parser\n","doc = nlp(example_abstracts[0][\"abstract\"]) # create \"doc\" of parsed sequences, chang index for a different abstract\n","abstract_lines = [str(sent) for sent in list(doc.sents)] # return detected sentences from doc in string type ( not spaCy token type)\n","abstract_lines"],"metadata":{"id":"pdEiLCRnI0_q","executionInfo":{"status":"aborted","timestamp":1641218932717,"user_tz":300,"elapsed":603,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UiCg-H4G16Gx"},"source":["Beautiful! It looks like spaCy has split the sentences in the abstract correctly. However, it should be noted, there may be more complex abstracts which don't get split perfectly into separate sentences (such as the example in [*Baclofen promotes alcohol abstinence in alcohol dependent cirrhotic patients with hepatitis C virus (HCV) infection*](https://pubmed.ncbi.nlm.nih.gov/22244707/)), in this case, more custom splitting techniques would have to be investigated.\n","\n","Now our abstract has been split into sentences, how about we write some code to count line numbers as well as total lines.\n","\n","To do so, we can leverage some of the functionality of our `preprocess_text_with_line_numbers()` function."]},{"cell_type":"code","source":["# Get total num of lines\n","total_lines_in_sample = len(abstract_lines)\n","\n","# Go through line in abstract & create a list of dictionaries containing features for each line\n","sample_lines = []\n","for i, line in enumerate(abstract_lines):\n","  sample_dict = {}\n","  sample_dict[\"text\"] = str(line)\n","  sample_dict[\"line_number\"] = i\n","  sample_dict[\"total_lines\"] = total_lines_in_sample -1\n","  sample_lines.append(sample_dict)\n","sample_lines"],"metadata":{"id":"ffTcrxyRKcT5","executionInfo":{"status":"aborted","timestamp":1641218932717,"user_tz":300,"elapsed":603,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"17X7ez2r37Nw"},"source":["Now we've got `\"line_number\"` and `\"total_lines\"` values, we can one-hot encode them with `tf.one_hot` just like we did with our training dataset (using the same values for the `depth` parameter)."]},{"cell_type":"code","source":["# Get all line_number values from sample abstract\n","test_abstract_line_numbers = [line[\"line_number\"] for line in sample_lines]\n","# One-hot encode to same depth as training data, so model accepts right input shape\n","test_abstract_line_numbers_one_hot = tf.one_hot(test_abstract_line_numbers, depth=15)\n","test_abstract_line_numbers_one_hot"],"metadata":{"id":"LQuljofhLZS_","executionInfo":{"status":"aborted","timestamp":1641218932718,"user_tz":300,"elapsed":604,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get all total_lines values from sample abstract\n","test_abstract_total_lines = [line[\"total_lines\"] for line in sample_lines]\n","# one-hot encode to show same depth as training data, so model accepts right input shape\n","test_abstract_total_lines_one_hot = tf.one_hot(test_abstract_total_lines, depth=20)\n","test_abstract_total_lines_one_hot"],"metadata":{"id":"yncaoisTMEVo","executionInfo":{"status":"aborted","timestamp":1641218932718,"user_tz":300,"elapsed":604,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wq-f17G440ur"},"source":["We can also use our `split_chars()` function to split our abstract lines into characters."]},{"cell_type":"code","source":["# Split abstract lines into characters\n","abstract_chars = [split_chars(sentence) for sentence in abstract_lines]\n","abstract_chars"],"metadata":{"id":"Fx3rRZU0MndX","executionInfo":{"status":"aborted","timestamp":1641218932719,"user_tz":300,"elapsed":605,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5MO7_-Hx5FvS"},"source":["Alright, now we've preprocessed our wild RCT abstract into all of the same features our model was trained on, we can pass these features to our model and make sequence label predictions!"]},{"cell_type":"code","source":["# Make predictions on sample abstract features\n","%%time\n","test_abstract_pred_probs = loaded_model.predict(x=(test_abstract_line_numbers_one_hot,\n","                                                   test_abstract_total_lines_one_hot,\n","                                                   tf.constant(abstract_lines),\n","                                                   tf.constant(abstract_chars)))\n","test_abstract_pred_probs"],"metadata":{"id":"UI88bYlkM7sW","executionInfo":{"status":"aborted","timestamp":1641218932719,"user_tz":300,"elapsed":604,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Turn prediction probabilities into prediction classes\n","test_abstract_preds = tf.argmax(test_abstract_pred_probs, axis=1)\n","test_abstract_preds"],"metadata":{"id":"ejl-T-lZNtZ0","executionInfo":{"status":"aborted","timestamp":1641218932720,"user_tz":300,"elapsed":605,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tSOOV4bp5sZI"},"source":["Now we've got the predicted sequence label for each line in our sample abstract, let's write some code to visualize each sentence with its predicted label."]},{"cell_type":"code","source":["# Turn prediction class integers into string class names\n","test_abstract_pred_classes = [label_encoder.classes_[i] for i in test_abstract_preds]\n","test_abstract_pred_classes"],"metadata":{"id":"M8rp4uFXN7yR","executionInfo":{"status":"aborted","timestamp":1641218932720,"user_tz":300,"elapsed":605,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualixe abstract lines & predict sequence labels\n","for i, line in enumerate(abstract_lines):\n","  print(f\"{test_abstract_pred_classes[i]}: {line}\")"],"metadata":{"id":"W5jPrFr4OSTF","executionInfo":{"status":"aborted","timestamp":1641218932721,"user_tz":300,"elapsed":606,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vCQVQ5DAKz4M"},"source":["Nice! Isn't that much easier to read? I mean, it looks like our model's predictions could be improved, but how cool is that?\n","\n","Imagine implementing our model to the backend of the PubMed website to format any unstructured RCT abstract on the site.\n","\n","Or there could even be a browser extension, called \"SkimLit\" which would add structure (powered by our model) to any unstructured RCT abtract.\n","\n","And if showed your medical researcher friend, and they thought the predictions weren't up to standard, there could be a button saying \"is this label correct?... if not, what should it be?\". That way the dataset, along with our model's future predictions, could be improved over time.\n","\n","Of course, there are many more ways we could go to improve the model, the usuability, the preprocessing functionality (e.g. functionizing our sample abstract preprocessing pipeline) but I'll leave these for the exercises/extensions.\n","\n","> ü§î **Question:** How can we be sure the results of our test example from the wild are truly *wild*? Is there something we should check about the sample we're testing on?"]},{"cell_type":"markdown","metadata":{"id":"bLNyY9OoLEYL"},"source":["## üõ† Exercises\n","\n","1. Train `model_5` on all of the data in the training dataset for as many epochs until it stops improving. Since this might take a while, you might want to use:\n","  * [`tf.keras.callbacks.ModelCheckpoint`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint) to save the model's best weights only.\n","  * [`tf.keras.callbacks.EarlyStopping`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping) to stop the model from training once the validation loss has stopped improving for ~3 epochs.\n","2. Checkout the [Keras guide on using pretrained GloVe embeddings](https://keras.io/examples/nlp/pretrained_word_embeddings/). Can you get this working with one of our models?\n","  * Hint: You'll want to incorporate it with a custom token [Embedding](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding) layer.\n","  * It's up to you whether or not you fine-tune the GloVe embeddings or leave them frozen.\n","3. Try replacing the TensorFlow Hub Universal Sentence Encoder pretrained  embedding for the [TensorFlow Hub BERT PubMed expert](https://tfhub.dev/google/experts/bert/pubmed/2) (a language model pretrained on PubMed texts) pretrained embedding. Does this effect results?\n","  * Note: Using the BERT PubMed expert pretrained embedding requires an extra preprocessing step for sequences (as detailed in the [TensorFlow Hub guide](https://tfhub.dev/google/experts/bert/pubmed/2)).\n","  * Does the BERT model beat the results mentioned in this paper? https://arxiv.org/pdf/1710.06071.pdf \n","4. What happens if you were to merge our `line_number` and `total_lines` features for each sequence? For example, created a `X_of_Y` feature instead? Does this effect model performance?\n","  * Another example: `line_number=1` and `total_lines=11` turns into `line_of_X=1_of_11`.\n","5. Write a function (or series of functions) to take a sample abstract string, preprocess it (in the same way our model has been trained), make a prediction on each sequence in the abstract and return the abstract in the format:\n","  * `PREDICTED_LABEL`: `SEQUENCE`\n","  * `PREDICTED_LABEL`: `SEQUENCE`\n","  * `PREDICTED_LABEL`: `SEQUENCE`\n","  * `PREDICTED_LABEL`: `SEQUENCE`\n","  * ...\n","    * You can find your own unstrcutured RCT abstract from PubMed or try this one from: [*Baclofen promotes alcohol abstinence in alcohol dependent cirrhotic patients with hepatitis C virus (HCV) infection*](https://pubmed.ncbi.nlm.nih.gov/22244707/)."]},{"cell_type":"markdown","metadata":{"id":"O6E8rcjKrLzY"},"source":["## üìñ Extra-curriculum\n","* For more on working with text/spaCy, see [spaCy's advanced NLP course](https://course.spacy.io/en/). If you're going to be working on production-level NLP problems, you'll probably end up using spaCy.\n","* For another look at how to approach a text classification problem like the one we've just gone through, I'd suggest going through [Google's Machine Learning Course for text classification](https://developers.google.com/machine-learning/guides/text-classification). \n","* Since our dataset has imbalanced classes (as with many real-world datasets), so it might be worth looking into the [TensorFlow guide for different methods to training a model with imbalanced classes](https://www.tensorflow.org/tutorials/structured_data/imbalanced_data).\n"]},{"cell_type":"code","source":[""],"metadata":{"id":"_iqyYgW3Om4b","executionInfo":{"status":"aborted","timestamp":1641218932721,"user_tz":300,"elapsed":606,"user":{"displayName":"Marko Varga","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAGDkkPYoUGiD6h43iLORZZz94YPgcdyC_7uTbZQ=s64","userId":"09169851864705873028"}}},"execution_count":null,"outputs":[]}]}